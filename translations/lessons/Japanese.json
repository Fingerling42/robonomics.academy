{
  "Part 3: Emergence of the World Computer": "第3部：ワールドコンピューターの出現",
  "In the third part titled \"Emergence of the World Computer,\" we will attempt, layer by layer, to recreate the engineering implementation of the world computer using examples from Ethereum and Polkadot, as before.\"": "第3部のタイトルは「ワールドコンピューターの出現」であり、エーテリアムとポルカドットの例を使用して、ワールドコンピューターのエンジニアリング実装を階層ごとに再現しようとします。",
  "Learn": "学ぶ",
  "In the third part titled \"Emergence of the World Computer,\" we will attempt, layer by layer, to recreate the engineering implementation of the world computer using examples from Ethereum and Polkadot, as before.": "第3部のタイトルは「ワールドコンピューターの出現」であり、エーテリアムとポルカドットの例を使用して、ワールドコンピューターのエンジニアリング実装を階層ごとに再現しようとします。",
  "Let's start with Ethereum. Ethereum began in 2015 with a state that can be characterized as a combination of the proof-of-work consensus algorithm, enabling the world computer to exist in a decentralized state (as discussed in Part 2). Additionally, the Ethereum Virtual Machine (EVM) was introduced, serving as a Turing-complete computational machine. Together, these two elements formed the first version of the world computer, sometimes referred to as a precursor. Within this context, decentralized applications, or smart contracts, began to emerge.": "まずはエーテリアムから始めましょう。エーテリアムは2015年に始まり、プルーフ・オブ・ワークのコンセンサスアルゴリズムを組み合わせた状態で、ワールドコンピューターが分散状態で存在できるようになりました（第2部で議論されたように）。さらに、エーテリアム仮想マシン（EVM）が導入され、チューリング完全な計算機として機能しました。これら2つの要素が組み合わさり、最初のワールドコンピューターのバージョンが形成されました。この文脈の中で、分散型アプリケーションまたはスマートコントラクトが登場し始めました。",
  "Over the next 5 years, Ethereum lived a relatively unchanged life, undergoing some engineering tunings, such as a continuous increase in gas limits, with the exception of events like the Shanghai fork. Notably, during the second DEFCON held in Shanghai, a denial-of-service attack exploited a function in the virtual machine that consumed minimal gas but triggered significant computations on the Ethereum network. This led to memory overflow, effectively disrupting an entire Ethereum node. This incident highlights the intricate details that arise when dealing with a large and abstract solution like creating a virtual machine.": "その後の5年間、エーテリアムは比較的変化のない生活を送り、ガスリミットの継続的な増加などのエンジニアリングの微調整を経験しましたが、上海フォークなどのイベントを除いては。特に、上海で開催された第2回DEFCONでは、仮想マシン内の機能が最小限のガスを消費しながらエーテリアムネットワーク上で重要な計算を引き起こす攻撃が行われました。これにより、メモリオーバーフローが発生し、エーテリアムノード全体が混乱しました。この事件は、仮想マシンを作成する際に発生する複雑な詳細を示しています。",
  "Moving forward, a significant shift occurred around the end of the decade, particularly in 2020, with the advent of Ethereum 2.0. However, Ethereum 2.0 has now been deprecated, and I would characterize the real breakthrough as starting around 2019-2020. During this period, there was a true technological breakthrough in Ethereum, moving towards the concept of Ethereum 2.0. The moment of engineering change in Ethereum's architecture can be considered the event known as \"the merge,\" where the functionalities of the beacon chain were combined. The merge marked a significant shift in the paradigm of Ethereum, transitioning it into a slightly different state than what was on the board. The actual engineering change in Ethereum's architecture can be associated with \"the merge,\" where the functionalities of the beacon chain were integrated. For a detailed history of this, you can refer to the ethereum.org website, which provides an excellent article on the coexistence of the traditional Ethereum blockchain with the parallel blockchain launched in 2015 and the Ethereum Virtual Machine.": "その後、2020年に特にディケードの終わり頃に重要な変化が起こり、エーテリアム2.0が登場しました。しかし、エーテリアム2.0は現在廃止されており、実際のブレークスルーは2019年から2020年頃に始まったと言えます。この期間中、エーテリアムで真の技術的ブレークスルーがあり、エーテリアム2.0の概念に向かって進んでいきました。エーテリアムのアーキテクチャにおけるエンジニアリングの変化���瞬間は、「マージ」として知られるイベントで、ビーコンチェーンの機能が統合されました。このマージは、エーテリアムのパラダイムの大きな変化を示し、ボード上にあったものとはやや異なる状態に移行しました。エーテリアムのアーキテクチャにおける実際のエンジニアリングの変化は、「マージ」と関連付けられ、ビーコンチェーンの機能が統合されました。これについての詳細な歴史については、2015年に開始された並行ブロックチェーンとエーテリアム仮想マシンと共存する優れた記事を提供しているethereum.orgウェブサイトを参照してください。",
  "When the merge occurred, we witnessed a new architectural representation, both at the network level and for individual nodes interacting with the Ethereum network. What was the actual change? For many, the merge signifies the transition from proof-of-work to proof-of-stake, which is indeed significant. It implies increased efficiency and fine-tuning, but it's still a tuning relative to one of the parameters. However, the more noteworthy internal engineering change for each network client was the split. There was no longer a single specific network client or a monolithic architecture. Instead, we got two components of a single node interacting with the Ethereum network.": "マージが発生したとき、私たちは新しいアーキテクチャの表現を目撃しました、ネットワークレベルとイーサリアムネットワークと相互作用する個々のノードの両方で。実際の変更は何でしたか？多くの人にとって、マージはプルーフオブワークからプルーフオブステークへの移行を意味し、これは確かに重要です。これは効率が向上し微調整されることを意味しますが、それはパラメータの1つに対する調整です。ただし、各ネットワーククライアントにとってより注目すべき内部エンジニアリングの変更は、分割でした。もはや特定のネットワーククライアントやモノリシックなアーキテクチャは存在しませんでした。代わりに、イーサリアムネットワークと相互作用する単一ノードの2つのコンポーネントを取得しました。",
  "The first part, which I labeled \"beacon chain\" on the diagram, essentially represents a collective image of all the innovations that came into the Ethereum client at the moment of the merge. The second part is the preserved virtual machine. Nevertheless, it's worth adding something here too. Dialogues truly began about replacing the virtual machine, which was exclusively tailored to work with smart contracts and smart contracts in a specific language—Solidity. This is because, by 2015, there were practically no interpreters left for smart contracts in languages other than Solidity, and the architecture appeared somewhat one-sided from the perspective of an Ethereum programmer. You learn a snippet of JavaScript in the form of Solidity, write smart contract code on it, and get your DApp, like Uniswap, for example.": "図面で「ビーコンチェーン」とラベル付けした最初の部分は、マージの瞬間にイーサリアムクライアントに入ったすべての革新の集合的なイメージを実質的に表しています。2番目の部分は保存された仮想マシンです���それにも何か追加する価値があります。実際、仮想マシンの置き換えについての対話が始まりました。これは、2015年までに、Solidity以外の言語でスマートコントラクトとスマートコントラクトを作業するためのインタプリタがほとんど残っていなかったためです。そして、イーサリアムプログラマーの観点から見ると、アーキテクチャはやや片寄って見えました。Solidityの形式でJavaScriptのスニペットを学び、それを使用してスマートコントラクトコードを書き、UniswapなどのDAppを取得します。",
  "Since the emergence of a more complex Ethereum architecture, discussions have revolved around the idea that the virtual machine, which existed as a somewhat monolithic element from 2015, can also be replaced in the new architecture. The conversation shifted towards replacing it with something like WebAssembly (Wasm) or a more interesting solution from the perspective of writing code for the world computer. You could say, \"Wasm with a question mark.\"": "より複雑なイーサリアムアーキテクチャの出現以来、仮想マシンは2015年からややモノリシックな要素として存在していたものも、新しいアーキテクチャで置き換えられる可能性があるという考えを中心に議論が展開されてきました。その会話は、WebAssembly（Wasm）などのもので置き換えることに向かい、世界コンピューターのためのコードを書く観点からより興味深い解決策に向かいました。言ってしまえば、「疑問符付きのWasm」です。",
  "From the perspective of the Beacon Chain, it indeed operates on proof-of-stake, but what's more interesting is the inclusion of Gasper. This represents a modification of the original ideas about Casper. Casper, often referred to as the friendly ghost finality gadget, was introduced, perhaps even as early as Defcon 3 or 4, and maybe even discussed at Defcon 2—I don't recall precisely. But at the EthCC conference in Paris, which definitely took place in 2018, Vlad Zamfir and Vitalik, from different rooms, were discussing the emergence of Casper as a friendly ghost, overseeing participants in proof-of-stake and coming to the aid of the network when a node misbehaves. From this idea of Casper, Gasper emerges. Without delving into terminology too much, the consensus algorithm undergoes a shift, changing not only in terms of simplicity but also becoming more complex, similar to Polkadot. As I mentioned earlier, Polkadot has two consensus algorithms, Babe and Grandpa. Similarly, with Ethereum's Beacon Chain functionality, achieving consensus and finality is not as instantaneous. It involves epochs, and the network operates on a more complex scenario, reaching a state that is already somewhat dynamic, not frozen, and is essentially carved in stone.": "ビーコンチェーンの観点から見ると、確かにプルーフオブステークで動作しますが、さらに興味深いのはGasperの含まれることです。これは、Casperに関する元のアイデアを修正したものです。Casperは、親しみやすいゴーストファイナリティガジェットとしてしばしば言及され、ノードが不正行為をしたときにネットワークを支援するために導入されました。このCasperのアイデアから、Gasperが現れます。用語にあまり深入りせずに言うと、コンセンサスアルゴリズムは変化し、単純さだけでなく、Polkadotに似たようにより複雑になります。前述のように、PolkadotにはBabeとGrandpaの2つのコンセンサスアルゴリズムがあります。同様に、イーサリアムのビーコンチェーン機能では、コンセンサスとファイナリティを達成することは即座ではありません。エポックが関与し、ネットワークはより複雑なシナリオで動作し、既にいくぶん動的で凍結されておらず、基本的に石に刻まれています。",
  "What can be added in relation to 2024? For me, it was a prolonged observation and an attempt to understand whether Ethereum would eventually implement sharding or not. Sharding is the ability to exist not with a single blockchain but with multiple blockchains within one network. As I observed the merge and the simultaneous rise of Layer 2 (L2) networks, questions arose in my mind about whether sharding would indeed materialize. Sharding seemed interesting to me due to its homogeneity—having multiple chains that are almost identical, lacking any specific characteristics. It appeared to be an interesting approach, but not as flexible as a heterogeneous approach. In L2 networks, even several years ago, I could see the heterogeneity of Ethereum, its ability to work with various types of more specific blockchains. I was curious about the direction it would take—whether sharding, with its homogeneity, would displace L2 solutions or whether L2 solutions with a heterogeneous approach would saturate the Beacon Chain and the main nodes of the Ethereum network.": "2024年に関連して追加できることは何でしょうか？私にとって、イーサリアムが最終的にシャーディングを実装するかどうかを理解しようとする長期的な観察でした。シャーディングとは、1つのネットワーク内に��数のブロックチェーンが存在する能力です。マージと同時にL2（第2層）ネットワークの台頭を目撃しながら、私の心にはシャーディングが実現するかどうかについての疑問が生じました。シャーディングは、ほぼ同一で特定の特性を持たない複数のチェーンを持つことから、均質性によって興味深いと思われました。それは興味深いアプローチのように見えましたが、異質なアプローチほど柔軟ではありませんでした。数年前でも、L2ネットワークでは、イーサリアムの異質性、さまざまな種類のより具体的なブロックチェーンとの連携能力を見ることができました。どのような方向に進むか、シャーディングが均質性を持つことでL2ソリューションを排除するか、異質なアプローチを持つL2ソリューションがビーコンチェーンとイーサリアムネットワークの主要ノードと飽和するかについて興味を持っていました。",
  "Today, in 2024, based on articles on ethereum.org, it seems that sharding as a concept has been pushed back, and the focus is on helping various L2 networks integrate with the Beacon Chain and align with the main chain's functionality, which is now divided into two elements in the Ethereum network's architecture.": "2024年の今日、ethereum.orgの記事に基づくと、シャーディングという概念は後退し、さまざまなL2ネットワークがビーコンチェーンと統合し、メインチェーンの機能と一致するように支援することに焦���が当てられているようです。これは、イーサリアムネットワークアーキテクチャのメインノードが2つの要素に分かれている現在の状況に関連しています。",
  "Therefore, without delving into the details of how L2 networks are structured—although we'll touch upon that when we fill in the second part of the board—we should imagine that Ethereum is now a kind of Beacon Chain, a beacon, a guiding star for numerous L2 networks. These L2 networks can have more specific functionality, executing their logic according to a set of individual functions. This is somewhat in line with the idea of a Swiss Army knife—not making Ethereum a Swiss Army knife, but L2 networks are starting to differentiate in architecture. They duplicate the functionality of the abstract computing machine of Ethereum but perform it with lower gas costs or within their specific segment. Some are already thinking about tuning and making their L2 layer more efficient, focusing on specific functional capabilities. Thus, in my opinion, we are witnessing the emergence of heterogeneity in the world computer that aimed to be homogeneous. Also, it's essential not to forget that decentralized applications (dApps) still exist within the main blockchain, within that same blockchain that started in 2015. This means that during the merge, during the transition to the new architectural state, there was no wipeout, no erasure of the previous history. All decentralized applications and smart contracts underlying these applications continued to exist, and they continue to exist today, and probably tomorrow. This is a question that we will explore using Polkadot as an example, but there is still a feeling that it will be possible to settle a decentralized application in the Beacon Chain—dApps.": "したがって、L2ネットワークがどのように構築されているかの詳細に踏み込むことなく、（ただし、ボードの2番目の部分を埋める際にそれに触れるでしょう）、Ethereumは今やビーコンチェーン、ビーコン、多くのL2ネットワークのための導く星のような存在と想像すべきです。これらのL2ネットワークは、個々の機能に従ってそのロジックを実行するより具体的な機能を持つことができます。これはスイスアーミーナイフのアイデアとやや一致していますが、Ethereumをスイスアーミーナイフにするのではなく、L2ネットワークはアーキテクチャで異なる方向に進み始めています。彼らはEthereumの抽象的なコンピューティングマシンの機能を複製しますが、それをより低いガスコストで実行するか、またはそれらの特定のセグメント内で実行します。一部の人々はすでに、L2レイヤーを調整し、より効率的にすることを考えており、特定の機能的な能力に焦点を当てています。したがって、私の意見では、均質であることを目指していた世界コンピュー���ーに異質性が現れているのを目撃していると思います。また、分散型アプリケーション（dApps）がまだ主要なブロックチェーン内に存在していることを忘れないでください、2015年に始まった同じブロックチェーン内に存在しています。これは、マージ中、新しいアーキテクチャ状態への移行中に、以前の履歴が消去されることなく、消去されることなく、すべての分散型アプリケーションとそれらのアプリケーションの基礎となるスマートコントラクトが継続して存在し続け、おそらく明日も存在し続けるということを意味します。これは、Polkadotを例にして探求する質問ですが、分散型アプリケーションをビーコンチェーンに収めることが可能になるという感覚がまだあります。",
  "In summary, let's imagine the engineering implementation of today's Ethereum as a world computer. We have each network node consisting of two parts. The first layer is responsible for the Ethereum Virtual Machine (EVM), the actual functionality of the virtual machine or Turing complete machine, if we talk in theoretical terms. Perhaps we will see the emergence of alternatives to the virtual machine designed in 2015. These alternatives will likely surpass it in terms of more abstract programming possibilities than writing smart contracts in Solidity. Meanwhile, smart contracts in Solidity continue to feel comfortable. If you want to write functionality for the Ethereum main chain without creating any infrastructure on top of Ethereum, without offloading any calculations to make them cheaper, and so on, decentralized applications that you can write as smart contracts can still be housed in Ethereum's main blockchain. At the same time, Beacon Chain functionality has emerged, separating the consensus logic between validators from the main protocol of the computing machine. This allows for additional flexibility in how consensus should work and how it should be further modified without affecting the virtual machine itself. The example of Shanghai and Defcon 2, where a small opcode error caused a shutdown of part of the infrastructure, hints that it would be good to have such complex functionalities separated into two parts.": "要するに、今日のEthereumのエンジニアリング実装を世界コンピューターとして想像してみましょう。各ネットワークノードは2つの部分で構成されています。最初のレイヤーはEthereum仮想マシン（EVM）を担当し、実際の機能、つまり仮想マシンまたはチューリング完全マシンの機能を担当しています。おそらく、2015年に設計された仮���マシンの代替が登場することが見込まれます。これらの代替は、Solidityでスマートコントラクトを記述するよりもより抽象的なプログラミング可能性においてそれを上回る可能性があります。一方で、Solidityでスマートコントラクトを記述することは引き続き快適に感じられます。Ethereumのメインチェーンの上にインフラを作成せずにEthereumのための機能を記述したい場合、計算をオフロードすることなく、など、引き続きEthereumのメインブロックチェーンに収めることができる分散型アプリケーションがあります。同時に、ビーコンチェーンの機能が登場し、検証者間のコンセンサスロジックをコンピューティングマシンのメインプロトコルから分離しています。これにより、コンセンサスがどのように機能すべきか、どのようにさらに変更すべきかについての柔軟性が追加され、仮想マシン自体に影響を与えることなく変更できます。小さなオペコードエラーが一部のインフラのシャットダウンを引き起こした上海とDefcon 2の例から、このような複雑な機能を2つの部分に分けることが良いことであることを示唆し���います。",
  "What's interesting about the Beacon Chain? It is a more complex, comprehensive algorithm for achieving network synchronicity and finalization with the introduction of concepts such as \"epoch,\" and the presence of a ghost living within the network.": "ビーコンチェーンについて興味深いのは何でしょうか？それは、\"エポック\"などの概念を導入してネットワークの同期性と最終化を達成するためのより複雑で包括的なアルゴリズムです。",
  "Lastly, what is important to consider now is that Ethereum is effectively putting an end to homogeneity, to the idea of getting a hundred identical blockchains working with the same virtual machine, where smart contracts written in Solidity can reside. Instead, various projects are proposing their own architectures or the same virtual machine taken beyond the main blockchain's limits. Alternatively, they are trying to build their more specific application, which, at the level of the Beacon Chain's main chain, is a smart contract written in Solidity. This is the current representation of Ethereum, which did not become Ethereum 2.0. It remains the same Ethereum—a project that once started with proof of work + Turing complete machine, transforming into this architecture.": "最後に、今考慮すべき重要な点は、Ethereumが均質性、すなわち同じ仮想マシンで動作する100個の同一のブロックチェーンを取得するという考えを実質的に終了させていることです。Solidityで書かれたスマートコントラクトが存在できるブロックチェーン内で、代わりに、さまざまなプロジェクトが独自のアーキテクチャを提案しているか、メインブロックチェーンの限界を超えた同じ仮想マシンを取り上げています。または、ビーコンチェーンのメインチェーンのレベルで、Solidityで書かれたスマートコントラクトがある特定のアプリケーションを構築しようとしています。これが、Ethereumの現在の表現であり、Ethereum 2.0にはならなかったものです。それは同じEthereumです—プルーフオブワーク+チューリング完全マシンで始まり、このアーキテクチャに変換されました。",
  "Now, let's take a look at how Polkadot emerged and evolved over the last 5 years. Polkadot came into existence five years after Ethereum, born out of the team that developed one of the best clients for Ethereum—Parity. Many might remember their web client, which, compared to Geth and other implementations, was probably much more pleasant to work with, at least from personal experience and the experience of colleagues.": "今、Polkadotが過去5年間にどのように出現し進化してきたかを見てみましょう。 Polkadotは、Ethereumの5年後に存在し、Ethereumの最高のクライアントの1つを開発したチームによって生まれました。多くの人は、Gethや他の実装と比較して、少なくとも個人の経験や同僚の経験からすると、おそらくParityのWebクライアントがはるかに使いやすかったことを覚えているかもしれません。",
  "In the end, after a couple of months of the relay chain's existence without any decentralized application functionality, without the ability to connect your parachain or L2 network, without user capabilities, the network transitioned from an authority state to proof of stake. This gave developers the ability to upload their runtimes.": "最終的に、リレーチェーンが分散型アプリケーション機能なしで存在し、パラチェーンやL2ネットワークを接続する能力なし、ユーザー機能なしの数ヶ月後、ネットワークは権威の状態からステークの証明に移行しました。これにより、開発者はランタイムをアップロードする能力を得ました。",
  "At this point, it's also interesting to discuss the differences between today's Ethereum and how the central part of Polkadot is structured. From the perspective of the heart, which we've already discussed, the picture will be absolutely the same not only for Ethereum and Polkadot but for any project that wants to be presented as an abstract computing machine. However, from an engineering and architectural standpoint, it's fascinating to observe Beacon Chain & Relay Chain. Here, we have a virtual machine, which has been inherited since 2015, but alternatives are being proposed. In the relay chain, there's the ability to upload your runtime. The runtime is, in fact, your virtual machine. For example, some parachains completely emulate the Ethereum Virtual Machine. It's written as a runtime, meaning you can essentially upload an Ethereum Virtual Machine analog to the parachain level in Polkadot or write more specific logic that works with four or five functions. Recall part one about the ideas— you can write your Swiss Army knife, but it won't require creating the entire infrastructure. You can implement specific functionality with certain functions at the runtime level, put it into the Polkadot relay chain, and the immutability of this runtime will be ensured by Polkadot validators.": "この時点で、今日のEthereumとPolkadotの中心部の構造の違いについても興味深いです。すでに議論した中心部の観点からは、EthereumとPolkadotだけでなく、抽象的な計算機として提示されたいかなるプロジェクトに対しても、絵はまったく同じになります。ただし、エンジニアリングと建築の観点からは、ビーコンチェーン＆リレーチェーンを観察することが魅力的です。ここでは、2015年以来引き継がれてきた仮想マシンがありますが、代替案が提案されています。リレーチェーンでは、ランタイムをアップロードする能力があります。ランタイムは実際にはあなたの仮想マシンです。たとえば、一部のパラチェーンは完全にEthereum仮想マシンをエミュレートしています。ランタイムとして書かれており、基本的にはPolkadotのパラチェーンレベルにEthereum仮想マシンのアナログをアップロードしたり、4つまたは5つの機能で動作するより具体的なロジックを書いたりすることができます。アイデアに関する第1部を思い出してください—あなたはスイスアーミーナイフを書くことができますが、全体のインフラを作成する必要はありません。ランタイムレベルで特定の機能を実装し、それをPolkadotリレーチェーンに配置し、このランタイムの不変性はPolkadotの検証者によって確保されます。",
  "What happens next? Over the course of about a year, a layer of parachains begins to form around the relay chain. In terms of Ethereum implementation, you could say that L2 networks are quite similar to parachains. However, there's one interesting cross-network distinction that I find fascinating in Polkadot, and I'm trying to further understand how it will develop—namely, the second layer of validation and data availability checks. After a couple of years, Polkadot takes a shape like this. It's not just a relay chain where proof-of-stake validators protect the runtime of future parachains; an additional and crucial layer of data validation and availability checking emerges from parachains.": "次に何が起こるのか？約1年の間に、リレーチェーンの周りにパラチェーンの層が形成され始めます。イーサリアムの実装に関しては、L2ネットワークはパラチェーンと非常に似ていると言えます。ただし、ポルカドットで興味深いクロスネットワークの違いが1つあり、それは私が魅力的だと思う第2層の検証とデータの可用性チェックです。数年後、ポルカドットはこのような形になります。これは単なるリレーチェーンではなく、プルーフ・オブ・ステークの検証者が将来のパラチェーンのランタイムを保護するリレーチェーンだけではありません。パラチェーンからデータの検証と可用性チェックの追加および重要な層が現れます。",
  "As you look at this diagram, try to notice the analogies that arise and the differences in engineering implementation details. So, what does this represent, and how does this scheme compare with Ethereum? We have an L2 project, in this case, with Polkadot, it's a parachain. A parachain also generates information blocks, which then go to the relay chain to be combined and release a relay chain block as the sum of all headers, headers, and more headers. The parachain collects transactions in a block using collators, which are not involved in validation. They don't stake anything in the relay chain; they only use the runtime, which is in the relay chain. They fetch it, apply it to transactions, perform necessary state transitions, form a block, and, crucially, provide proof of validity—a stamp containing cryptographic proofs that the collator correctly assembled the block. This information goes to the external validation ring of the relay chain. In this ring, there are internal validators of Polkadot—parachain collators. Again, they don't stake anything directly from the relay chain's point of view. Parachain implementations sometimes introduce their consensus among collators, and some don't. For example, in Robonomics, implementing a parachain, we find this paradigm more interesting, less burdensome, and it makes the network simpler while still remaining functionally substantial. Any collator, without reaching consensus with anyone—verified by us—can propose a block and some proof to the external layer. This is precisely why blocks are proposed, proofs of block assembly validity are offered, and there's an external ring. We don't need any consensus from parachain validators. Anyone can generate a block and send it, and if this node of the collator sends incorrect information to the parachain validators on the external ring, the validator at this level will reject it. It won't pass into the central part. But let's say the block was provided correctly by the collator. Our transactions got in; the collator calculated them, applying the runtime stored in the relay chain, executed all state transitions, gathered some proof of validity—validity of the assembled block—and passed it to the external ring of the relay chain. Here, every epoch, which is also part of the finalization, every epoch has validators from the relay chain diverging into parachains. Some of them stay in the center, and the others go to parachains. Their number ranges from 16 to 64 validators, and this figure, I believe, will change in the specification—somewhere more, somewhere less. However, parachain validators re-verify the information from one selected group of validators about everything coming from the collator being correct, that work has been done in accordance with the runtime, and that the proof of validity is indeed valid. The selected segment of relay chain validators who already have something staked respond, or rather, chirp among themselves. They respond to the chosen main block producer of the parachain, so to speak, saying,": "この図を見る際に、生じる類推やエンジニアリングの実装の詳細における違いに注意してみてください。では、これは何を表しており、このスキームはイーサリアムと比較してどのようなものでしょうか？この場合、ポルカドットのようなL2プロジェクトはパラチェーンです。パラチェーンは情報ブロックを生成し、それがリレーチェーンに送られて結合され、すべてのヘッダー、ヘッダー、およびさらにヘッダーの合計としてリレーチェーンブロックがリリースされます。パラチェーンはコレーターを使用してブロック内のトランザクションを収集し、検証には関与しません。彼らはリレーチェーンに何もステークせず、ランタイムのみを使用します。それを取得し、トランザクションに適用し、必要な状態遷移を実行し、ブロックを形成し、そして重要なことに、ブロックを正しく組み立てたことを示す暗号証明を含むスタンプである有効性の証明を提供します。この情報はリレーチェーンの外部検証リングに送られます。このリングには、ポルカドットの内部検証者であるパラチェーンコレーターがいます。再び、彼らはリレーチェーンの観点から直接何もステークしません。パラチェーンの実装によっては、コレーター間での合意を導入するものもあれば、導入しないものもあります。たとえば、パラチェーンを実装するRobonomicsでは、このパラダイムをより興味深く、負担が少なく、ネットワークをよりシンプルに保ちながら機能的に重要なものにしています。誰もが誰かと合意に達することなく、私たちが検証した上で、ブロックといくつかの証拠を外部層に提案できます。これがブロックが提案され、ブロックの組み立ての有効性の証明が提供され、外部リングがある理由です。パラチェーンの検証者から合意を得る必要はありません。誰もがブロックを生成して送信できます。そして、もしコレーターのノードが外部リングのパラチェーン検証者に誤った情報を送信した場合、このレベルの検証者はそれを拒否します。それは中央部分には通過しません。しかし、仮にコレーターが正しくブロックを提供したとしましょう。私たちのトランザクションが含まれ、コレーターがそれを計算し、リレーチェーンに保存されているランタイムを適用し、すべての状態遷移を実行し、有効性の証明、すなわち組み立てられたブロックの有効性の証明を収集し、それをリレーチェーンの外部リングに渡します。ここでは、各エポックごとに、最終化の一部として、リレーチェーンの検証者がパラチェーンに分岐します。彼らの一部���中央に留まり、他の一部はパラチェーンに移動します。彼らの数は16から64の検証者に及び、この数字は仕様で変更されると信じています。どこかではもっと、どこかではもっと少なくなります。ただし、パラチェーンの検証者は、コレーターからのすべての情報が正しいことを選択された検証者グループから再検証し、ランタイムに従って作業が行われ、有効性の証明が実際に有効であることを確認します。すでにステークしているリレーチェーンの選択されたセグメントの検証者は、選択された主要なパラチェーンのブロックプロデューサーに対して、いわば、",
  "\"Yes, we agree. There are no problems. You can carry it through the entire external ring inside.\"": "“「はい、同意します。問題はありません。全体の外部リング内でそれを運ぶことができます。”",
  "And thus, almost all information formed on the parachain collators, with verification on the external ring, enters the internal one. The lower part, not that it's physically at the bottom, still constitutes the external ring—data availability. Data starts to be checked at this stage, meaning that on the external ring, not only the correctness of block assembly is verified, but the process of preparing for distribution within the Polkadot network begins, ensuring that the block information will not be lost in the future. Here, precisely, is what I mentioned in the second part about chunks, like CD RW. At this stage of block preparation for transfer to the internal ring, the data availability layer is formed as a service, something that is currently also attempted by some projects in Ethereum. Some projects put additional redundant information directly into smart contracts, necessary for checking what is happening on the L2 layer and, if necessary, slashing or punishing those who did it incorrectly. It's impossible to overcome the external ring without distributing block information and without rechecking dozens of nodes with stakes laid down on the assumption that the runtime must work correctly.": "そして、そのため、パラチェーンコレーターで形成されたほとんどの情報は、外部リングで検証され、内部リングに入ります。下部は、物理的に底にあるわけではないが、依然として外部リング、つまりデータの可用性を構成しています。この段階でデータのチェックが始まり、外部リングでは、ブロックの組み立ての正確性だけでなく、Polkadotネットワーク内での配布の準備プロセスも開始され、ブロック情報が将来失われないように保証されます。ここで、第2部でCD RWのようなチャンクについて言及したのが正確です。内部リングへの転送のためのブロックの準備段階では、データの可用性レイヤーがサービスとして形成され、現在、Ethereumの一部のプロジェクトでも試みられています。一部のプロジェクトは、L2レイヤーで何が起こっているかを確認し、必要に応じて間違って行った人をスラッシュしたり罰したりするために、スマートコントラクトに余分な冗長情報を直接入れます。ランタイムが正しく動作するという前提でステークを置���た数十のノードを再確認せずに、ブロック情報を配布せずに外部リングを超えることは不可能です。",
  "Thus, information that has passed through the external ring is already quite trustworthy, probably yes, you can say that, and on the internal ring, work is mainly done not with parachain blocks, but their block headers are collected into one big header. That is, from many headers, one header of a relay chain block is assembled—a mechanism of linking in Shared Security, as mentioned in Polkadot, which ensures the security of parachains. One could say that parachains are validated and reach a state where the service exists in a distributed decentralized form on the external ring. In the internal ring, the information that has entered attempts to come together in one hyperblock, which should precisely link everything together. There are no calculations happening there; there is no recalculation of absolutely everything. The assembly of the final block takes place, so to speak, in the current iteration of the world computer, to put a point on the question of whether the transaction has passed in a particular parachain. We must assemble a hyperblock that contains not all the information from the parachains but gathers all the headers verified on the external ring of parachains into one large block. And thus, our world computer in Polkadot operates.": "したがって、外部リングを通過した情報はすでにかなり信頼できると言えるでしょう、おそらくは、そして内部リングでは、パラチェーンブロックではなく、そのブロックヘッダーが1つの大きなヘッダーに収集されます。つまり、多くのヘッダーから、リレーチェーンブロックの1つのヘッダーが組み立てられます。これは、Polkadotで言及されているShared Securityにおけるリンクのメカニズムであり、パラチェーンのセキュリティを保証します。パラチェーンは検証され、外部リングで分散分散形式でサービスが存在する状態に達します。内部リングでは、入力された情報が1つのハイパーブロックにまとまろうとしますが、それはすべてを正確にリンクさせるべきです。そこでは計算は行われません。すべてを再計算するわけではありません。最終ブロックの組み立てが行われ、いわば、世界コンピューターの現在のイテレーションで、特定のパラチェーンでトランザクションが通過したかどうかの問題にピリオ���を打つために、ハイパーブロックを組み立てる必要があります。パラチェーンからのすべての情報を含むのではなく、パラチェーンの外部リングで検証されたすべてのヘッダーを1つの大きなブロックに集めます。そして、これにより、Polkadotの世界コンピューターが動作します。",
  "Let's take another look at these two schemes together: relay chain, beacon chain, runtime, secured by proof of stake, where someone stakes their funds to validate that they will always perform their work correctly. There's a virtual machine where you can also stake your funds, and if you perform any computation or state transition not in accordance with the Ethereum Virtual Machine's specification, you'll be penalized.": "これらの2つのスキームを一緒に見直してみましょう：リレーチェーン、ビーコンチェーン、ランタイム、プルーフ・オブ・ステークによって保護され、誰かが自分の資金を賭けて、常に正しく作業を行うことを検証する。仮想マシンもあり、資金を賭けることができ、イーサリアム仮想マシンの仕様に準拠しない計算や状態遷移を行うと、罰せられます。",
  "In Polkadot, there's an additional external layer, which seems to be one of the main advantages, such pleasant perks of the engineering implementation that, in my opinion, should be present here. It should appear between L2 networks and the beacon chain, which exists in Ethereum. By the way, some say that the term \"beacon chain\" is dying out again and is misunderstood, but I really like to use it in analogy with the \"relay chain,\" a term from Ethereum's roadmap.": "Polkadotには、主要な利点の1つである追加の外部レイヤーがあります。エンジニアリングの実装の快適な特典があり、私の意見ではここに存在すべきです。これは、L2ネットワークとイーサリアムに存在するビーコンチェーンの間に現れるべきです。ちなみに、「ビーコンチェーン」という用語は再び消えて誤解されていると言う人もいますが、私は本当に「リレーチェーン」という用語とアナロジーを用いるのが好きです。これは、イーサリアムのロードマップからの用語です。",
  "And perhaps one more interesting story in this part of the lecture: so far, we can hardly imagine proper cross-chain messages between L2 networks in Ethereum. Maybe I missed something in the papers, but when you don't have an external ring and issues like collators, paravalidators, and data availability services are not resolved, thinking about how two L2 layers can communicate is challenging. Yet, in Polkadot, it exists. Even horizontally, through the relay chain, meaning directly, one can send a transaction securely from one parachain to another, without trusting any bridges between these two parachains. This is another crucial functionality that will likely need to be implemented at the level of connecting L2 networks. Smart contracts in Ethereum communicate well. We have created many chains of linked smart contracts, where one triggers another. With this, there is no problem. But when we say that almost all applications are moving to the L2 layer in a heterogeneous network, I hear that if you live in a specific area, you won't be able to get out. That's not the case at the level of parachains and implementation in Polkadot. Both architectures are worth watching, as, in my opinion, the engineering implementation follows the mainstream path of becoming a global computer. They differ slightly, but there are many similarities. There's an enormous amount of engineering work everywhere. As we see, human civilization, in the form of a multitude of researchers, engineers, and growing developers with significant resources for further development, is moving roughly in the same direction from the smallest early stage to probably some future establishment of the world's computer, all on the same tracks.": "そして、この講義のこの部分でもう1つ興味深い話があるかもしれません：これまでに、イーサリアムのL2ネットワーク間で適切なクロスチェーンメッセージを想像するのはほとんど不可能です。論文で何か見落としたかもしれませんが、外部リングがない場合やコレータ、パラバリデータ、データ可用性サービスなどの問題が解決されていない場合、2つのL2レイヤーがどのように通信できるか考えることは難しいです。しかし、Polkadotではそれが存在します。リレーチェーンを介して水平に、つまり直接、1つのパラチェーンから別のパラチェーンに安全にトランザクションを送信できます。これにより、これら2つのパラチェーン間に信頼できるブリッジがなくても、重要な機能が実装される可能性が高いです。イーサリアムのスマートコントラクトはうまく通信します。私たちは、1つが別のものをトリガーするリンクされたスマートコントラクトの多くのチェーンを作成しました。これにより、問題はありません。しかし、ほぼすべてのアプリ��ーションが異種ネットワークのL2レイヤーに移行していると言うとき、特定の地域に住んでいる場合、出られないと聞きます。これはパラチェーンやPolkadotでの実装のレベルではそうではありません。両方のアーキテクチャは注目に値します。私の意見では、エンジニアリングの実装は世界的なコンピュータになるための主流の道をたどっています。わずかに異なりますが、多くの類似点があります。どこでも膨大な量のエンジニアリング作業が行われています。我々が見るように、多くの研究者、エンジニア、そして将来の世界のコンピュータの確立に向けて重要なリソースを持つ開発者が、おおよそ同じ方向に向かって移動しています。",
  "Part 1: The Idea of a World Computer": "第1部：世界コンピューターのアイデア",
  "This is the first part of a four-part lecture titled \"World Computer in Your Home.\" In the first part, titled \"The Idea of a World Computer,\" I want to analyze and share my own reflections that have, in a broader historical context, gathered around the hashtag \"world computer.\"": "これは「あなたの家に世界コンピューター」と題された4部作の講義の第1部です。第1部「世界コンピューターのアイデア」では、広い歴史的文脈の中で「世界コンピューター」というハッシュタグを中心に集まった私自身の考えを分析し共有したいと思います。",
  "To begin with, let's try to gather a generalized understanding of what a world computer is, without delving into terminology or specific technical details. If you take your mobile phone in hand and look at the icons, you can notice that practically every application on the phone has two major segments or areas of operation.": "まずは、用語や具体的な技術的詳細には踏み込まず、世界コンピューターとは何かを一般的に理解しようとしてみましょう。携帯電話を手に取り、アイコンを見ると、携帯電話のほとんどのアプリケーションが2つの主要なセグメントや操作領域を持っていることに気づくでしょう。",
  "The first is the local part, meaning, for example, your calculator or notes application. This is a completely local application that requires almost no external communication. Although even applications like the notes app on an iPhone are a bit more than that, let's focus on the more austere Open Source side of applications for Android phones, so to speak.": "1つ目はローカルパートで、たとえば、電卓やメモアプリケーションです。これはほとんど外部との通信を必要としない完全にローカルなアプリケーションです。iPhoneのメモアプリなどのアプリケーションでもそれ以上のものですが、Android携帯電話向けのより質素なオープンソース側のアプリケーションに焦点を当てましょう。",
  "The second part requires cloud infrastructure, and here, when the question of cloud infrastructure arises, a multitude of quite complex stories begins: who owns this cloud infrastructure, what capabilities do developers have to add features to an application, and in general, how does the user own this application? What capabilities and responsibilities does the user have when dealing with an application that exists not only on their phone but also in some infrastructure beyond their pocket or palm? The world computer is precisely one example of how the developer community responds to these obvious questions. Obvious questions about creating higher-quality applications for your mobile phone, laptop, server, and any other smart device that needs to connect to the network and obtain knowledge from there.": "2つ目はクラウドインフラストラクチャを必要とし、ここでクラウドインフラストラクチャの問題が浮上すると、かなり複雑なストーリーが始まります。このクラウドインフラストラクチャを所有しているのは誰か、開発者はアプリケーションに機能を追加する権限を持っているのか、そして一般的にユーザーはこのアプリケーションをどのように所有するのか？ユーザーが自分の携帯電話だけでなく、ポケットや手の届かないインフラストラクチャにも存在するアプリケーションを扱う際に、ユーザーはどのような機能と責任を持つのでしょうか？世界コンピューターは、開発者コミュニティがこれらの明らかな問いにどのように応えるかの一例です。モバイル電話、ノートパソコン、サーバー、およびネットワークに接続してそこから知識を得る必要がある他のスマートデバイス向けにより高品質なアプリケーションを作成するための明らかな問いについての一例です。",
  "The world computer is, accordingly, the same cloud, the same infrastructure that exists on the internet, with which developers can interact and publish their applications. As a user, you can install, download, and run them on your PC. However, with one interesting, crucial feature: no one actually owns the infrastructure or cloud of the world computer. There is no specific company, jurisdiction, or individual on Earth who can determine and say whether you can publish your application there or not, whether you have the right to access this world computer infrastructure to receive the provided service. Therefore, the world computer is a cloud in which any developer can place their application, and any user with access solely to the internet network and not to a specific IP address behind a firewall can use the application by paying for computations from their pocket.": "世界コンピューターは、インターネット上に存在する同じクラウド、同じインフラストラクチャであり、開発者がインタラクションを行い、アプリケーションを公開できるものです。ユーザーとして、PCにインストールし、ダウンロードし、実行することができます。ただし、興味深く、重要な機能が1つあります：実際には誰も世界コンピューターのインフラストラクチャやクラウドを所有していません。世界コンピューターにアプリケーションを公開できるかどうか、この世界コンピューターインフラストラクチャにアクセスする権利があるかどうかを決定し、言うことができる特定の企業、管轄区域、または地球上の個人は存在しません。したがって、世界コンピューターは、どの開発者も自分のアプリケーションを配置できるクラウドであり、インターネットネットワークにのみアクセス権があり、ファイアウォールの背後に特定のIPアドレスにアクセスできないユーザーは、自分のポケットから計算を支払うことでアプリケーションを使���できます。",
  "Here's the story in a generalized format. There is no mention of \"blockchain,\" no mention of \"smart contracts,\" but these concepts are underneath. Let's still acknowledge: a world computer is a cloud infrastructure that is sovereign, owned by no one, allowing each developer to avoid censorship from platform owners offering app downloads. It also prevents users from being in a situation where they don't understand how an app works on their phone. In my opinion, these are important and cool features deserving respect and attention from those who want to create more futuristic, cooler applications. This is precisely what my team and I have been doing for eight years, choosing perhaps the most challenging area - creating services for robotics on the world computer, which seems to be right outside your door, quietly scraping and saying, \"I want to come into your home.\"": "一般化された形式で物語を紹介します。\"ブロックチェーン\"や\"スマートコントラクト\"の言及はありませんが、これらの概念はその下にあります。それでも認識しましょう：世界コンピューターは、誰も所有していない主権を持つクラウドインフラストラクチャであり、各開発者がアプリのダウンロードを提供するプラットフォーム所有者からの検閲を回避できるようにします。また、ユーザーが自分の電話でアプリがどのように動作するか理解できない状況に陥ることを防ぎます。私の意見では、これらは重要でクールな機能であり、より未来志向でクールなアプリケーションを作りたい人々から尊敬と注目を受けるべきです。これが私と私のチームが8年間取り組んできたことであり、おそらく最も困難な分野を選択しています - 世界コンピューター上のロボティクス向けのサービスを作成しています。それはあなたのドアの外に正確にあるようで、静かにこすりつけて、「あなたの家に入りたい」と言っています。",
  "Now, let's move on to a timeline and look through my personal experience at how the concept of the world computer evolved. First, let's go back to 2012. This year is notable because Bitcoin already exists as a global internet service, accessible to everyone, not owned by anyone specific. By 2012, besides Bitcoin, its so-called forks start appearing. One of the most well-known is Litecoin.": "さて、タイムラインに移り、世界コンピューターの概念がどのよう��進化したかを私の個人的な経験を通して見てみましょう。まず、2012年にさかのぼりましょう。この年は注目すべき年です。なぜなら、ビットコインはすでにグローバルなインターネットサービスとして存在し、誰でもアクセスでき、特定の誰かの所有物ではないからです。2012年までに、ビットコイン以外にも、そのいわゆるフォークが現れ始めます。最もよく知られているのはLitecoinです。",
  "Litecoin is notable because its developer did the most important work for the entire community. He collected the most crucial configurable variables or constants from different parts of Bitcoin's code after the protocol was launched. This allowed specifying block generation time, block reward, and, statistically, Litecoin is more frequently forked than Bitcoin. When we say \"fork of Bitcoin,\" I can confidently say that, in most cases, it will be a fork of Litecoin.": "Litecoinは注目すべきです。その開発者は、プロトコルが立ち上がった後、ビットコインのコードのさまざまな部分から最も重要な設定可能な変数や定数を収集しました。これにより、ブロック生成時間、ブロック報酬を指定でき、統計的にはLitecoinはビットコインよりも頻繁にフォークされています。私たちが「ビットコインのフォーク」と言うとき、ほとんどの場合、それはLitecoinのフォークであると自信を持って言えます。",
  "Namecoin is also a fork of Bitcoin, and if memory serves me right, it was initially a direct fork from Bitcoin, and then Litecoin appeared a few months later in 2011. However, Namecoin turned out to be a bit different, paving the way for many developers mentally on where ideas underlying Bitcoin's internet service could evolve. Namecoin went beyond being just a coin; it could store identity as a database and allow an internet service to place your domain name. This was the first example where an internet service spawned from Bitcoin could have a different nature, not just like Litecoin with fast transactions but the ability to pay for storing certain information with its internal currency, an internal token. For example, the name in the .bit domain zone.": "NamecoinはBitcoinのフォークでもあり、記憶が正しければ、最初はBitcoinから直接フォークされ、その後2011年に数ヶ月後にLitecoinが登場しました。しかし、Namecoinは少し異なることがわかり、Bitcoinのインターネットサービスの基本的なアイデアがどのように進化するかについて多くの開発者に影響を与えました。Namecoinは単なるコインにとどまらず、データベースとしてアイデンティティを保存し、インターネットサービスがあなたのドメイン名を配置することができました。これは、Bitcoinから派生したインターネットサービスが異なる性質を持つ可能性がある最初の例であり、Litecoinのような高速トランザクションだけでなく、内部通貨、内部トークンで特定の情報の保存に支払う能力があることを示しました。例えば、.bitドメインゾーンの名前。",
  "Developers worldwide were experimenting with Bitcoin, mostly creating forks, making them faster, cheaper electronic cash. Alongside this, the first services appeared, seeing opportunities not only in financial applications but also in cross-industrial applications in other areas like Namecoin. Namecoin provided the first globally accessible and unowned internet service through which you could launch your website without being under the jurisdiction of a specific organization but within a distributed globally accessible network. This moment is crucial for us to move on to the early precursors of the world computer's ideas.": "世界中の開発者はBitcoinで実験を行っており、主にフォークを作成し、それらをより速く、安価な電子現金にしています。これに伴い、最初のサービスが登場し、金融アプリケーションだけでなく、Namecoinのような他の分野での業界間アプリケーションにも機会が見出されました。Namecoinは、特定の組織の管轄下になることなく、分散された世界的にアクセス可能なネットワーク内でウェブサイトを立ち上げることができる最初の世界的にアクセス可能で所有権のないインターネットサービスを提供しました。この瞬間は、私たちが世界コンピュータのアイデアの初期の前兆に進むために重要です。",
  "The first practical ideas of the world computer emerged in 2014, two years after the appearance of the first wave of Bitcoin forks and the creation of meaningful services dedicated not only to electronic cash but also exploring broader themes. We encounter ideas that precede the launch of Ethereum.": "世界コンピュータの最初の実用的なアイデアは、2014年に登場しました。これは、最初のBitcoinフォークの波と、電子現金だけでなく、より広いテーマを探求する意義あるサービスの創設の2年後です。私たちは、Ethereumの立ち上げの前に出現するアイデアに出会います。",
  "In 2014, at several meetups worldwide, in Miami and, I believe, in Europe, Vitalik Buterin articulated sensible ideas. He suggests that we can develop not just a set of internet services that essentially function as a Swiss army knife, right? We can develop a virtual machine. Those with an education in Computer Science probably remember what an infinite tape is in Turing machines, and if we go back to the theory of computational machines, we probably recall the theoretical origins of creating our personal computers, essentially the server infrastructure we have today. It's interesting that, fifty years after the development of von Neumann architecture and the complete Turing machine theory, and with the dawn of internet technologies only by 2014, and only after experiments with Bitcoin, the first idea emerges on our planet of creating a fully virtual computational machine based on the same theory that has been tested in the computer science industry for the past 50 years. The mechanics are the same as when creating any personal computer or server in a data center, but based more on achievements in internet technologies and the achievements of the world that will later be called Web3.": "2014年、マイアミやおそらくヨーロッパで、いくつかのミートアップで、Vitalik Buterinが理にかなったアイデアを述べました。彼は、本質的にスイスアーミーナイフとして機能するインターネットサービスのセットだけでなく、仮想マシンを開発できると提案しています。コンピュータサイエンスの教育を受けた人々は、チューリングマシンの無限���ープが何であるかをおそらく覚えており、計算機科学の理論の起源に戻ると、私たちはおそらく、本質的には今日持っているサーバーインフラストラクチャー、つまり私たちの個人用コンピュータを作成する理論的な起源を思い出すでしょう。興味深いことに、フォン・ノイマンアーキテクチャの開発から50年後、完全なチューリングマシン理論、そして2014年までにインターネット技術の到来と、Bitcoinの実験の後に、私たちの惑星で、過去50年間にコンピュータサイエンス業界でテストされてきた同じ理論に基づいて完全に仮想的な計算機を作成するアイデアが初めて浮かび上がります。メカニクスは、データセンター内の任意の個人用コンピュータやサーバーを作成する際と同じですが、インターネット技術の成果と、後にWeb3と呼ばれる世界の成果に基づいています。",
  "Ethereum itself is not a Swiss army knife, not a set of specific internet services. It is, in the direct sense, a cloud, a computational machine. What lies at its core, I will tell you in the next lecture. Here, the most important thing for us is to focus on where the idea of Ethereum began. It started with the realization that, in two years, dozens of different internet services were invented that were interesting because they were globally accessible, available without censorship for developers to deploy. Users could use them only with an internal currency. However, what was not liked in all these concepts was that almost every interesting service required its own massive distributed infrastructure. Unlike familiar internet services, you couldn't just launch your globally accessible infrastructure if you were a very small person or a small team because such a network would be vulnerable, and the service itself would become unsafe. To overcome the problems that were side effects or negative externalities of creating your own globally accessible sovereign internet service, the concept of Ethereum emerged. Ethereum, as a full-fledged cloud capable of handling any formalized computation, allows you to write your program code, a complete program essentially, and run it in the same blockchain alongside hundreds of other applications. This possibility, sounding from the small stages of 2014, naturally captivated the minds of many and seemed absolutely logical for someone with a basic education in Computer Science. If you could understand what Turing completeness was by 2014, if you could envision the historical theory of creating a personal computer, you would definitely not overlook the Ethereum whitepaper and would say that this is exactly what the entire developer community needs.": "イーサリアム自体はスイス軍ナイフではなく、特定のインターネットサービスのセットでもありません。それは、直接的な意味で、クラウド、計算機です。その核にあるものは、次の講義でお話しします。ここでは、私たちにとって最も重要なことは、イーサリアムのアイデアがどこから始まったかに焦点を当てることです。それは、2年間で、世界中でアクセス可能で、開発者が検閲なしで展開できる興味深い数十の異なるインターネットサービスが発明されたことから始まりました。ユーザーは内部通貨だけでそれらを使用できました。しかし、これらの概念のすべてに好ましくなかったのは、ほとんどの興味深いサービスが独自の大規模な分散インフラストラクチャを必要としたことです。おなじみのインターネットサービスとは異なり、非常に小さな人間や小さなチームであっても、独自の世界的にアクセス可能なインフラストラクチャを立ち上げることはできませんでした。なぜなら、そのようなネットワークは脆弱になり、サービス��体が安全でなくなるからです。独自の世界的にアクセス可能な主権インターネットサービスを作成することの副作用や負の外部性を克服するために、イーサリアムの概念が生まれました。イーサリアムは、任意の形式化された計算を処理できる完全なクラウドとして、あなたがプログラムコードを書き、他の何百ものアプリケーションと同じブロックチェーンで実行できるようにします。この可能性は、2014年の初期段階から響き渡り、多くの人々の心を自然に魅了し、コンピュータサイエンスの基本教育を持つ人にとっては完全に論理的に思えました。2014年までにチューリング完全性が何であるかを理解できたなら、個人用コンピュータを作成する歴史的理論を想像できたなら、イーサリアムのホワイトペーパーを見逃すことはなく、これがまさに開発者コミュニティ全体が必要としているものだと言うでしょう。",
  "I believe the year 2014 and Ethereum mark the first, though not explicitly named, instances of the concept of a global computer. It started with the idea that we don't need a Swiss knife; instead, we need infrastructure or a universal cloud that addresses global-level security challenges. Developers, at a low cost, should be able to deploy their applications there without concerning themselves with issues like securing the network or creating a network of providers for this computer or your specific internet service.": "私は2014年とイーサリアムが、明示的に名前が付けられていないものの、グローバルコンピュータの概念の最初の例を示していると信じています。スイスナイフは必要ない、代わりに、グローバル���ベルのセキュリティ課題に対処するインフラストラクチャや普遍的なクラウドが必要だという考えから始まりました。開発者は低コストでアプリケーションを展開できるべきであり、ネットワークのセキュリティを確保したり、このコンピュータや特定のインターネットサービスのためのプロバイダーネットワークを作成する必要がないようにすべきです。",
  "In 2015, Ethereum was effectively launched. From that moment onwards, even until 2020, I haven't encountered significant counterarguments against the idea of creating not just specific internet services but embracing and developing the concept of a virtual computer, virtual server, cloud, or a global computer, as I prefer to call it.": "2015年、イーサリアムは実質的に立ち上げられました。その時点から2020年まで、私は特定のインターネットサービスだけでなく、仮想コンピュータ、仮想サーバー、クラウド、または私がそれを呼ぶように好むグローバルコンピュータの概念を採用し、開発するというアイデアに対する重要な反論には遭遇していません。",
  "Various variations emerge, perhaps some remember the then-popular EOS suggesting a slightly different consumption paradigm. Despite my personal aversion to that project, with its 21st validator and all, it seemed sufficient for many. But it introduced the idea that owning tokens grants you a portion of bandwidth, which, in the realm of Robonomics architecture, remains interesting to me to this day.": "さまざまなバリエーションが現れ、おそらく一部の人々は、わずかに異なる消費パラダイムを提案した当時人気のあったEOSを覚えているかもしれません。私はそのプロジェクトに個人的な嫌悪感を抱いていますが、21の検証者など、多くの人々には十分だと思われました。しかし、トークンを所有することで帯域幅の一部を得るというアイデアを導入しました。これは、Robonomicsアーキテクチャの領域では、今日まで興味深いものとして残っています。",
  "Simultaneously, other ideas on how to modernize the Ethereum network arise. Projects like Definity, Solana, and others come into play. Around the same time, Gavin Wood introduces Polkadot, who assisted Vitalik in creating Ethereum. From a multitude of technological projects between 2015 and 2020, we move from a race to create individual internet service variants to witnessing, on a communication protocol level, the emergence of something like Ethereum killers. Many projects started under this slogan, taking the idea of a unified cloud for multiple internet services and modifying some aspects. For instance, EOS proposed an alternative utilization scheme, where only token-backed ownership allowed access to bandwidth. There were projects where the programming language for writing code was more interesting. For example, during a hackathon for BMW, when we won with an implementation on Ethereum, the automaker immediately stated that we wouldn't go any further unless we had formally verified contracts, which was impossible to achieve on Ethereum at that time.": "同時に、Ethereumネットワークを近代化するアイデアが他にも浮かび上がってきます。Definity、Solanaなどのプロジェクトが登場します。同じ時期に、Gavin WoodがPolkadotを紹介し、Vitalikを助けてEthereumを作成しました。2015年から2020年までの多くの技術プロジェクトから、個々のインターネットサービスのバリアントを作成する競争から、Ethereumキラーのようなものが通信プロトコルレベルで現れるのを目撃します。多くのプロジェクトがこのスローガンの下で始まり、複数のインターネットサービスのための統一されたクラウドのアイデアを取り入れ、いくつかの側面を変更しました。例えば、EOSは、トークンで裏付けられた所有権のみが帯域幅へのアクセスを許可する代替利用計画を提案しました。コードの記述のためのプログラミング言語がより興味深いプロジェクトもありました。例えば、BMWのハッカソン中に、Ethereum上での実装で勝利した際、自動車メーカーはすぐに、Ethereumではその時点では不可能だった正式に検証された契約がない限り、これ以上進まないと述べました。",
  "At this moment, as you read about the ideas of Eternity and other networks, you may think, \"I should try working with them too.\" Service developers understood this, as did, as I mentioned, projects like Definity, which recently launched the World Computer and is gaining traction. Simultaneously, the idea of Polkadot emerges as a heterogeneous multi-chain framework. Ethereum, around the mid-2010s, also received a roadmap for scalability and development. By 2024, almost all concepts converge on the idea of having not just one database or blockchain but a multitude. Various transaction processing methods, two-layer consensus algorithms, optimistic majority approaches, and a plethora of technical implementation variations emerge, all aiming at the same global computer concept.": "この時点で、Eternityや他のネットワークのアイデアについて読んでいると、「私もそれらと一緒に働いてみるべきだ」と考えるかもしれません。サービス開発者はこれを理解し、最近World Computerを立ち上げ、注目を集めているDefinityなどのプロジェクトも同様です。同時に、異種多様なマルチチェーンフレームワークとしてPolkadotのアイデアが浮かび上がります。2010年代半ば頃、Ethereumもスケーラビリティと開発のためのロードマップを受け取りました。2024年までに、ほぼすべての概念が1つのデータベースやブロックチェーンだけでなく、複数のデータベースやブロックチェーンを持つというアイデアに収束します。さまざまなトランザクション処理方法、2層のコンセンサスアルゴリズム、楽観的多数派アプローチ、さまざまな技術的実装のバリエーションが登場し、すべてが同じグローバルコンピュータのコンセプトを目指しています。",
  "Let's now go through a timeline snapshot:": "ここでタイムラインのスナップショットを見てみましょう。",
  "**2009-2012**: Emergence of the first globally accessible internet service for electronic cash - Bitcoin.": "**2009-2012**：電子キャッシュ用の最初の世界的にアクセス可能なインターネ���トサービスの出現 - Bitcoin。",
  "**Early 2012**: The first fork war occurs, with projects emerging to replicate similar services. Some multi-billion projects create their forks. Simultaneously, projects like Namecoin propose interesting ideas.": "**2012年初頭**：最初のフォーク戦争が発生し、同様のサービスを複製しようとするプロジェクトが登場します。数十億ドル規模のプロジェクトが自分たちのフォークを作成します。同時に、Namecoinのようなプロジェクトが興味深いアイデアを提案します。",
  "**2014**: The concept of a world computer emerges, requiring a deep understanding of computer science theory and immersion in Bitcoin's development.": "**2014年**：コンピュータサイエンス理論の深い理解とBitcoinの開発への没頭が必要とされる、ワールドコンピュータの概念が浮かび上がります。",
  "**2015-2020**: The concept moves from theory to practice. Modifications and variations of Ethereum arise, introducing different ideas with varying degrees of quality. The term \"World Computer\" became established.": "**2015-2020**：概念は理論から実践に移行します。Ethereumの変更とバリエーションが登場し、異なるアイデアが異なる品質で導入されます。\"World Computer\"という用語が確立されました。",
  "**2024**: We reach the World Computer, a term now well-established, marking the transition from a simple calculator on your phone to a globally accessible institution. The idea of the World Computer encompasses future money, programming money, storage for identification records, and important documents.": "**2024年**：私たちは今や確立された用語であるWorld Computerに到達し、単なる電卓からグローバルにアクセス可能な機関への移行を示します。World Computerのアイデアは、将来のお金、プログラミングマネー、識別記録や重要文書の保存を包括しています。",
  "In conclusion, from a simple calculator to a globally accessible institution, the idea of the World Computer has evolved. It's seen as a place for the future of money and the storage of vital records. The concept of a World Computer has progressed from theoretical discussions to practical engineering implementations. In the next lecture, the discussion will delve into what a World Computer actually represents. It is fundamentally a state transition function, a concept to be explored further in the upcoming lecture, emphasizing its importance and the need to safeguard it.": "結論として、単なる電卓からグローバルにアクセス可能な機関へのアイデアであるWorld Computerは進化しています。これは将来のお金や重要記��の保存の場所と見なされています。World Computerの概念は、理論的な議論から実用的なエンジニアリングの実装に進化しました。次回の講義では、World Computerが実際に何を表しているかについて掘り下げます。これは基本的に状態遷移関数であり、その重要性と保護の必要性を強調する今後の講義でさらに探求されるべき概念です。",
  "Part 2: The Heart of the World Computer": "第2部：世界コンピューターの核心",
  "What lies at the core of projects like Ethereum or Polkadot, or any other web3 project claiming the title of the world computer, and why does the comparison with the heart in the human body fit so well into the abstract architecture of the world computer?": "EthereumやPolkadotなどのプロジェクトの中核には何があり、なぜ世界コンピューターとしての称号を持つ他のweb3プロジェクトと人体の心臓との比較が世界コンピューターの抽象的なアーキテクチャに非常に適しているのでしょうか？",
  "Let's try to understand these questions in this part of the lecture, and to begin with, we'll have to break the chains of Bitcoin maximalists a bit. Most likely, you've already read one or several popular science articles dedicated to Bitcoin in your life, and the main thing that is practically noted everywhere is the three main advantages of Bitcoin as electronic cash:": "この講義のこの部分でこれらの問いを理解しようとしてみましょう。まず、Bitcoinマキシマリストの枷を少し解かなければなりません。おそらく、あなたは人生で1つまたは複数の人気のある科学記事を読んだことがあり、Bitcoinに関するもので、ほとんどの場所でBitcoinの電子キャッシュとしての3つの主要な利点が実質的に指摘されていることがほとんどです：",
  "Censorship resistance": "検閲耐性",
  "Immutability of data stored in the Bitcoin blockchain": "Bitcoinブロックチェーンに格納されたデータの不変性",
  "Transparency of transactions": "取引の透明性",
  "Let's quickly go through each of these properties, and most importantly, at the end, we'll need to step back a bit from them, as the world computer inherits them as some kind of successor to Bitcoin.": "これらの特性をすばやく見ていきましょう。そして何よりも、最後に、Bitcoinの後継として世界コンピューターがこれらを継承しているため、少し後退する必要があります。",
  "**Firstly**, immutability of data. Of course, this property, from the perspective of electronic cash, has significant advantages and importance. After you send a transaction or receive bitcoins, after one or two blocks, you gradually begin to feel the immutability of data in the blockchain. In the first 15 minutes, you can observe, using a blockchain explorer, how the transaction should settle. You already see it in the network, but it is not finalized, meaning these bitcoins are not yet in your account. However, after several blocks, there is confidence that these funds will not disappear from your account. As time passes, the probability of values being somehow overwritten from your account becomes almost negligible, practically reducing to zero. This is our property of data immutability. How cool it is when you can share information with the recipient, send them a link to the blockchain explorer, and you don't need to obtain any paper or document from the bank stating that you sent a payment on a certain date and time - this is the second advantage of Bitcoin that is very helpful in practice and is probably the most pleasant perk when comparing a bank transfer and a Bitcoin transfer.": "**まず**、データの不変性。もちろん、この特性は、電子キャッシュの観点から見ると、重要な利点があります。取引を送信したりビットコインを受け取った後、1つまたは2つのブロック後、ブロックチェーン内のデータの不変性を徐々に感じ始めます。最初の15分間、ブロックチェーンエクスプローラーを使用して、取引がどのように解決されるかを観察できます。ネットワークで既に見えますが、確定されていません。つまり、これらのビットコインはまだあなたの口座にはありません。しかし、数ブロック後、これらの資金があなたの口座から消える可能性はほとんどないという自信があります。時間が経つにつれて、あなたの口座から何らかの方法で上書きされる可能性がほぼ無視できるほどになり、ほぼゼロにまで減少します。これが私たちのデータの不変性の特性です。情報を受信者と共有し、ブロックチェーンエクスプローラーへのリンクを送信し、銀行から特定の日付と時刻に支払いを送信したことを示す紙や文書を取得する必要がないとき、どれだけ素晴らしいことでしょうか。これは、銀行振込とBitcoin送金を比較する際に非常に役立つ2番目のBitcoinの利点であり、実践的に非常に役立つと思われる最も楽しい特典です。",
  "**Secondly**, transparency of transactions. There is practically no fear when using Bitcoin that you will find yourself in a region of the world or connected to an internet provider through which you cannot perform operations with the Bitcoin network. There are practically no options other than locking you in a dark room without internet access so that you cannot use the Bitcoin network.": "**次に**、取引の透明性。Bitcoinを使用する際に、自分がBitcoinネットワークで操作を行うことができない地域やインターネットプロバイダーに接続されている状況に陥ることを恐れる必要はほとんどありません。Bitcoinネットワークを使用できないようにインターネットアクセスのない暗室に閉じ込められる以外の選択肢はほとんどありません。",
  "These three properties are, of course, very important. Now, in order to understand the question \"What is at the heart of the world computer,\" we will need to step back from them, abstract ourselves, and make a small leap of faith, a jump, approximately, 100 years back to the 1930s.": "これらの3つの特性は、もちろん非常に重要です。さて、「世界コンピュータの核心は何か」という問いを理解するためには、これらから一歩引いて、抽象化し、信仰の小さな飛躍、ジャンプ、おおよそ1930年代に100年ほど遡る必要があります。",
  "In 1936, Alan Turing made a proposal to the scientific community to solve the formalization problem and, in fact, a more qualitative description of such a concept as an algorithm. Interestingly, from Alan Turing's proposal, the architecture and development of all computer science in the future emerged, but he in no way pursued the idea of creating a personal computer, and he knew nothing about data centers or clouds. His task was to provide a way to define an algorithm in the context of the tasks faced by mathematicians. It's a fascinating picture over the span of a century that the achievement of computer science turns out to be a by-product of a rather mundane problem among mathematicians.": "1936年、アラン・チューリングは形式化問題を解決するために科学コミュニティに提案し、実際にはアルゴリズムという概念のより質的な説明を行いました。興味深いことに、アラン・チューリングの提案から、将来のすべてのコンピュータ科学のアーキテクチャと開発が生まれましたが、彼は決して個人用コンピュータの作成を追求することはなく、データセンターやクラウドについては何も知りませんでした。彼の仕事は、数学者が直面する課題の文脈でアルゴリズムを定義する手段を提供することでした。数学者の間での比較的ありふれた問題の副産物として、コンピュータ科学の達成が1世紀にわたってどのようになるかは興味深い絵です。",
  "Let's delve into what Alan Turing proposed, without delving too deeply into algorithm theory and the purpose for which he suggested it. Alan Turing proposed the Turing machine, which represents an infinite tape (we can call it memory cells to make it easier), traversed by a reading and writing head. This head, positioned over a certain cell, can read data, apply some simple operations to them, and write new values.": "アラン・チューリングが提案したものについて掘��下げてみましょうが、アルゴリズム理論や彼がそれを提案した目的にはあまり深入りしません。アラン・チューリングは、無限のテープ（それをメモリセルと呼ぶこともできます）を表すチューリングマシンを提案しました。このヘッドは、特定のセルの上に配置され、データを読み取り、それにいくつかの単純な操作を適用し、新しい値を書き込むことができます。",
  "Today, when you hear phrases like this, it might seem to you: \"Well, yes, it's a hard drive, a computer, or something like that.\" That's absolutely correct. This description gave rise to the first computer architecture. However, the main task of the Turing machine was to provide a means of representing a system or entity capable of performing any formalized computations. One can imagine a box or room, even filled with lamps, into which you insert your punch card, card, or transmit a Bluetooth signal, and the machine starts working, performing simple operations that ultimately solve your problem. Thus, the Turing machine is a universal computational mechanism that primarily solves the universal and essential task of providing a mechanism through which any simple computation or, more accurately, any formalized computation can be performed—computations that can be decomposed into the language of mathematics": "今日、このようなフレーズを聞くと、「まあ、それはハードドライブ、コンピュータ、またはそのようなものですね」と思われるかもしれません。それは完全に正しいです。この説明が最初のコンピュータアーキテクチャを生み出しました。ただし、チューリングマシンの主な目的は、任意の形式化された計算を実行できるシステムまたはエンティティを表す手段を提供することでした。あるいは、あなたがパンチカード、カードを挿入するか、Bluetooth信号を送信するか、ランプでいっぱいの箱や部屋を想像してみてください。そして、その機械は動き出し、最終的に問題を解決するために単純な操作を行います。したがって、チューリングマ���ンは、任意の単純な計算またはより正確には任意の形式化された計算を実行できるメカニズムを提供することを主に解決する普遍的な計算メカニズムです—数学の言語に分解できる計算",
  "In essence, the task of the last 100 years, after finding some solution in the field of mathematics, was precisely to give it a physical form, to find the set of transistors that could be placed on a board, learn how to solder them all, reduce the processes of the computing processor, and so on. No wonder that the theory from 1936 finds application in 2014 for the ideas of the world computer. These 100 years were occupied, in general, in another area—the field of physically implementing this computer.": "基本的に、過去100年の課題は、数学の分野でいくつかの解決策を見つけた後、それに物理的な形を与えることであり、基板に配置できるトランジスタのセットを見つけ、それらすべてをはんだ付けする方法を学び、コンピューティングプロセッサのプロセスを削減することなどでした。1936年の理論が2014年に世界コンピュータのアイデアに応用されるのも不思議ではありません。これらの100年は、一般的に別の領域、つまりこのコンピュータを物理的に実装する分野で占められていました。",
  "When the planet became saturated, and we had personal computers, computational machines even inside smart devices, and when data centers started growing on the planet, the question shifted from the hardware solution to how the computational machine might look not at the physical or mathematically abstract level but at some non-physical, perhaps metaphysical, level relative to the entire planet. However, the foundation remains the same: the state transition function and nothing else.": "惑星が飽和し、個人用コンピュータやスマートデバイスの中にさえ計算機があり、データセンターが増え始めたとき、問題はハードウェアの解決策から、計算機が物理的または数学的抽象レベルではなく、非物理的、おそらく形而上的なレベルでどのように見えるかという点に移行しました。ただし、基盤は変わらず、状態遷移関数だけです。",
  "As an addition to what has been said, so that we don't only dwell on the theory of 1936 and don't just break the shackles of Bitcoin maximalists, open the Ethereum white paper. There you will find the crucial phrase \"Turing complete machine\"—this is the main definition of Ethereum. A Turing complete machine means that Ethereum can handle any simple operations described in a formal language, operations that are possible. This is not some set of operations that Ethereum can provide as a calculator or a sophisticated calculator for scientists. Instead, it is an abstraction inside which it is possible to load any possible variations, manipulations with variables, constants, additions, calculations with any states, and so on. You won't find anything different from what Turing proposed in the 1930s in the Ethereum concept. You will find an engineering implementation of how to do it. If we move on and open the Polkadot wiki, it's a bit more challenging to find. For this, you should use the search, enter \"State transition,\" and in the search results, find several mentions that Polkadot guarantees nothing else but the state transition. Neither the storage of data in the Polkadot blockchain nor any additional services—only the purest change of state caused by incoming transactions and processed by Polkadot validators. Now, let's try to delve more into this.": "1936年の理論についてだけに留まらず、ビットコインの最大主義者の枷を破るだけでなく、イーサリアムのホワイトペーパーも開いてみてください。そこには重要なフレーズ「チューリング完全機械」という言葉があります。これがイーサリアムの主要な定義です。チューリング完全機械とは、イーサリアムが可能な形式言語で記述された任意の単純な操作を処理できることを意味します。これは、イーサリアムが科学者向けの電卓や洗練された電卓として提供できる操作のセットではありません。代わりに、可能な変化、変数、定数、追加、任意の状態での計算などをロードできる抽象化です。イーサリアムの概念には、1930年代にチューリングが提案したものとは異なるものは見つかりません。それをどのように行うかのエンジニアリング実装が見つかります。次に、Polkadotのウィキを開いてみると、少し難しいかもしれません。これには検索を使用し、「状態遷移」と入力し、検索結果でPolkadotが状態遷移以外の何も保証しないことをいくつかの言及で見つける必要があります。Polkadotのブロックチェーンにデータを保存したり、追加のサービスを提供したりすることはありません。入力トランザクションによって引き起こされ、Polkadotのバリデータによって処理される状態の純粋な変化だけです。さて、これについてもう少し掘り下げてみましょう。",
  "Now, let's add a bit to this linear diagram to move from the theory of the 1930s to today's realities, where we describe the abstract picture of the world computer. To do this, let's consider an example with Alice and Bob. Alice, being in the office, wants to start Bob's home vacuum robot for cleaning. If we look at today's concepts of how the link between Alice's mobile application and the robot vacuum at home is implemented, you will see roughly the following picture: Alice's mobile application generates a transaction in some cloud where calculations take place, and the output of these calculations is the output values that effectively turn into a command to start the vacuum robot. It would be useful for us, from the field of robotics and Robonomics as concepts in the world of web3, to understand that in the cloud, there is a digital twin of this robot, and its state is changed. We can, in general, not go that far and stop at the fact that Alice sends a transaction to the cloud, and the cloud, having performed all the necessary calculations and manipulations, generates a command to start Bob's vacuum robot.": "今、この線形図に少し追加して、1930年代の理論から現在の現実に移動しましょう。そこでは、世界コンピュータの抽象的な画像を説明します。これを行うために、アリスとボブの例を考えてみましょう。オフィスにいるアリスは、ボブの家庭用掃除ロボットを起動したいと思っています。今日の概念を見ると、アリスのモバイルアプリケーションと家庭のロボット掃除機の間のリンクがどのように実装されているか、おおよそ次のような画像が見えます：アリスのモバイルアプリケーションは、いくつかのクラウドでトランザクションを生成し、計算が行われる場所で、これらの計算の出力は、効果的に掃除機ロボットを起動するコマンドに変換されます。ロボティクスとWeb3の世界でのコンセプトであるRobonomicsの分野から、クラウドにはこのロボットのデジタルツインがあり、その状態が変化します。一般的には、アリスがクラウドにトランザクションを送信し、クラウドがすべての必要な計算と操作を行った後、ボブの掃除機ロボットを起動するコマンドを生成します。",
  "In this scheme today, there are several main questions: if you were interacting with a physical computer in front of you or were in a room with the vacuum robot, you would approach, press a physical button, and set it in motion. What changes when instead of arrows, there is not a manual drive but a communication layer, the internet? A multitude of questions arises about how we can safely connect Alice and this cloud, how we can be sure that Alice has access to this cloud. The question of the communication network arises—how we can protect Alice from someone else addressing her vacuum robot, requesting, for example, to make a video of her entire apartment instead of cleaning, and a similar aspect arises: why would the vacuum robot listen to this cloud with such honor and integrity? Why would the robot fully trust this cloud?": "このスキームでは、今日、いくつかの主要な問題があります：目の前の物理コンピューターとやり取りしているか、または掃除機ロボットがある部屋にいる場合、物理ボタンを押して起動させます。矢印の代わりに通信レイヤーがある場合、インターネットはどのように変わるのでしょうか？アリスとこのクラウドを安全に接続する方法、アリスがこのクラウドにアクセスできることを確認する方法について多くの質問が生じます。通信ネットワークの問題が生じます—アリスを他の誰かから彼女の掃除機ロボットにアプローチされることからどのように保護できるか、例えば、掃除の代わりにアパート全体のビデオを作成するよう要求されることから。同様の側面が生じます：なぜ掃除機ロボットはこのクラウドをそんなに尊敬し、信頼するのでしょうか？なぜロボットはこのクラウドを完全に信頼するのでしょうか？",
  "Today's approach with the architecture of cloud solutions that connect your mobile phone, or rather, the application on your mobile phone, and some technology on the other side, smart devices, is based on the significant achievements in building physical computers. Computers in data centers today are something extraordinary—the level of technical processes is simply amazing. However, from the perspective of communication technologies, when you already have some experience working with internet applications, it seems that somewhere there, at the level of a technical school or college, or maybe not right next to how developers, architects of Intel processors are solving their tasks now. Almost all questions about connecting Alice to Bob boil down solely to outputting a specific access certificate on a specific IP address from both sides, linking them together, and the cloud will own and do anything. The most important thing in this scheme is to do anything, meaning to perform state transitions or operations that occur without any guarantees that for Alice, for Bob, these will be executed according to the same logic. No one can say anything about how the cloud is arranged. It is a black box where computations are not formalized, and neither Alice nor Bob knows how the computation is performed.": "今日のアプローチは、モバイル電話を接続するクラウドソリューションのアーキテクチャに基づいています。あるいは、正確には、モバイル電話のアプリケーションと、もう一方の側にあるいくつかの技術、スマートデバイスを接続します。データセンター内のコンピューターは今日、何か特別なものです—技術プロセスのレベルは単純に驚くほどです。しかし、通信技術の観点から見ると、すでにインターネットアプリケーションで作業する経験がある場合、技術学校や大学のレベルで、またはおそらく開発者、インテルプロセッサのアーキテクトが今解決している課題のすぐそばにあるとは思えません。アリスをボブに接続するすべての質問は、両側から特定のIPアドレスに特定のアクセス証明書を出力し、それらをリンクし、クラウドが所有し、何でも行うことです。このスキームで最も重要なことは、何でも行うこと、つまり、アリスやボブにとって、これらが同じロジックに従って実行されるという保証がない状態遷移や操作を実行することです。誰もクラウドがどのように構成されているかについて何も言えません。計算が形式化されていないブラックボックスであり、アリスもボブも計算がどのように行われるかを知りません。",
  "The place where you must fully trust—relying on the reputation of the company that owns these data centers, and you must completely trust the network access providers who issue a certificate and verify the security of your connection. In fact, if we talk about the boom of internet applications, this is a huge problem. The problem is that there are actually some citadels located in specific jurisdictions that operate on a relatively simple technology stack to connect you as easily as possible to the cloud, which represents a black box. Dissatisfaction with this approach actually arouses interest in the world computer because it will arrange things a bit differently. And how? Let's try to supplement the scheme we drew with blue color right now.": "完全に信頼しなければならない場所—これらのデータセンターを所有する会社の評判に依存し、ネットワークアクセスプロバイダーを完全に信頼し、証明書を発行し、接続のセキュリティを検証する必要があります。実際、インターネットアプリケーションのブームについて話すと、これは大きな問題です。問題は、特定の管轄区域にある要塞が実際に存在し、クラウドにできるだけ簡単に接続するための比較的単純な技術スタックで運営されていることです。このアプローチに不満を持つことは、実際には世界コンピュータに興味を持たせます。そして、どのように？今すぐ、描いたスキームに青色を追加してみましょう。",
  "So, to supplement our linear graph, our linear diagram from both sides, let's take a look at the discoveries that have significance in computer science and that are directly or indirectly related to achievements from the world of web3.": "したがって、両側から線形グラフ、線形図を補完するために、コンピュータサイエンスで重要な発見を見てみましょう。それらは直接または間接的にWeb3の世界からの成果と関連しています。",
  "Let's start with Leslie Lamport in 1976. Those who attended my presentations, lectures from 2015-2020, probably remember how often I liked to mention that before the invention of Bitcoin, problems related to creating a decentralized network were well described by Leslie Lamport in 1976 in the Byzantine Generals problem. The solution to the Byzantine Generals problem is at the core of Tendermint PBFT algorithms and all synchronous algorithms used from Telegram Open Network to Tendermint, to Cosmos, and other blockchain projects that, accordingly, followed the path of Byzantine Generals.": "1976年のLeslie Lamportから始めましょう。2015年から2020年までの私のプレゼンテーション、講義に参加した人々は、おそらく、ビットコインの発明以前に、分散型ネットワークを作成する問題が1976年にLeslie Lamportによってよく説明されていたことを覚えているでしょう。ビザンチン将軍問題の解決策は、Tendermint PBFTアルゴリズムの中核にあり、Telegram Open NetworkからTendermint、Cosmos、および他のブロックチェーンプロジェクトに至るまで、ビザンチン将軍の道をたどった同期アルゴリズムに使用されています。",
  "The second interesting achievement in internet technologies is torrent trackers. We don't have any specific, already erased, cloud or a black box that stores files. Still, users worldwide, by exchanging torrent files, can download exactly the file they were looking for, and this works without data substitution. No one uploads any viruses to you by replacing the file. There might sometimes be a virus embedded in the file, but the idea of receiving a link to download and actually downloading something other than what you were offered to download using torrent technology is impossible. Similar processes exist in the IPFS network, a hash-oriented storage - a way of connecting various participants with trust in the information you convey without using a black box, precisely.": "インターネット技術における2番目の興味深い達成はトレントトラッカーです。私たちは特定の、すでに消去されたクラウドやファイルを保存するブラックボックスを持っていません。それでも、世界中のユーザーはトレントファイルを交換することで、まさに探していたファイルをダウンロードすることができ、これはデータの置き換えなしで機能します。誰もがファイルを置き換えてウイルスをアップロードすることはありません。ファイルに埋め込まれたウイルスがあることもありますが、トレント技術を使用して提供されたものとは異なるものをダウンロードするリンクを受け取ることは不可能です。IPFSネットワークにも同様のプロセスが存在し、ハッシュ指向のストレージ - ブラックボックスを使用せずに情報を伝達するための信頼を持つさまざまな参加者を接続する方法です。",
  "And of course, Bitcoin. Bitcoin, as a more collective example, I'm sure Satoshi Nakamoto was well aware of Leslie Lamport's solution to the Byzantine Generals problem and, of course, observed how the idea of torrent trackers was developing. If we don't emphasize the properties that the Bitcoin blockchain obtained, such as immutability, transparency of transactions, and, to some extent, censorship resistance, then Bitcoin is an internet service that performs state transition, some changes in state based on transactions without a central node. It is an example of a collective construction of a global network in which there is a constantly functioning state transition function that we can trust, and to ensure trust, neither jurisdictions nor specific IP addresses nor the most primitive technologies used and still used today in building cloud services are used. The collective image of Bitcoin allowed overlaying the general concept from the 1930s of a Turing-complete machine on the existence of a universal abstract function for everything.": "そしてもちろん、ビットコイン。ビットコインは、より集合的な例として、私はサトシ・ナカモトがレスリー・ランポートのビザンチン将軍問題の解決��をよく知っていたこと、そしてもちろん、トレントトラッカーのアイデアがどのように発展していたかを観察していたことを確信しています。ビットコインのブロックチェーンが取得した特性、つまり不変性、取引の透明性、そしてある程度の検閲耐性などを強調しない限り、ビットコインは中央ノードなしでトランザクションに基づく状態の変化を行うインターネットサービスです。信頼できる常に機能する状態遷移関数が存在するグローバルネットワークの集合的な構築の例であり、信頼を確保するために、特定の管轄区域や特定のIPアドレス、そしてクラウドサービスの構築に今日も使用されている最も原始的な技術は使用されていません。ビットコインの集合的なイメージは、1930年代のチューリング完全マシンの概念を存在するすべてのものに重ね合わせることを可能にしました。",
  "So, what do we need to add to this scheme to envision a global computer? From the bottom, we provide consensus validators or, in general, validators. It can be said that the \"Data availability layer\" is probably a phrase many have heard around Ethereum this year, and it has become an advantage of Bitcoin as well. However, in the organization scheme of the global computer, this is one piece of the puzzle and, as I mentioned, it complements the main function that lies at the heart of the global computer—the function of universal state transition. Going back to the very beginning, the analogy of the heart in the human body is interesting here. It's not a thinking thing, indeed. Yes, it doesn't generate, you could say, the brain is much more important. Still, life is impossible without the heart. It simply pumps blood. Similarly, at the core of the global computer, all transactions are pumped through the state transition function, resulting in outputs. But to organize this in a distributed internet network without the need to trust some citadel, we need to supplement the picture with two components.": "では、この計画にグローバルコンピュータを想像するために何を追加する必要があるのでしょうか？最下部から、コンセンサスバリデーター、または一般的にはバリデーターを提供します。今年のイーサリアム周辺で多く���人が聞いたであろう「データ可用性レイヤー」というフレーズは、ビットコインの利点となっています。しかし、グローバルコンピュータの組織計画では、これはパズルの一部であり、私が述べたように、グローバルコンピュータの中心にある主要な機能を補完するものであり、それは普遍的な状態遷移の機能です。最初に戻ると、ここで人間の体の中心の比喩は興味深いです。それは考えるものではありません、確かに。はい、生成しません、脳の方がはるかに重要ですと言えるでしょう。それでも、心なしでは生活は不可能です。それは単に血液を送り出すだけです。同様に、グローバルコンピュータの中核には、すべてのトランザクションが状態遷移関数を通じて送り出され、出力が生成されます。しかし、何らかの要塞を信頼する必要がない分散型インターネットネットワークでこれを組織するためには、2つのコンポーネントを補完する必要があります。",
  "The first component is a set of computers or nodes that are ready to execute the state transition. When you send transactions, they don't just go here; they go to the validators. Validators perform computations, recalling what I've already mentioned in this ongoing conversation. They take your transaction, retrieve information from the blockchain about how to process that transaction, apply that processing, and then coordinate with other validators the fact that they correctly executed the state transition. The core of the global computer, in terms of protection against situations where Bob, the vacuum cleaner robot, receives a correct command from Alice in the office, is not based on trust but on cross-verification by a multitude of network participants based on available information from the blockchain. Not only from the blockchain, by the way. It's complex, and we won't delve into it right now, but essentially, a multitude of validators take turns watching and have incentives, some internal incentives within the protocol, to prevent the universal and capable-of-calculating-anything machine from executing this operation incorrectly. A validator effectively processes transactions that come into the global computer, and other validators help prevent situations where one of the validators performed an incorrect calculation. The better the consensus algorithms of the validators, the better protection we have for the state transition function or, in other words, the heart of our global computer.": "最初のコンポーネントは、状態遷移を実行する準備ができているコンピュータまたはノードのセットです。トランザクションを送信するとき、ここに行くだけでなく、検証者に行きます。検証者は計算を行い、この継続的な会話で既に言及したことを思い出します。あなたのトランザクションを取り、そのトランザクションを処理する方法についてのブロックチェーンからの情報を取得し、その処理を適用し、他の検証者と協力して、正しく状態遷移を実行したことを確認します。グローバルコンピュータの核心は、オフィスでアリスから正しいコマンドを受け取ったときのボブ、掃除機ロボット、の状況に対する保護において、信頼ではなく、ブロックチェーンからの利用可能な情報に基づく多数のネットワーク参加者による相互検証に基づいています。ちなみに、ブロックチェーンだけでなく。複雑で、今すぐには詳しくは触れませんが、基本的には、多数の検証者が交代で見守り、プロトコル内の一部の内部インセンティブを持ち、この操作を誤って実行する可能性のある普遍的で何でも計算できる機械を防ぐために、互いに協力します。検証者は、グローバルコンピュータに入ってくるトランザクションを効果的に処理し、他の検証者は、誤った計算を行った検証者の状況を防ぐのに役立ちます。検証者のコンセンサスアルゴリズムが優れていれば、状態遷移関数または言い換えれば、グローバルコンピュータの核心の保護が向上します。",
  "The second part of this scheme is the data availability service—what we've always called the database in Bitcoin or Ethereum. In fact, we'll have to abandon that concept because there's a fundamental change in the architecture of all projects, and for those specifically targeting the global computer, this change is most crucial. For a simple present-day example: there are various implementations of Layer 2 networks on top of Ethereum—such as Arbitrum, Optimism, and others. If you start looking into their main differences and how they operate, you'll find that, in some cases, an L2 network in Ethereum sends a larger amount of data, solely from the first-layer blockchain, i.e., from the Ethereum blockchain. All the necessary puzzle pieces to confirm that the computation on the L2 layer was correct can be found in the first-layer Ethereum blockchain. On the other hand, other approaches suggest that beyond the first layer of Ethereum, something else is stored that needs to be found to prove the correctness of transactions. So, right now, before our eyes, there is again a question of improvement, but specifically of such an architecture where transactions go on the left, in the middle, we have the heart in the form of the state transition function, validators, and their consensus allows for the correct execution of this state transition. But there is also a question of data availability, which is necessary to ensure both cross-verification and, essentially, the existence of the service itself. Some approaches and patterns for creating L2 on top of Ethereum today ask the question: \"What if a certain L2 layer loses the data it doesn't store within the main Ethereum blockchain?\"": "この計画の第2部は、データ可用性サービスです。これは、ビットコインやイーサリアムでデータベースと呼んできたものです。実際、すべてのプロジェクトのアーキテクチャに根本的な変更があるため、この概念を放棄しなければなりません。特にグローバルコンピュータを対象とするプロジェクトにとって、この変更は非常に重要です。現代の例を挙げると、イーサリアムの上にLayer 2ネットワークのさまざまな実装があります。例えば、Arbitrum、Optimismなどです。彼らの主な違いや動作を調べてみると、場合によっては、イーサリアムのL2ネットワークが、イーサリアムブロックチェーンからのみ、つまり最初のレイヤーブロックチェーンから、より多くのデータを送信することがあります。L2レイヤーでの計算が正しいことを確認するために必要なすべてのパズルのピースは、最初のレイヤーのイーサリアムブロックチェーンに見つかります。一方、他のアプローチでは、イーサリアムの最初のレイヤーを超えて、トランザクションの正確性��証明するために見つける必要があるデータが格納されていると示唆しています。したがって、今、私たちの目の前で、再び改善の問題がありますが、特にトランザクションが左に進むアーキテクチャの場合、中央には状態遷移関数、検証者、およびそのコンセンサスがこの状態遷移の正しい実行を可能にする心臓があります。しかし、データの可用性の問題もあり、これは相互確認と、本質的にはサービス自体の存在を確保するために必要です。現在のイーサリアムの上にL2を作成するためのいくつかのアプローチとパターンは、次のような質問をします。「あるL2レイヤーが、主要なイーサリアムブロックチェーン内に保存していないデータを失った場合はどうなるでしょうか？」",
  "Let's complement this picture with how Polkadot is structured. Polkadot has two consensus mechanisms: the \"babe\" consensus, responsible for the parachain-level consensus and is fast, and the \"grandpa\" consensus, which is slower and verifies everything afterward. So, if you delve into the wiki article titled \"The Path of a Block in the Polkadot Network,\" you will encounter interesting abbreviations. After achieving the \"babe\" consensus at the parachain level, the \"grandpa\" consensus introduces the concept of \"proof of validity and data availability.\" Going deeper, you'll find the term \"chunk\" of redundant pieces of information, inspired by CD RW technologies from the 90s and 2000s. This addresses the question of how to preserve information when absolute trust in a specific entity in the network is not feasible. The concept of \"chunk\" of redundant information is one of these patterns.": "この図をポルカドットの構造とどのように補完するかを見てみましょう。ポルカドットには2つのコンセンサスメカニズムがあります。「babe」コンセンサスは、パラチェーンレベルのコンセンサスを担当し、速く、そして「grandpa」コンセンサスは遅く、その後すべてを検証します。したがって、ポルカドットネットワーク内のブロックの経路というウィキ記事に深入りすると、興味深い略語に出会うでしょう。「babe」コンセンサスをパラチェーンレベルで達成した後、「grandpa」コンセンサスは「有効性とデータの可用性の証明」という概念を導入します。さらに深く掘り下げると、「90年代と2000年代のCD RW技術に触発された冗長な情報の「チャンク」という用語が見つかります。これは、ネットワーク内の特定のエンティティに絶対的な信頼が不可能な場合に情報をどのように保存するかという問題に対処します。冗長な情報の「チャンク」という概念は、これらのパターンの1つです。",
  "Summing up, at the core lies an abstract function that enables any computation and was described by Alan Turing in the 1930s. The personal computer, essentially a side effect of a mathematical problem, emerged from Turing's work. The technologies first applied in Bitcoin, such as consensus that allows the network to exist without a specific data center or entity responsible for data correctness, form a functioning mechanism. It goes beyond providing a specific service for electronic cash transfers; it allows us to audit and control any computation in the network. Additionally, we face the challenge of ensuring data availability, as it's not the primary concern of the world computer. The world computer's task lies at its core, executing computation, managing state transitions, and performing calculations, while the data in this scheme serves as a puzzle piece that is more necessary to support the lower part. Thus, this overall scheme can be seen as an abstract and generalized illustration of the world computer's structure, where the state transition function is at its core.": "要約すると、核心には、任意の計算を可能にする抽象関数があり、これは1930年代にアラン・チューリングによって記述されました。個人用コンピュータは、本質的には数学的な問題の副産物として、チューリングの仕事から生まれました。ビットコインなどで最初に適用された技術、例えば、特定のデータセンターやデータの正確性に責任を持つ特定のエンティティなしでネットワークが存在できるコンセンサスなど、機能するメカニズムを形成します��これは特定のサービスを提供するだけでなく、ネットワーク内の任意の計算を監査および制御することを可能にします。さらに、データの可用性を確保するという課題に直面しています。これは、世界コンピュータの主要な関心事ではありません。世界コンピュータのタスクは、計算を実行し、状態遷移を管理し、計算を実行することであり、この計画のデータは、下部をサポートするためにより必要なパズルのピースとして機能します。したがって、この全体的な計画は、状態遷移関数が中心にある世界コンピュータの構造の抽象的かつ一般的なイラストとして見ることができます。",
  "Part 4: The Path of a New Block of Information in the World Computer": "情報ブロックの新しい経路：第4部",
  "The fourth and final part of our lecture is \"The World Computer in Your Home.\" After this, I will begin recording screencasts for the practical part of the sessions.": "私たちの講義の第4部である「あなたの家の世界コンピューター」の最後の部分です。これ以降、実践的なセッションのためのスクリーンキャストの録画を開始します。",
  "Now we will try to summarize almost all the theory we have covered so far in terms of one process. The process that describes the path of an information block in the world computer. Let's start again by returning to the theme of web3 and the concept of blockchain. The phrase \"block\" or \"information block\" can be considered identical when stepping away from the last 10 years and taking a more general theory, as explored in the previous parts of the lectures. The concept of a \"block of information\" aligns with web3, but not necessarily with blockchain. Even without any crypto projects, we need to understand that when forming the theory of the world computer without referencing the formation of information blocks, it's currently challenging to envision other models. So, we will consider the path of an information block throughout the entire world computer, not because it is blockchain, but because, for now, there are no other ways to conceptualize the existence of the world computer other than by processing information in specific portions.": "これからは、これまでにカバーしたほぼすべての理論を1つのプロセスの観点からまとめてみましょう。それは、世界コンピューター内の情報ブロックの経路を記述するプロセスです。Web3のテーマとブロックチェーンの概念に戻って始めましょう。過去の講義の前半で探求されたように、最後の10年から離れて一般的な理論を取り上げると、「ブロック」または「情報ブロック」というフレーズは同一視できます。 「情報ブロック」という概念はweb3と一致しますが、必ずしもブロックチェーンとは一致しません。暗号プロジェクトがなくても、情報ブロックの形成を参照せずに世界コンピューターの理論を形成する際には、他のモデルを想像するのが現在は難しいことを理解する必要があります。したがって、私たちは情報ブロックの経���を考慮しますが、それがブロックチェーンであるためではなく、現時点では情報を特定の部分で処理する以外に世界コンピューターの存在を概念化する他の方法がないからです。",
  "Block of information = block in web3, but without blockchain and without any crypto project influence. We must currently consider the formation of information blocks when discussing the theory of the world computer. Now, let's move on to the first point. I tried to find close analogies from everyday life to help illustrate the path of an information block in the world computer. The analogy I've chosen is the movement of a bus on a route. Our first meeting point is the bus station.": "情報ブロック＝web3のブロック、ただしブロックチェーンや暗号プロジェクトの影響はなし。現在、世界コンピューターの理論を議論する際には情報ブロックの形成を考慮する必要があります。さて、最初のポイントに移りましょう。私は、情報ブロックの経路を説明するのに日常生活から類推を見つけようとしました。選んだ類推は、バスがルート上を移動することです。最初の出会いの場所はバス停です。",
  "I marked transactions in pink as small dots. Let's imagine a typical bus stop where people gather, waiting for a bus that operates on a schedule. If we don't consider the hustle and bustle of large cities, where buses are always late, everyone in the world generally knows that the train from village A to village B always arrives around 7:15 am. Transactions that users want to send to the world computer gather at a certain bus stop and wait for the bus to arrive.": "取引を小さなピンクの点でマークしました。典型的なバス停を想像してみましょう。人々が集まり、スケジュールに従って運行されるバスを待っています。大都市の喧騒を考慮しない場合、世界中の誰もが村Aから村Bへの列車がいつも午前7時15分ごろに到着することを知っています。ユーザーが世界コンピューターに送信したい取引は特定のバス停に集まり、バスが到着するのを待ちます。",
  "This is how our block is formed. Imagine: the bus arrives, and each person starts boarding one by one, taking their seats. The bus then follows its route. In our case, the block of information overcomes the first frontier. Our transactions, in some form, have settled into the bus and overcome the initial barrier. I will be using terminology primarily from Polkadot, and the third part should have better explained the concept of the world computer in the comparison between Ethereum and Polkadot. My personal opinion, and probably the majority of engineers today would agree, is that the representation of a heterogeneous multicentric world computer is better implemented in Polkadot. However, we will still go through the terms inherited from Ethereum, but towards the end of this part of the lecture.": "これが私たちのブロックが形成される方法です。想像してみてください：バスが到着し、各人が順番に乗車し、席に着席します。その後、バスはルートに従います。私たちの場合、情報のブロックは最初のフロンティアを乗り越えます。私たちの取引は、ある形で、バスに落ち着き、最初の障壁を乗り越えます。私は主にPolkadotから用語を使用し、第三部分では、EthereumとPolkadotの比較で世界コンピュータの概念をよりよく説明すべきでした。私の個人的な意見、そしておそらく今日のほとんどのエンジニアが同意するであろうことは、異種多中心世界コンピュータの表現はPolkadotでよりよく実装されているということです。ただし、私たちは引き続きEthereumから継承された用語を説明しますが、この講義のこの部分の終わりに向かいます。",
  "What is the line that separates the bus stop from the bus's further movement? This line represents the collators of the network – participants in the network nodes who collect transactions. You can think of a collator not as a bus driver but as a controller who stays at the bus stop. In other words, this controller checks whether you have a ticket when you enter the bus. It doesn't recheck in the database how valid the ticket is but looks at the basic parameters of the ticket and checks if everything seems fine. In reality, collators perform almost all the calculations required, verifying the ticket number and other data, but they are not required to guarantee that the check is done correctly. Therefore, collators are controllers who remain at the bus stop, primarily ensuring passenger boarding, seating, and sending the bus further along the route.": "バス停とバスのさらなる移動を分ける線は何ですか？この線は、ネットワークのコレーターを表します - トランザクションを収集するネットワークノードの参加者。コレーターをバスの運転手ではなく、バス停にとどまるコントローラーと考えることができます。言い換えれば、このコントローラーは、バスに乗車する際にチケットを持っているかどうかを確認します。データベースでチケットが有効かどうかを再確認するのではなく、チケットの基本的なパラメータを見て、すべてが正常に見えるかどうかを確認します。実際には、コレーターは、チケット番号やその他のデータを検証するために必要なほとんどすべての計算を行いますが、その検査が正しく行われていることを保証する必要はありません。したがって、コレーターは、乗客の乗車、着席、およびバスをルートに沿って送ることを主に確認するコントローラーです。",
  "Beyond the drawn border, we enter the first validation area where paravalidators are located. These are validators of the entire ecosystem, the entire network, specifically assigned for a certain time to check each transaction and thus perform actual computations in the world computer. Our not-yet-fully-formed block of information is marked with a dashed line. It is still a candidate block of information since it has not undergone any actual verification. The collator, who collected the block of information and checked the transactions at the entrance, does not participate in any way in securing the cybersecurity of the computations conducted. Its task is only to seat all transactions and form the first block. At this stage, the transformation from a candidate to a real block of information begins.": "引かれた境界を超えると、最初の検証エリアに入ります。ここにはパラバリデータがあります。これらは、生態系全体、特定の時間に特定のトランザクションをチェックするために割り当てられたネットワークの検証者です。まだ完全に形成されていない情報のブロックは破線で示されています。実際の検証を受けていないため、まだ情報の候補ブロックです。情報のブロックを収��し、入口でトランザクションをチェックしたコレーターは、実際の計算のサイバーセキュリティを確保する方法には何ら関与しません。その役割は、すべてのトランザクションを着席させ、最初のブロックを形成することだけです。この段階では、候補から実際の情報ブロックへの変換が始まります。",
  "I have divided it into three parts, but forgot one more. Let's consider four parts of this candidate block. The top part, known to users of various web3 applications as the header or block header, is the quintessence, the most popular piece of information circulating and reflected from the block explorer to the console clients of all nodes mining, staking, and so on. The header is a key element of the block, but it is practically formed at the last stage at this point.": "3つに分けましたが、1つを忘れました。この候補ブロックの4つの部分を考えてみましょう。ヘッダーまたはブロックヘッダーとしてさまざまなweb3アプリケーションのユーザーに知られているトップ部分は、情報の中心であり、ブロックエクスプローラからコンソールクライアントに反映され、マイニング、ステーキングなどのすべてのノードによって使用される最も人気のある情報です。ヘッダーはブロックの重要な要素ですが、この時点で実質的に形成されます。",
  "Firstly, we have our actual requests for state transitions or computations. There is a list of changes that need to be made: convert A to A', B to B', C to C', applying a set of algorithms to them. For this, we will now build another boundary immediately and go beyond it to perform this part of the work, and then only proceed beyond it. Already at the block preparation stage, we have to cross the second boundary within the world computer to go for the algorithms that need to be applied to prepare the block. As I mentioned before, theoretically, the controller at the bus stop here does the same, but I wouldn't pay much attention to that. The block preparation stage, especially when we talk about examples simultaneously from Polkadot and Ethereum as a world computer, they differ slightly and show us the insignificance of checks at this stage because it is precisely on the second step, after passing the first boundary and receiving the block of information from collators, that the attention-worthy calculations of this world computer begin.": "まず、状態遷移や計算の実際のリクエストがあります。行う必要がある変更のリストがあります：AをA'に、BをB'に、CをC'に変換し、それらに一連のアルゴリズムを適用します。これにより、すぐに別の境界を構築し、この作業の一部を行うた���にそれを超え、その後に進みます。すでにブロックの準備段階で、ブロックを準備するために適用する必要があるアルゴリズムに進むために、世界コンピュータ内で2番目の境界を越えなければなりません。前述のように、理論的には、ここでバス停のコントローラーが同じことを行いますが、それにはあまり注意を払いません。特に、PolkadotとEthereumの世界コンピュータから同時に例を挙げる場合、この段階でのチェックの無意味さがわかり、この世界コンピュータの注目すべき計算が始まります。",
  "To perform these calculations, the validator, at this stage, can only do so by turning to the relay chain, the central database, and taking from there the algorithms from the runtime. In the case of Ethereum, it was the same virtual machines in the previous architectural concept, which could be applied, so there was no need to go anywhere. Almost every node had a complete copy of the algorithms that could be applied. But in terms of a heterogeneous network, where each segment or each individual chain may have its own set of algorithms, a validator, before actually executing all the transitions, calculations obtained in the form of a block candidate from the collator, must consult. It must consult the relay chain, consult the main blockchain in the network and take from there the necessary algorithms, apply them, and perform state transitions.": "これらの計算を実行するために、検証者はこの段階ではリレーチェーン、中央データベースにアクセスし、ランタイムからアルゴリズムを取得することしかできません。Ethereumの場合、以前のアーキテクチャコンセプトと同じ仮想マシンが適用されたため、どこにも行く必要はありませんでした。ほとんどのノードが適用可能なアルゴリズムの完全なコピーを持っていました。しかし、各セグメントや各個々のチェーンが独自のアルゴリズムセットを持つ異種ネットワークの場合、コレーターからブロック候補として取得した遷移、計算を実際に実行する前に、検証者は相談する必要があります。リレーチェーンに相談し、ネットワーク内のメインブロックチェーンに相談し、そこから必要なアルゴリズムを取得し、適用し、状態遷移を実行する必要があります。",
  "During the execution of calculations, a Merkle tree is simultaneously formed, and we won't dwell on it because Merkle trees are not that complicated from the perspective of computer science. Still, I notice that to understand how to apply them in engineering and in the architecture of a project, how they are applied, not just by reading on Wikipedia, you need to break your head a bit, imagine examples. In this example, we won't delve too much into it, but I think for those who are already familiar with some basic definitions, have read about Merkle trees, it will become a bit clearer about how and at what moments another Merkle tree is assembled. The Merkle tree is formed when we actually perform calculations and output values appear. These output values are packed into a binary tree format, then the addition is performed between them in computer science language, and the top node reaches the header. Let's denote it with a big letter \"H.\" It's a small and pleasant aspect of considering such schemes.": "計算の実行中に、Merkleツリーが同時に形成されますが、コンピュータサイエンスの観点から見ると、Merkleツリーはそれほど複雑ではないため、詳細には触れません。それでも、エンジニアリングやプロジェクトのアーキテクチャにそれらを適用する方法、どのように適用されるかを理解するには、Wikipediaで読むだけではなく、少し頭を使い、例を想像する必要があります。この例ではそれについてあまり深入りしませんが、基本的な定義に既に精通している人、Merkleツリーについて読んだことがある人にとっては、別のMerkleツリーがどのように組み立てられるかが少し明確になると思います。Merkleツリーは、実際に計算を実行し、出力値が現れたときに形成されます。これらの出力値はバイナリツリーフォーマットにパッキングされ、それからコンピュータサイエンスの言語でそれらの間で加算が実行され、トップノードがヘッダに到達します。大文字の「H」でそれを示しましょう。これはそのようなスキームを考慮する際の小さな楽しい側面です。",
  "In this scheme, we can note how the block header is actually related to the computations performed inside. Let's look again - our block candidate came from the collator. There is a set of transactions that need to be executed, perform calculations. The validator went through another internal boundary, one more, behind the algorithms, applied them, and recorded all the results at the lowest level of the Merkle tree. The other nodes are essentially systemic. They do not come from any data; they don't come from anywhere. At the second level, the node does not come from any information. It is obtained by summing values in these two leaves, and when we go up with you, we get only the root of this tree, which is enough to protect all output values. We won't get the same header if we change any of these calculations. And this is one of the magical and simple features, like hash-oriented storage, of how we can protect a whole block of information by talking only about one header. Therefore, headers are so important and play a cornerstone role even in architectures when we transition from one chain or one virtual machine to many combined in the network. It is enough for us to ensure the security of storing headers to be sure that all transactions that were executed at the block preparation stage were executed correctly, and they cannot be replaced.": "このスキームでは、ブロックヘッダが実際に内部で実行された計算と関連しているかどうかに注目できます。もう一度見てみましょう - ��たちのブロック候補はコレーターから来ました。実行する必要があるトランザクションのセット、計算を実行します。検証者は別の内部境界を通過し、アルゴリズムの背後にさらに1つ、それらを適用し、すべての結果をMerkleツリーの最下位レベルに記録しました。他のノードは基本的にシステム的です。どのデータからも来ません。第2レベルでは、ノードはどの情報からも来ません。これら2つのリーフで値を合計することによって取得され、一緒に上に行くと、私たちと一緒にこのツリーのルートだけを取得します。これはすべての出力値を保護するのに十分です。これらの計算のいずれかを変更すると、同じヘッダを取得できません。これは、ハッシュ指向のストレージのような、1つのヘッダについて話すだけで全体の情報ブロックを保護する方法の魔法のようでシンプルな機能の1つです。したがって、ヘッダは非常に重要であり、1つのチェーンや1つの仮想マシンからネットワーク内で組み合わされた多くのチェーンに移行する際にも、基石的な役割を果たします。ヘッダの保存のセキュリティを確保する��けで十分です。ブロック準備段階で実行されたすべてのトランザクションが正しく実行され、それらを置き換えることはできないことを確認するために。",
  "And one field is still left unfilled. In the process of preparing the block of information, it is the author's field, that is, the validator who actually performed all the changes, prepared the Merkle tree, and recorded the header. Since we are considering an example with the bus moving along the route from the stop, let's call the validator a \"controller\" who goes right inside the bus, passes each seat, approaches each person, checks for real what is written on their tickets, makes some mark, validates it, and, accordingly, puts their signature. The controller, for example, number 134, meaning, naturally, each validator has some unique identifier, their address, and we also somehow uniquely renamed it here.": "そして1つのフィールドがまだ未入力のままです。情報ブロックを準備する過程で、実際にすべての変更を行い、Merkleツリーを準備し、ヘッダーを記録したのは、著者のフィールド、つまり実際に行った検証者です。停留所からルートを移動するバスの例を考えているので、検証者を「コントローラー」と呼びましょう。バスの中に直接入り、各座席を通り、各人に近づき、チケットに書かれている内容を実際に確認し、何かしるしをつけ、検証し、それに応じて署名をします。例えば、コントローラーは134番とします。当然のことですが、各検証者には固有の識別子、アドレスがあり、ここでも何らかの方法で固有に名前を付けています。",
  "And it seems that at this point, we could have shaded and made our block boundaries bolder, but no, and this is one of the interesting changes that have occurred in the last 5 years in terms of decentralized ecosystems, namely the shift from proof of work. When validators of the network, at that time miners, never had to coordinate anything with each other. You produced a block and sent it to the network and moved on. In fact, it was not a consensus of agreed consent. It was a consensus of obvious agreement with the fact that had occurred. What is interesting changes when the architecture becomes more complex, and we have come closer from a simple calculator like Bitcoin with a ledger towards an actual virtual computer, is that at each stage, the connectivity of participants who ensure security and block production has increased. Because, in fact, no one who risks their stake, the one who ensures this security and wants to earn by processing your transactions, has something to lose, unlike proof of work. In proof of work, you bought the equipment, yes, you put money into it, you spend electricity, but there is actually no protection against the fact that you can attack the network with your power, the same 51% attack, where someone with a lot of miners can try to rewrite the chain.": "そしてこの時点で、私たちはブロックの境界線をより鮮明にし、強調することができたかもしれませんが、いいえ、これは過去5年間に分散型エコシステムの観点から起こった興味深い変化の1つです。つまり、プルーフ・オブ・ワークからの移行です。ネットワークの検証者、当時のマイナーたちは、お��いに何も調整する必要がありませんでした。ブロックを生成してネットワークに送信し、次に進みました。実際、それは合意された同意のコンセンサスではありませんでした。起こった事実に対する明白な同意のコンセンサスでした。アーキテクチャがより複雑になると、興味深い変化が起こります。私たちは、ビットコインのようなシンプルな計算機から実際の仮想コンピューターに近づいてきました。各段階で、セキュリティとブロックの生成を確保する参加者の連結性が増しています。実際、リスクを冒す人は誰もいません。セキュリティを確保し、トランザクションを処理して報酬を得たい人は、プルーフ・オブ・ワークとは異なり、何も失うものがありません。プルーフ・オブ・ワークでは、機器を購入し、お金を投資し、電力を消費しますが、実際には、自分の力でネットワークを攻撃できるという保護がありません。同じく51%攻撃があります。多くのマイナーを持つ人がチェーンを書き換えようとする可能性があります。",
  "Now we are talking about proof of stake, where a deposit is already made, and if you do something wrong, a part will be withdrawn from it, as a penalty. All nodes, absolutely, in all architectures that I currently observe, mechanisms for messaging between validators began to appear quickly at the block preparation stage. In Polkadot, it is no different. Any validator of a separate parachain that collects a block knows the addresses or already has established contact with another 15-63 validators who are with you on this epoch, on some temporary period, as validators, and each of them randomly becomes a block producer at some point. But being appointed as a producer does not negate a very important component of this process. You do not stop interacting with the other participants. There is always a pool of validators assigned to a specific epoch, to a certain time slot, for validating a particular parachain or segment of the world computer. Regardless of whether you are a validator-controller specifically assigned to produce the next block in the world computer of this segment, you still stay in touch with the other validators, and you have constant contact with them.": "今、私たちはステークの証明について話しています。ここでは、すでに預金が行われており、何か間違ったことをした場合、その一部が引き出され、罰金として支払われます。私が現在観察しているすべてのアーキテクチャにおいて、バリデーター間のメッセージングの仕組みがブロックの準備段階で急速に現れ始めました。Polkadotでも同様です。特定のパラチェーンの任意のバリデーターは、ブロックを収集する際に、このエポックであなたと一緒にいる別の15〜63のバリデーターのアドレスを知っているか、すでに連絡を取っています。そして、それぞれがランダムにある時点でブロックプロデューサーになります。しかし、プロデューサーに任命されたとしても、このプロセスの非常に重要な要素を無視するわけではありません。他の参加者とのやり取りを止めるわけではありません。特定のエポック、特定の時間スロットに割り当てられたバリデータープールが常に存在し、特定のパラチェーンやワールドコンピューターのセグメントを��証します。このセグメントのワールドコンピューターで次のブロックを生成するように明示的に指定されたバリデーターコントローラーであっても、他のバリデーターと常に連絡を取り合い、彼らと常に接触を保ちます。",
  "Why is this constant contact necessary? It turns out to be quite simple. We do not want, when we move into the inner part, to be afraid or worry that we performed any of the operations incorrectly. As surprising as it may seem, it is beneficial for any validator, before moving on, to first turn to their colleagues assigned to validation and ask them to double-check the calculations. This check is informal, so even if we do not use any logging into an immutable database of requests for verification and the results of this verification, the appointed controller, after talking to the pool of validators, still collects additional responses from all validators assigned to this parachain or network segment. Together with additional confirmations, the controller moves on to the next stage. But even here, it's not quite as simple. At this stage, another process has to be performed. It is important to note that at this stage, our block of information is still a candidate block, and settlement of information is already taking place in the storage. Neither at the very end, nor after we have created and sealed the block and attached it with an archiver in the final part, namely here, in this middle part where all the calculations are actually performed, does the information get saved in the storage. Therefore, our controller, in addition to talking to their colleagues, also ensures the storage of data in some storage, which is also quite metaphysical because the moment you communicate with other validators, this storage gets filled. How is this checked? We will need to move on to the next stage.": "なぜこの継続的な連絡が必要なのでしょうか？実際には非常にシンプルです。私たちは内部に移動する際に、操作を誤って行ったのではないかと恐れたり心配したりしたくありません。驚くべきことに、次に進む前に、検証に割り当てられた同僚に最初に相談し、計算をダブルチェックしてもらうことがどんな検証者にとっても有益であることがわかります。このチェックは非公式ですので、検証とその結果のリクエストの不変のデータベースにログインしない場合でも、指定されたコントローラーは、検証に割り当てられたすべての検証者から追加の応答を収集します。追加の確認とともに、コントローラーは次の段階に進みます。しかし、ここでもそれほど簡単ではありません。この段階では、別のプロセスを実行する必要があります。この段階では、情報のブロックはまだ候補ブロックであり、情報の決済はすでにストレージで行われています。最後の段階でも、ブロックを作成し封印し、最終部分でアーカイバーと連携させた後でも、つまり、すべての計算が実際に行われるこの中間部分で、情報はストレージに保存されません。したがって、私たちのコントローラーは、同僚と話すだけでなく、データをあるストレージに保存することも確認します。他の検証者と通信すると、このストレージが埋まるというのはかなり形而上学的です。これがどのようにチェックされるのでしょうか？次の段階に進む必要があります。",
  "In summary, to complete the middle part, let's look again. We still have only a candidate block at the very beginning. Yes, all transactions are roughly calculated somewhere at the bus stop, everyone has taken their seats according to their tickets. We have passed the first boundary, which is essentially direct established contact between validators and block collators. In Ethereum and Polkadot, these are slightly different schemes now. But everything that happens on the left side at the very beginning does not provide cybersecurity for data and calculations. It's just preparation. Once we have passed and entered the environment of the validators' attention, work with the block of information in the world computer begins. A randomly selected validator, in our case, with a bus route - a controller, actually goes through each of the seats, checks the ticket, checks and performs all the calculations that were made, gathers all the information into a tree. The resulting root node of this tree becomes the header of the proposed block. The validator who actually performs all the calculations with this block of information communicates with the other participants who perform a similar function for the same route in an undefined time slot. And while communicating with them and asking them to verify all the calculations, we are actually filling a certain storage of data in the network. It is not a specific physical storage; there is no specific IP address, no specific hard drive onto which they all load through some VPN or login and password scheme, of course not. In the process of communicating with other validators, data remains on their local machines, and this data will further participate in the transformation of this candidate into a new block of information. In essence, the sealed block that will be settled in the relay chain is collected. We have assembled a block. All the metadata around the calculations is already filled, which means we can try to move on to the next frontier.": "要約すると、中間部分を完成させるために、もう一度見てみましょう。まだ最初の段階での候補ブロックしかありません。はい、すべての取引はバス停のどこかでおおよその計算が行われ、誰もがチケットに従って座席に着席しています。私たちは、基本的にはバリデータとブロックコレーターの間で直接確立された接触を通過しました。EthereumとPolkadotでは、これらは現在わずかに異なるスキームです。しかし、最初の段階で左側で起こるすべては、データと計算のサイバーセキュリティを提供しません。それはただの準備です。一度バリデータの注意を引き、世界コンピュータ内の情報ブロックとの作業が始まります。ランダムに選択されたバリデータ、私たちの場合、バスルートを持つコントローラーは、実際に各座席を通過し、チケットを確認し、すべての計算を行い、すべての情報をツリーに集めます。このツリーの結果のルートノードが提案されたブロックのヘッダーとなります。この情報ブロックですべての計算を実行するバリデータは、同じルートの他の参加者と通信し、未定の時間枠で同様の機能を実行するよう要請します。そして、彼らと通信しながら、すべての計算を検証するよう要請することで、実際にネットワーク内のデータの一定のストレージを埋めています。具体的な物理的なストレージではありません。特定のIPアドレスも、特定のハードドライブもありません。VPNやログインパスワードスキームを介してすべてのデータをロードするわけではありません。他のバリデータと通信する過程で、データは彼らのローカルマシンに残り、このデータはさらにこの候補を新しい情報ブロックに変換するプロセスに参加します。基本的に、リレーチェーンに解決される封印されたブロックが収集されます。私たちはブロックを組み立てました。計算周りのすべてのメタデータが既に埋められているため、次のフロンティアに進むことができます。",
  "At this moment, let's delve into the passage of the next boundary. The most crucial aspect at the final stage becomes the block header. We are less concerned with the execution of computations; we can simplify our perspective here, as computations may vary based on the architecture, whether it's Ethereum or Polkadot. The key point is that, on the intermediate stage, from what I observe in the theory and practice of implementing the world computer concept, most computations happen at an intermediate level. The last level remains only to execute essential checks. Almost all these checks in a multi-chain architecture are related to the concatenation or merging of block headers into one block.": "この瞬間、次の境界の通過に突入しましょう。最終段階で最も重要な要素はブロックヘッダーになります。計算の実行についてはあまり心配する必要はありません。ここでは視点を単純化できます。計算はアーキテクチャによって異なる可能性があるため、イーサリアムかポルカドットかに関係なく、中間段階では、世界コンピューター概念の理論と実践で観察したところ、ほとんどの計算が中間レベルで行われています。最後の段階は主要なチェックのみを実行するだけです。マルチチェーンアーキテクチャにおけるほとんどのこれらのチェックは、ブロックヘッダーの連結やマージに関連しています。",
  "In the final part of our journey, the most important element in the world computer's information block becomes the cornerstone – the header. The second component is more about meta-information. If the header is the actual result of all computations, the additional meta-information being transmitted consists of receipts and signatures of the validators who participated in the intermediate stage of this process. At the final stage, we can visualize the whole picture solely as the assembly of the same tree, not as a list of transactions. In the relay chain's final part, the crucial aspect is the assembly of headers from many similar processes, but linked to different segments of the world computer, different parachains.": "旅の最後の部分では、世界コンピューターの情報ブロックで最も重要な要素は、基礎となるヘッダーになります。2番目のコンポーネントはメタ情報についてです。ヘッダーがすべての計算の実際の結果である場合、送信される追加のメタ情報は、このプロセスの中間段階に参加したバリデーターの受領書と署名から構成されています。最���段階では、全体像を単に同じツリーの組み立てとして視覚化できます。リレーチェーンの最終部分では、多くの類似プロセスからのヘッダーの組み立てが重要ですが、世界コンピューターの異なるセグメントにリンクされています。",
  "Each parachain, each set of validators – we've discussed one example, but in reality, such block preparations for parachains happen 30-40 times. The number of parachain slots or the number of L2 networks in Ethereum will result in a similar number of processes with a similar architecture. However, in the final stage, we will see an approximately identical picture everywhere – how the block header will be formed from a multitude of headers from other blocks. In this process, we need to introduce one more entity and jump back across the boundary to the second stage.": "各パラチェーン、各バリデーターセット - 1つの例を議論しましたが、実際には、パラチェーンのためのブロックの準備が30〜40回行われます。イーサリアムのパラチェーンスロットの数やL2ネットワークの数は、同様のアーキテクチャを持つ同様のプロセスの数につながります。しかし、最終段階では、どこでもほぼ同じ絵が見られるでしょう - ブロックヘッダーが他のブロックからの多数のヘッダーから形成される方法。このプロセスでは、さらに1つのエンティティを導入し、境界を越えて第2段階に戻ります。",
  "Finalizers. In fact, they are also validators, but relay chain validators. In the Polkadot architecture, we have a thousand validators divided into two groups. The first, a very small group, is responsible only for forming the block header and a new block consisting of the headers of the State of the States blocks. The second group – parachain validators – is further divided into many subgroups, but this group is called parachain validators. In L2 networks above Ethereum, this story will eventually gain more understanding, more denominators. For now, let's focus on the Polkadot architecture. Finalizers, besides checking an additional set of meta-information and rechecking a validator with a specific ID, randomly chosen to generate this block of all blocks, also help recheck meta-information, check, and assemble all headers into one. It's a bit complex, yes, if we look at it from the perspective of tree assembly.": "ファイナライザー。実際には、リレーチェーンのバリデーターでもあります。ポルカドットのアーキテクチャでは、1000人のバリデーターが2つのグループに分かれています。最初の非常に小さなグループは、State of the Statesブロックのヘッダーと新しいブロックを形���する責任があります。2番目のグループ - パラチェーンバリデーター - さらに多くのサブグループに分かれていますが、このグループはパラチェーンバリデーターと呼ばれています。イーサリアムのL2ネットワークでは、この物語は最終的により理解され、より多くの分母を持つようになるでしょう。今のところ、ポルカドットのアーキテクチャに焦点を当てましょう。ファイナライザーは、すべてのブロックからこのブロックを生成するためにランダムに選択された特定のIDを持つバリデーターを再チェックし、メタ情報を再チェックし、すべてのヘッダーを1つに組み立てるのを手伝います。少し複雑ですが、ツリーの組み立ての観点から見るとそうです。",
  "In addition to this, in the Polkadot architecture and in Ethereum with the latest changes, a data availability check takes place. For this, finalizers visit parachain validators and try to request actual information about each block stored in the network. If they receive data from at least 1/3 of the validators, using technology that allows redundant storage of information, and subsequently, if someone loses it, one or two or three validators can still restore it, there is a critical threshold at 1/3. If 1/3 of the nodes respond and say that we have data about the block being produced, finalizers tell the block that it is already a fully formed information block, that all computations have been done correctly, that we have already taken the header of this block and combined it with someone else's headers from other segments of the network. We have already formed the main header of the entire network. After that, finalizers place many checkmarks on the final block, which combines all performed computations.": "これに加えて、Polkadotのアーキテクチャと最新の変更があり、データの可用性チェックが行われます。これにより、ファイナライザーがパラチェーンのバリデータを訪れ、ネットワークに格納されている各ブロックの実際の情報をリクエストしようとします。バリデータの少なくとも1/3からデータを受信した場合、情報の冗長な保存を可能にする技術を使用し、その後、誰かがそれを失った場合でも、1つまたは2つまたは3つのバリデータがそれを復元できるようになります。1/3の臨界点があります。ノードの1/3が応答し、生成されたブロックに関するデータを持っていると言うと、ファイナライザーはそのブロックがすでに完全に形成された情報ブロックであること、すべての計算が正しく行われたこと、このブロックのヘッダーをすでに取得し、他のセグメントのヘッダーと組み合わせたことを伝えます。すでに全ネットワークのメインヘッダーを形成しています。その後、ファイナライザーは最終ブロックに多くのチェックマークを付けます��",
  "Currently, this is the situation from the perspective of the most engineering-implemented multi-chain heterogeneous ecosystem, which is Polkadot. It is the most engineering-implemented multi-chain heterogeneous ecosystem, not too far from Ethereum. I would like to focus on the comparison, and if someone is interested in understanding how information blocks flow in Ethereum with L2 networks, you can try to do that now. I will return to this question when some elements of Ethereum, in terms of heterogeneity and multi-chain aspects, are completed. It might take 1-2 years, and then we can build such a picture. Nevertheless, we can generally accept a scheme with three main stages:": "現在、最もエンジニアリングが実装されたマルチチェーン異種生態系であるPolkadotの観点からの状況です。これは、Ethereumからあまり遠くない最もエンジニアリングが実装されたマルチチェーン異種生態系です。比較に焦点を当てたいと思います。EthereumとL2ネットワークで情報ブロックがどのように流れるかを理解したい方は、今すぐ試してみることができます。Ethereumの要素のうち、異質性とマルチチェーンの側面に関して、完了した時点でこの質問に戻ります。1〜2年かかるかもしれませんが、その後、そのような図を構築することができます。それにもかかわらず、一般的には、3つの主要な段階を受け入れることができます。",
  "**1. Formation of a candidate for the information block:**": "**1. 情報ブロックの候補の形成:**",
  "In this stage, the initial candidate for the information block is formed.": "この段階では、情報ブロックの初期候補が形成されます。",
  "**2. Execution of all computations, data storage, data availability, rechecking with other nodes, ensuring that all state transitions are performed correctly according to specific algorithms, and storing these algorithms in the main citadel:**": "**2. すべての計算、データ保存、データの可用性、他のノードとの再確認、すべての状態遷移が特定のアルゴリズムに従って正しく実行されていることを確認し、これらのアルゴリズムをメインシタデルに保存する実行:**",
  "This stage involves the actual execution of computations, saving data to certain layers, ensuring data availability, rechecking with other nodes to confirm that all state transitions are in accordance with algorithms stored somewhere in the main citadel.": "この段階では、実際の計算の実行、データの特定の層への保存、データの可用性の確保、他のノードとの再確認によるすべての状態遷移がメインシタデルのどこかに保存されているアルゴリズムに従っていることを確認します。",
  "**3. Finalization, which will not recheck the computations but will verify the meta-information, how this meta-information is stored. It will then assemble the final block, which is the state of the states, and release it as a common information block for the entire segmented multi-chain network:**": "**3. 最終確定、計算を再確認することはありませんが、メタ情報を検証し、このメタ情報がどのように保存されているかを確認します。その後、最終ブロックを組み立て、それをセグメンテッドマルチチェーンネットワーク全体の共通情報ブロックとしてリリースします:**",
  "The final stage involves checking the meta-information, verifying how this meta-information is stored, assembling the final block (state of the states), and releasing it as a common information block for the entire segmented multi-chain network.": "最終段階では、メタ情報をチェックし、このメタ情報がどのように保存されているかを検証し、最終ブロック（状態の状態）を組み立て、それをセグメンテッドマルチチェーンネットワーク全体の共通情報ブロックとしてリリースします。",
  "At this point, we can say that our information is saved. It has passed through the heart, the heart has executed its data transfer correctly, and we can already use the output values. Some will use them to open a smart-contract-purchased apartment with a smart lock, while others might show off their NFT, just received for 10 ethers.": "この時点で、私たちの情報が保存されたと言えます。心臓を通過し、心臓がデータ転送を正しく実行し、出力値をすでに使用できるようになりました。一部の人は、スマートロックで購入したアパートを開くためにそれらを使用するかもしれませんが、他の人は、10エーテルで受け取ったばかりのNFTを見せびらかすかもしれません。",
  "In general, this is approximately how it works. This concludes the theoretical part. I think it took about 2 hours, and ahead of us are practical sessions that I will be recording over the next few months. They will help us understand the observed data from the console window, decentralized applications, block explorers, where we will gradually understand how all these theoretical numbers and letters actually look in implementation using Polkadot as an example. I will also start getting hands-on with implementations at the L2 level using one of the well-known frameworks for building L2. Thank you to everyone who has been watching.": "一般的には、おおよそこのように機能します。これで理論的な部分は終了です。約2時間かかったと思いますが、これからは数か月かけて録画する実用的なセッションが待っています。これらは、コンソールウィンドウ、分散型アプリケーション、ブロックエクスプローラーから観察されたデータを理解するのに役立ちます。そこで、Polkadotを例にしてこれらの理論的な数字や文字が実際にどのように実装されているかを徐々に理解していきます。また、L2を構築するためのよく知られたフレームワークの1つを使用して、L2レベルでの実装に取り組み始めます。��れまでご覧いただいた皆様、ありがとうございました。"
}