{
  "Part 3: Emergence of the World Computer": "Deel 3: Opkomst van de Wereldcomputer",
  "In the third part titled \"Emergence of the World Computer,\" we will attempt, layer by layer, to recreate the engineering implementation of the world computer using examples from Ethereum and Polkadot, as before.\"": "In het derde deel getiteld 'Opkomst van de Wereldcomputer', zullen we laag voor laag proberen de technische implementatie van de wereldcomputer opnieuw te creëren met behulp van voorbeelden van Ethereum en Polkadot, zoals eerder.",
  "Learn": "Leer",
  "In the third part titled \"Emergence of the World Computer,\" we will attempt, layer by layer, to recreate the engineering implementation of the world computer using examples from Ethereum and Polkadot, as before.": "In het derde deel getiteld 'Opkomst van de Wereldcomputer', zullen we laag voor laag proberen de technische implementatie van de wereldcomputer opnieuw te creëren met behulp van voorbeelden van Ethereum en Polkadot, zoals eerder.",
  "Let's start with Ethereum. Ethereum began in 2015 with a state that can be characterized as a combination of the proof-of-work consensus algorithm, enabling the world computer to exist in a decentralized state (as discussed in Part 2). Additionally, the Ethereum Virtual Machine (EVM) was introduced, serving as a Turing-complete computational machine. Together, these two elements formed the first version of the world computer, sometimes referred to as a precursor. Within this context, decentralized applications, or smart contracts, began to emerge.": "Laten we beginnen met Ethereum. Ethereum begon in 2015 met een staat die kan worden gekarakteriseerd als een combinatie van het proof-of-work consensusalgoritme, waardoor de wereldcomputer in een gedecentraliseerde staat kon bestaan (zoals besproken in Deel 2). Daarnaast werd de Ethereum Virtual Machine (EVM) geïntroduceerd, die diende als een Turing-complete computationele machine. Samen vormden deze twee elementen de eerste versie van de wereldcomputer, soms aangeduid als een voorloper. Binnen deze context begonnen gedecentraliseerde applicaties, of slimme contracten, op te komen.",
  "Over the next 5 years, Ethereum lived a relatively unchanged life, undergoing some engineering tunings, such as a continuous increase in gas limits, with the exception of events like the Shanghai fork. Notably, during the second DEFCON held in Shanghai, a denial-of-service attack exploited a function in the virtual machine that consumed minimal gas but triggered significant computations on the Ethereum network. This led to memory overflow, effectively disrupting an entire Ethereum node. This incident highlights the intricate details that arise when dealing with a large and abstract solution like creating a virtual machine.": "In de daaropvolgende 5 jaar leefde Ethereum een relatief onveranderd leven, onderging enkele technische aanpassingen, zoals een voortdurende toename van gaslimieten, met uitzondering van gebeurtenissen zoals de Shanghai fork. Tijdens de tweede DEFCON die in Shanghai werd gehouden, werd opgemerkt dat een denial-of-service-aanval een functie in de virtuele machine misbruikte die minimaal gas verbruikte maar aanzienlijke berekeningen op het Ethereum-netwerk activeerde. Dit leidde tot geheugenoverschrijding, waardoor effectief een hele Ethereum-node werd verstoord. Dit incident benadrukt de complexe details die naar voren komen bij het omgaan met een grote en abstracte oplossing zoals het creëren van een virtuele machine.",
  "Moving forward, a significant shift occurred around the end of the decade, particularly in 2020, with the advent of Ethereum 2.0. However, Ethereum 2.0 has now been deprecated, and I would characterize the real breakthrough as starting around 2019-2020. During this period, there was a true technological breakthrough in Ethereum, moving towards the concept of Ethereum 2.0. The moment of engineering change in Ethereum's architecture can be considered the event known as \"the merge,\" where the functionalities of the beacon chain were combined. The merge marked a significant shift in the paradigm of Ethereum, transitioning it into a slightly different state than what was on the board. The actual engineering change in Ethereum's architecture can be associated with \"the merge,\" where the functionalities of the beacon chain were integrated. For a detailed history of this, you can refer to the ethereum.org website, which provides an excellent article on the coexistence of the traditional Ethereum blockchain with the parallel blockchain launched in 2015 and the Ethereum Virtual Machine.": "Vervolgens vond er een significante verschuiving plaats rond het einde van het decennium, met name in 2020, met de komst van Ethereum 2.0. Echter, Ethereum 2.0 is nu verouderd, en ik zou het echte keerpunt karakteriseren als beginnend rond 2019-2020. Tijdens deze periode vond er een echte technologische doorbraak plaats in Ethereum, met de overgang naar het concept van Ethereum 2.0. Het moment van technische verandering in de architectuur van Ethereum kan worden beschouwd als het evenement dat bekend staat als 'de merge', waarbij de functionaliteiten van de beacon chain werden gecombineerd. De merge markeerde een significante verschuiving in het paradigma van Ethereum, waarbij het werd overgezet naar een iets andere staat dan wat op het bord stond. De daadwerkelijke technische verandering in de architectuur van Ethereum kan worden geassocieerd met 'de merge', waarbij de functionaliteiten van de beacon chain werden geïntegreerd. Voor een gedetailleerde geschiedenis hiervan kunt u verwijzen naar de website ethereum.org, die een uitstekend artikel biedt over de co-existentie van de traditionele Ethereum blockchain met de parallelle blockchain gelanceerd in 2015 en de Ethereum Virtual Machine.",
  "When the merge occurred, we witnessed a new architectural representation, both at the network level and for individual nodes interacting with the Ethereum network. What was the actual change? For many, the merge signifies the transition from proof-of-work to proof-of-stake, which is indeed significant. It implies increased efficiency and fine-tuning, but it's still a tuning relative to one of the parameters. However, the more noteworthy internal engineering change for each network client was the split. There was no longer a single specific network client or a monolithic architecture. Instead, we got two components of a single node interacting with the Ethereum network.": "Toen de samensmelting plaatsvond, zagen we een nieuwe architectonische representatie, zowel op netwerkniveau als voor individuele knooppunten die met het Ethereum-netwerk interageren. Wat was de werkelijke verandering? Voor velen betekent de samensmelting de overgang van proof-of-work naar proof-of-stake, wat inderdaad significant is. Het impliceert verhoogde efficiëntie en fijnafstemming, maar het is nog steeds een afstemming ten opzichte van een van de parameters. De meer opmerkelijke interne technische verandering voor elke netwerkclient was echter de splitsing. Er was niet langer een specifieke netwerkclient of een monolithische architectuur. In plaats daarvan kregen we twee componenten van een enkel knooppunt dat met het Ethereum-netwerk interageert.",
  "The first part, which I labeled \"beacon chain\" on the diagram, essentially represents a collective image of all the innovations that came into the Ethereum client at the moment of the merge. The second part is the preserved virtual machine. Nevertheless, it's worth adding something here too. Dialogues truly began about replacing the virtual machine, which was exclusively tailored to work with smart contracts and smart contracts in a specific language—Solidity. This is because, by 2015, there were practically no interpreters left for smart contracts in languages other than Solidity, and the architecture appeared somewhat one-sided from the perspective of an Ethereum programmer. You learn a snippet of JavaScript in the form of Solidity, write smart contract code on it, and get your DApp, like Uniswap, for example.": "Het eerste deel, dat ik op het diagram 'beacon chain' heb genoemd, vertegenwoordigt in feite een collectief beeld van alle innovaties die in de Ethereum-client kwamen op het moment van de samensmelting. Het tweede deel is de behouden virtuele machine. Toch is het ook de moeite waard om hier iets aan toe te voegen. Er werden daadwerkelijk dialogen gestart over het vervangen van de virtuele machine, die exclusief was afgestemd op het werken met slimme contracten en slimme contracten in een specifieke taal - Solidity. Dit komt doordat er tegen 2015 praktisch geen interpreters meer waren voor slimme contracten in talen anders dan Solidity, en de architectuur leek enigszins eenzijdig vanuit het perspectief van een Ethereum-programmeur. Je leert een stukje JavaScript in de vorm van Solidity, schrijft er slim contractcode op en krijgt je DApp, zoals bijvoorbeeld Uniswap.",
  "Since the emergence of a more complex Ethereum architecture, discussions have revolved around the idea that the virtual machine, which existed as a somewhat monolithic element from 2015, can also be replaced in the new architecture. The conversation shifted towards replacing it with something like WebAssembly (Wasm) or a more interesting solution from the perspective of writing code for the world computer. You could say, \"Wasm with a question mark.\"": "Sinds de opkomst van een complexere Ethereum-architectuur draaien discussies om het idee dat de virtuele machine, die vanaf 2015 als een enigszins monolithisch element bestond, ook kan worden vervangen in de nieuwe architectuur. Het gesprek verschoof naar het vervangen ervan door iets als WebAssembly (Wasm) of een interessantere oplossing vanuit het perspectief van het schrijven van code voor de wereldcomputer. Je zou kunnen zeggen, 'Wasm met een vraagteken.'",
  "From the perspective of the Beacon Chain, it indeed operates on proof-of-stake, but what's more interesting is the inclusion of Gasper. This represents a modification of the original ideas about Casper. Casper, often referred to as the friendly ghost finality gadget, was introduced, perhaps even as early as Defcon 3 or 4, and maybe even discussed at Defcon 2—I don't recall precisely. But at the EthCC conference in Paris, which definitely took place in 2018, Vlad Zamfir and Vitalik, from different rooms, were discussing the emergence of Casper as a friendly ghost, overseeing participants in proof-of-stake and coming to the aid of the network when a node misbehaves. From this idea of Casper, Gasper emerges. Without delving into terminology too much, the consensus algorithm undergoes a shift, changing not only in terms of simplicity but also becoming more complex, similar to Polkadot. As I mentioned earlier, Polkadot has two consensus algorithms, Babe and Grandpa. Similarly, with Ethereum's Beacon Chain functionality, achieving consensus and finality is not as instantaneous. It involves epochs, and the network operates on a more complex scenario, reaching a state that is already somewhat dynamic, not frozen, and is essentially carved in stone.": "Vanuit het perspectief van de Beacon Chain werkt het inderdaad op proof-of-stake, maar wat interessanter is, is de inclusie van Gasper. Dit vertegenwoordigt een wijziging van de oorspronkelijke ideeën over Casper. Casper, vaak aangeduid als het vriendelijke spook finaliteitsgadget, werd geïntroduceerd, misschien zelfs al bij Defcon 3 of 4, en misschien zelfs besproken bij Defcon 2 - ik herinner me dat niet precies. Maar op de EthCC-conferentie in Parijs, die zeker plaatsvond in 2018, bespraken Vlad Zamfir en Vitalik, vanuit verschillende kamers, de opkomst van Casper als een vriendelijk spook, dat deelnemers aan proof-of-stake overziet en te hulp schiet van het netwerk wanneer een knooppunt zich misdraagt. Uit dit idee van Casper ontstaat Gasper. Zonder te diep in te gaan op de terminologie, ondergaat het consensusalgoritme een verschuiving, waarbij het niet alleen in termen van eenvoud verandert, maar ook complexer wordt, vergelijkbaar met Polkadot. Zoals ik eerder al zei, heeft Polkadot twee consensusalgoritmen, Babe en Grandpa. Op dezelfde manier, met de functionaliteit van de Ethereum Beacon Chain, is het bereiken van consensus en finaliteit niet zo onmiddellijk. Het omvat epochs, en het netwerk werkt volgens een complexer scenario, waarbij het een staat bereikt die al enigszins dynamisch is, niet bevroren, en in wezen in steen gebeiteld.",
  "What can be added in relation to 2024? For me, it was a prolonged observation and an attempt to understand whether Ethereum would eventually implement sharding or not. Sharding is the ability to exist not with a single blockchain but with multiple blockchains within one network. As I observed the merge and the simultaneous rise of Layer 2 (L2) networks, questions arose in my mind about whether sharding would indeed materialize. Sharding seemed interesting to me due to its homogeneity—having multiple chains that are almost identical, lacking any specific characteristics. It appeared to be an interesting approach, but not as flexible as a heterogeneous approach. In L2 networks, even several years ago, I could see the heterogeneity of Ethereum, its ability to work with various types of more specific blockchains. I was curious about the direction it would take—whether sharding, with its homogeneity, would displace L2 solutions or whether L2 solutions with a heterogeneous approach would saturate the Beacon Chain and the main nodes of the Ethereum network.": "Wat kan er worden toegevoegd met betrekking tot 2024? Voor mij was het een langdurige observatie en een poging om te begrijpen of Ethereum uiteindelijk sharding zou implementeren of niet. Sharding is het vermogen om niet met een enkele blockchain te bestaan, maar met meerdere blockchains binnen één netwerk. Terwijl ik de samensmelting en de gelijktijdige opkomst van Layer 2 (L2) netwerken observeerde, rezen er vragen in mijn hoofd over of sharding daadwerkelijk zou materialiseren. Sharding leek interessant voor mij vanwege zijn homogeniteit - het hebben van meerdere ketens die bijna identiek zijn, zonder enige specifieke kenmerken. Het leek een interessante benadering, maar niet zo flexibel als een heterogene benadering. In L2-netwerken, zelfs enkele jaren geleden, kon ik de heterogeniteit van Ethereum zien, zijn vermogen om te werken met verschillende soorten meer specifieke blockchains. Ik was nieuwsgierig naar de richting die het zou inslaan - of sharding, met zijn homogeniteit, L2-oplossingen zou verdringen of dat L2-oplossingen met een heterogene benadering de Beacon Chain en de belangrijkste knooppunten van het Ethereum-netwerk zouden verzadigen.",
  "Today, in 2024, based on articles on ethereum.org, it seems that sharding as a concept has been pushed back, and the focus is on helping various L2 networks integrate with the Beacon Chain and align with the main chain's functionality, which is now divided into two elements in the Ethereum network's architecture.": "Vandaag, in 2024, gebaseerd op artikelen op ethereum.org, lijkt het erop dat sharding als concept naar achteren is geschoven, en de focus ligt op het helpen van verschillende L2-netwerken om te integreren met de Beacon Chain en zich af te stemmen op de functionaliteit van de hoofdketen, die nu is verdeeld in twee elementen in de architectuur van het Ethereum-netwerk.",
  "Therefore, without delving into the details of how L2 networks are structured—although we'll touch upon that when we fill in the second part of the board—we should imagine that Ethereum is now a kind of Beacon Chain, a beacon, a guiding star for numerous L2 networks. These L2 networks can have more specific functionality, executing their logic according to a set of individual functions. This is somewhat in line with the idea of a Swiss Army knife—not making Ethereum a Swiss Army knife, but L2 networks are starting to differentiate in architecture. They duplicate the functionality of the abstract computing machine of Ethereum but perform it with lower gas costs or within their specific segment. Some are already thinking about tuning and making their L2 layer more efficient, focusing on specific functional capabilities. Thus, in my opinion, we are witnessing the emergence of heterogeneity in the world computer that aimed to be homogeneous. Also, it's essential not to forget that decentralized applications (dApps) still exist within the main blockchain, within that same blockchain that started in 2015. This means that during the merge, during the transition to the new architectural state, there was no wipeout, no erasure of the previous history. All decentralized applications and smart contracts underlying these applications continued to exist, and they continue to exist today, and probably tomorrow. This is a question that we will explore using Polkadot as an example, but there is still a feeling that it will be possible to settle a decentralized application in the Beacon Chain—dApps.": "Daarom, zonder in te gaan op de details van hoe L2-netwerken zijn gestructureerd - hoewel we daarop zullen ingaan wanneer we het tweede deel van het bord invullen - moeten we ons voorstellen dat Ethereum nu een soort Beacon Chain is, een baken, een leidende ster voor tal van L2-netwerken. Deze L2-netwerken kunnen meer specifieke functionaliteit hebben, hun logica uitvoeren volgens een reeks individuele functies. Dit is enigszins in lijn met het idee van een Zwitsers zakmes - niet van Ethereum een Zwitsers zakmes maken, maar L2-netwerken beginnen zich te differentiëren in architectuur. Ze dupliceren de functionaliteit van de abstracte rekenmachine van Ethereum, maar voeren deze uit met lagere gas kosten of binnen hun specifieke segment. Sommigen denken al na over het afstemmen en efficiënter maken van hun L2-laag, gericht op specifieke functionele mogelijkheden. Zo zijn we naar mijn mening getuige van de opkomst van heterogeniteit in de wereldcomputer die homogeen wilde zijn. Ook is het essentieel om niet te vergeten dat gedecentraliseerde applicaties (dApps) nog steeds bestaan binnen de hoofdblockchain, binnen dezelfde blockchain die in 2015 is gestart. Dit betekent dat tijdens de samenvoeging, tijdens de overgang naar de nieuwe architecturale staat, er geen uitwissing was, geen uitwissing van de vorige geschiedenis. Alle gedecentraliseerde applicaties en slimme contracten die aan deze applicaties ten grondslag liggen, bleven bestaan en bestaan vandaag nog steeds, en waarschijnlijk morgen ook. Dit is een vraag die we zullen verkennen aan de hand van Polkadot als voorbeeld, maar er is nog steeds het gevoel dat het mogelijk zal zijn om een gedecentraliseerde applicatie te vestigen in de Beacon Chain - dApps.",
  "In summary, let's imagine the engineering implementation of today's Ethereum as a world computer. We have each network node consisting of two parts. The first layer is responsible for the Ethereum Virtual Machine (EVM), the actual functionality of the virtual machine or Turing complete machine, if we talk in theoretical terms. Perhaps we will see the emergence of alternatives to the virtual machine designed in 2015. These alternatives will likely surpass it in terms of more abstract programming possibilities than writing smart contracts in Solidity. Meanwhile, smart contracts in Solidity continue to feel comfortable. If you want to write functionality for the Ethereum main chain without creating any infrastructure on top of Ethereum, without offloading any calculations to make them cheaper, and so on, decentralized applications that you can write as smart contracts can still be housed in Ethereum's main blockchain. At the same time, Beacon Chain functionality has emerged, separating the consensus logic between validators from the main protocol of the computing machine. This allows for additional flexibility in how consensus should work and how it should be further modified without affecting the virtual machine itself. The example of Shanghai and Defcon 2, where a small opcode error caused a shutdown of part of the infrastructure, hints that it would be good to have such complex functionalities separated into two parts.": "Samengevat, laten we de technische implementatie van het huidige Ethereum als een wereldcomputer voorstellen. We hebben elk netwerkknooppunt bestaande uit twee delen. De eerste laag is verantwoordelijk voor de Ethereum Virtual Machine (EVM), de daadwerkelijke functionaliteit van de virtuele machine of Turing complete machine, als we in theoretische termen praten. Misschien zullen we de opkomst zien van alternatieven voor de virtuele machine die in 2015 is ontworpen. Deze alternatieven zullen waarschijnlijk deze overtreffen op het gebied van meer abstracte programmeermogelijkheden dan het schrijven van slimme contracten in Solidity. Ondertussen blijven slimme contracten in Solidity zich comfortabel voelen. Als je functionaliteit wilt schrijven voor de Ethereum hoofdchain zonder enige infrastructuur bovenop Ethereum te creëren, zonder enige berekeningen uit te besteden om ze goedkoper te maken, enzovoort, kunnen gedecentraliseerde applicaties die je als slimme contracten kunt schrijven nog steeds worden gehuisvest in de hoofdblockchain van Ethereum. Tegelijkertijd is de functionaliteit van de Beacon Chain ontstaan, waarbij de consensuslogica tussen validators wordt gescheiden van het hoofdprotocol van de rekenmachine. Dit biedt extra flexibiliteit in hoe consensus zou moeten werken en hoe het verder zou moeten worden aangepast zonder de virtuele machine zelf te beïnvloeden. Het voorbeeld van Shanghai en Defcon 2, waar een kleine opcode-fout een deel van de infrastructuur deed stilleggen, suggereert dat het goed zou zijn om dergelijke complexe functionaliteiten in twee delen te scheiden.",
  "What's interesting about the Beacon Chain? It is a more complex, comprehensive algorithm for achieving network synchronicity and finalization with the introduction of concepts such as \"epoch,\" and the presence of a ghost living within the network.": "Wat interessant is aan de Beacon Chain? Het is een complexer, uitgebreider algoritme voor het bereiken van netwerksynchroniciteit en finalisatie met de introductie van concepten zoals 'epoch' en de aanwezigheid van een geest die binnen het netwerk leeft.",
  "Lastly, what is important to consider now is that Ethereum is effectively putting an end to homogeneity, to the idea of getting a hundred identical blockchains working with the same virtual machine, where smart contracts written in Solidity can reside. Instead, various projects are proposing their own architectures or the same virtual machine taken beyond the main blockchain's limits. Alternatively, they are trying to build their more specific application, which, at the level of the Beacon Chain's main chain, is a smart contract written in Solidity. This is the current representation of Ethereum, which did not become Ethereum 2.0. It remains the same Ethereum—a project that once started with proof of work + Turing complete machine, transforming into this architecture.": "Tot slot is het nu belangrijk om te overwegen dat Ethereum effectief een einde maakt aan homogeniteit, aan het idee van honderd identieke blockchains die werken met dezelfde virtuele machine, waar slimme contracten geschreven in Solidity kunnen verblijven. In plaats daarvan stellen verschillende projecten hun eigen architecturen voor of dezelfde virtuele machine die voorbij de grenzen van de hoofdblockchain wordt genomen. Als alternatief proberen ze hun meer specifieke toepassing te bouwen, die op het niveau van de hoofdchain van de Beacon Chain een slim contract geschreven in Solidity is. Dit is de huidige representatie van Ethereum, dat geen Ethereum 2.0 is geworden. Het blijft hetzelfde Ethereum - een project dat ooit begon met proof of work + Turing complete machine, dat zich heeft getransformeerd in deze architectuur.",
  "Now, let's take a look at how Polkadot emerged and evolved over the last 5 years. Polkadot came into existence five years after Ethereum, born out of the team that developed one of the best clients for Ethereum—Parity. Many might remember their web client, which, compared to Geth and other implementations, was probably much more pleasant to work with, at least from personal experience and the experience of colleagues.": "Nu gaan we eens kijken naar hoe Polkadot is ontstaan en geëvolueerd in de afgelopen 5 jaar. Polkadot kwam vijf jaar na Ethereum tot stand, voortgekomen uit het team dat een van de beste clients voor Ethereum ontwikkelde - Parity. Velen herinneren zich misschien hun webclient, die, in vergelijking met Geth en andere implementaties, waarschijnlijk veel prettiger was om mee te werken, althans vanuit persoonlijke ervaring en de ervaring van collega's.",
  "In the end, after a couple of months of the relay chain's existence without any decentralized application functionality, without the ability to connect your parachain or L2 network, without user capabilities, the network transitioned from an authority state to proof of stake. This gave developers the ability to upload their runtimes.": "Uiteindelijk, na een paar maanden van het bestaan van de relay chain zonder enige gedecentraliseerde applicatiefunctie, zonder de mogelijkheid om je parachain of L2-netwerk aan te sluiten, zonder gebruikersmogelijkheden, maakte het netwerk de overgang van een autoriteitsstaat naar proof of stake. Dit gaf ontwikkelaars de mogelijkheid om hun runtimes te uploaden.",
  "At this point, it's also interesting to discuss the differences between today's Ethereum and how the central part of Polkadot is structured. From the perspective of the heart, which we've already discussed, the picture will be absolutely the same not only for Ethereum and Polkadot but for any project that wants to be presented as an abstract computing machine. However, from an engineering and architectural standpoint, it's fascinating to observe Beacon Chain & Relay Chain. Here, we have a virtual machine, which has been inherited since 2015, but alternatives are being proposed. In the relay chain, there's the ability to upload your runtime. The runtime is, in fact, your virtual machine. For example, some parachains completely emulate the Ethereum Virtual Machine. It's written as a runtime, meaning you can essentially upload an Ethereum Virtual Machine analog to the parachain level in Polkadot or write more specific logic that works with four or five functions. Recall part one about the ideas— you can write your Swiss Army knife, but it won't require creating the entire infrastructure. You can implement specific functionality with certain functions at the runtime level, put it into the Polkadot relay chain, and the immutability of this runtime will be ensured by Polkadot validators.": "Op dit punt is het ook interessant om de verschillen tussen het huidige Ethereum en hoe het centrale deel van Polkadot is gestructureerd te bespreken. Vanuit het perspectief van het hart, waar we het al over hebben gehad, zal het beeld absoluut hetzelfde zijn, niet alleen voor Ethereum en Polkadot, maar voor elk project dat zich wil presenteren als een abstracte rekenmachine. Vanuit een technisch en architectonisch oogpunt is het echter fascinerend om Beacon Chain & Relay Chain te observeren. Hier hebben we een virtuele machine, die is geërfd sinds 2015, maar er worden alternatieven voorgesteld. In de relay chain is er de mogelijkheid om je runtime te uploaden. De runtime is in feite je virtuele machine. Sommige parachains bootsen bijvoorbeeld volledig de Ethereum Virtual Machine na. Het is geschreven als een runtime, wat betekent dat je in feite een analoge Ethereum Virtual Machine naar het parachain-niveau in Polkadot kunt uploaden of meer specifieke logica kunt schrijven die werkt met vier of vijf functies. Herinner je deel één over de ideeën - je kunt je Zwitsers zakmes schrijven, maar het vereist niet het creëren van de hele infrastructuur. Je kunt specifieke functionaliteit implementeren met bepaalde functies op het runtimeniveau, het in de Polkadot relay chain plaatsen en de onveranderlijkheid van deze runtime zal worden gegarandeerd door Polkadot validators.",
  "What happens next? Over the course of about a year, a layer of parachains begins to form around the relay chain. In terms of Ethereum implementation, you could say that L2 networks are quite similar to parachains. However, there's one interesting cross-network distinction that I find fascinating in Polkadot, and I'm trying to further understand how it will develop—namely, the second layer of validation and data availability checks. After a couple of years, Polkadot takes a shape like this. It's not just a relay chain where proof-of-stake validators protect the runtime of future parachains; an additional and crucial layer of data validation and availability checking emerges from parachains.": "Wat gebeurt er vervolgens? In de loop van ongeveer een jaar begint zich een laag parachains te vormen rond de relay chain. In termen van Ethereum-implementatie zou je kunnen zeggen dat L2-netwerken vrij vergelijkbaar zijn met parachains. Er is echter één interessant cross-network onderscheid dat ik fascinerend vind in Polkadot, en ik probeer verder te begrijpen hoe het zich zal ontwikkelen - namelijk, de tweede laag van validatie en data beschikbaarheidscontroles. Na een paar jaar krijgt Polkadot een vorm als deze. Het is niet alleen een relay chain waar proof-of-stake validators de runtime van toekomstige parachains beschermen; er ontstaat een aanvullende en cruciale laag van data-validatie en beschikbaarheidscontrole vanuit parachains.",
  "As you look at this diagram, try to notice the analogies that arise and the differences in engineering implementation details. So, what does this represent, and how does this scheme compare with Ethereum? We have an L2 project, in this case, with Polkadot, it's a parachain. A parachain also generates information blocks, which then go to the relay chain to be combined and release a relay chain block as the sum of all headers, headers, and more headers. The parachain collects transactions in a block using collators, which are not involved in validation. They don't stake anything in the relay chain; they only use the runtime, which is in the relay chain. They fetch it, apply it to transactions, perform necessary state transitions, form a block, and, crucially, provide proof of validity—a stamp containing cryptographic proofs that the collator correctly assembled the block. This information goes to the external validation ring of the relay chain. In this ring, there are internal validators of Polkadot—parachain collators. Again, they don't stake anything directly from the relay chain's point of view. Parachain implementations sometimes introduce their consensus among collators, and some don't. For example, in Robonomics, implementing a parachain, we find this paradigm more interesting, less burdensome, and it makes the network simpler while still remaining functionally substantial. Any collator, without reaching consensus with anyone—verified by us—can propose a block and some proof to the external layer. This is precisely why blocks are proposed, proofs of block assembly validity are offered, and there's an external ring. We don't need any consensus from parachain validators. Anyone can generate a block and send it, and if this node of the collator sends incorrect information to the parachain validators on the external ring, the validator at this level will reject it. It won't pass into the central part. But let's say the block was provided correctly by the collator. Our transactions got in; the collator calculated them, applying the runtime stored in the relay chain, executed all state transitions, gathered some proof of validity—validity of the assembled block—and passed it to the external ring of the relay chain. Here, every epoch, which is also part of the finalization, every epoch has validators from the relay chain diverging into parachains. Some of them stay in the center, and the others go to parachains. Their number ranges from 16 to 64 validators, and this figure, I believe, will change in the specification—somewhere more, somewhere less. However, parachain validators re-verify the information from one selected group of validators about everything coming from the collator being correct, that work has been done in accordance with the runtime, and that the proof of validity is indeed valid. The selected segment of relay chain validators who already have something staked respond, or rather, chirp among themselves. They respond to the chosen main block producer of the parachain, so to speak, saying,": "Terwijl je naar dit diagram kijkt, probeer de analogieën op te merken die ontstaan en de verschillen in technische implementatiedetails. Dus, wat vertegenwoordigt dit en hoe verhoudt dit schema zich tot Ethereum? We hebben een L2-project, in dit geval met Polkadot, het is een parachain. Een parachain genereert ook informatieblokken, die vervolgens naar de relay chain gaan om te worden gecombineerd en een relay chain-blok vrij te geven als de som van alle headers, headers en meer headers. De parachain verzamelt transacties in een blok met behulp van collators, die niet betrokken zijn bij validatie. Ze staken niets in de relay chain; ze gebruiken alleen de runtime, die in de relay chain zit. Ze halen het op, passen het toe op transacties, voeren noodzakelijke staatsovergangen uit, vormen een blok en, cruciaal, leveren bewijs van geldigheid - een stempel met cryptografische bewijzen dat de collator het blok correct heeft samengesteld. Deze informatie gaat naar de externe validatiering van de relay chain. In deze ring bevinden zich interne validators van Polkadot - parachain collators. Nogmaals, ze staken niets rechtstreeks vanuit het oogpunt van de relay chain. Parachain-implementaties introduceren soms hun consensus onder collators, en sommige niet. Bijvoorbeeld, in Robonomics, bij het implementeren van een parachain, vinden we dit paradigma interessanter, minder belastend, en het maakt het netwerk eenvoudiger terwijl het functioneel substantieel blijft. Elke collator, zonder consensus te bereiken met iemand - geverifieerd door ons - kan een blok voorstellen en wat bewijs naar de externe laag sturen. Daarom worden blokken voorgesteld, bewijzen van de geldigheid van de blokassemblage worden aangeboden, en er is een externe ring. We hebben geen consensus nodig van parachain validators. Iedereen kan een blok genereren en verzenden, en als deze node van de collator onjuiste informatie naar de parachain validators op de externe ring stuurt, zal de validator op dit niveau het afwijzen. Het zal niet doorgaan naar het centrale deel. Maar laten we zeggen dat het blok correct is verstrekt door de collator. Onze transacties zijn erin gekomen; de collator heeft ze berekend, de runtime toegepast die is opgeslagen in de relay chain, alle staatsovergangen uitgevoerd, wat bewijs van geldigheid verzameld - geldigheid van het samengestelde blok - en dit doorgegeven aan de externe ring van de relay chain. Hier, elke epoch, die ook de finalisatie omvat, heeft elke epoch validators van de relay chain die zich vertakken naar parachains. Sommigen van hen blijven in het midden, en de anderen gaan naar parachains. Hun aantal varieert van 16 tot 64 validators, en dit cijfer, geloof ik, zal veranderen in de specificatie - ergens meer, ergens minder. Parachain validators controleren opnieuw de informatie van een geselecteerde groep validators over alles wat afkomstig is van de collator correct is, dat het werk is uitgevoerd in overeenstemming met de runtime, en dat het bewijs van geldigheid inderdaad geldig is. Het geselecteerde segment van relay chain validators die al iets hebben ingezet, reageren, of liever gezegd, tjilpen onderling. Ze reageren op de gekozen hoofdblokproducent van de parachain, zogezegd, zeggend,",
  "\"Yes, we agree. There are no problems. You can carry it through the entire external ring inside.\"": "\"Ja, we zijn het eens. Er zijn geen problemen. Je kunt het door de hele externe ring binnen dragen.\"",
  "And thus, almost all information formed on the parachain collators, with verification on the external ring, enters the internal one. The lower part, not that it's physically at the bottom, still constitutes the external ring—data availability. Data starts to be checked at this stage, meaning that on the external ring, not only the correctness of block assembly is verified, but the process of preparing for distribution within the Polkadot network begins, ensuring that the block information will not be lost in the future. Here, precisely, is what I mentioned in the second part about chunks, like CD RW. At this stage of block preparation for transfer to the internal ring, the data availability layer is formed as a service, something that is currently also attempted by some projects in Ethereum. Some projects put additional redundant information directly into smart contracts, necessary for checking what is happening on the L2 layer and, if necessary, slashing or punishing those who did it incorrectly. It's impossible to overcome the external ring without distributing block information and without rechecking dozens of nodes with stakes laid down on the assumption that the runtime must work correctly.": "En dus komt bijna alle informatie die is gevormd op de parachain collators, met verificatie op de externe ring, de interne ring binnen. Het onderste deel, niet dat het fysiek onderaan staat, vormt nog steeds de externe ring - gegevensbeschikbaarheid. Gegevens beginnen op dit punt te worden gecontroleerd, wat betekent dat op de externe ring niet alleen de juistheid van de blokassemblage wordt geverifieerd, maar ook het proces van voorbereiding op distributie binnen het Polkadot-netwerk begint, waarbij wordt gegarandeerd dat de blokinformatie niet verloren gaat in de toekomst. Hier, precies, is wat ik noemde in het tweede deel over brokken, zoals CD RW. Op dit punt van blokvoorbereiding voor overdracht naar de interne ring wordt de gegevensbeschikbaarheidslaag gevormd als een service, iets dat momenteel ook wordt geprobeerd door sommige projecten in Ethereum. Sommige projecten voegen aanvullende redundante informatie rechtstreeks toe aan slimme contracten, die nodig zijn om te controleren wat er gebeurt op de L2-laag en, indien nodig, degenen die het verkeerd hebben gedaan te straffen. Het is onmogelijk om de externe ring te overwinnen zonder blokinformatie te distribueren en zonder tientallen knooppunten opnieuw te controleren met inzetten die zijn gedaan op de veronderstelling dat de runtime correct moet werken.",
  "Thus, information that has passed through the external ring is already quite trustworthy, probably yes, you can say that, and on the internal ring, work is mainly done not with parachain blocks, but their block headers are collected into one big header. That is, from many headers, one header of a relay chain block is assembled—a mechanism of linking in Shared Security, as mentioned in Polkadot, which ensures the security of parachains. One could say that parachains are validated and reach a state where the service exists in a distributed decentralized form on the external ring. In the internal ring, the information that has entered attempts to come together in one hyperblock, which should precisely link everything together. There are no calculations happening there; there is no recalculation of absolutely everything. The assembly of the final block takes place, so to speak, in the current iteration of the world computer, to put a point on the question of whether the transaction has passed in a particular parachain. We must assemble a hyperblock that contains not all the information from the parachains but gathers all the headers verified on the external ring of parachains into one large block. And thus, our world computer in Polkadot operates.": "Dus, informatie die door de externe ring is gegaan, is al behoorlijk betrouwbaar, waarschijnlijk ja, je kunt dat zeggen, en op de interne ring wordt het werk voornamelijk gedaan niet met parachainblokken, maar hun blokkoppen worden verzameld in één grote kop. Dat wil zeggen, uit veel koppen wordt één kop van een relay chain-blok samengesteld - een mechanisme van koppeling in Shared Security, zoals vermeld in Polkadot, dat de beveiliging van parachains garandeert. Men zou kunnen zeggen dat parachains worden gevalideerd en een staat bereiken waarin de service bestaat in een gedistribueerde gedecentraliseerde vorm op de externe ring. In de interne ring probeert de informatie die is binnengekomen samen te komen in één hyperblok, dat alles precies moet verbinden. Er vinden geen berekeningen plaats; er is geen herberekening van absoluut alles. De samenstelling van het uiteindelijke blok vindt plaats, zogezegd, in de huidige iteratie van de wereldcomputer, om een punt te zetten achter de vraag of de transactie is geslaagd in een bepaalde parachain. We moeten een hyperblok samenstellen dat niet alle informatie van de parachains bevat, maar alle gecontroleerde koppen op de externe ring van parachains verzamelt in één groot blok. En zo werkt onze wereldcomputer in Polkadot.",
  "Let's take another look at these two schemes together: relay chain, beacon chain, runtime, secured by proof of stake, where someone stakes their funds to validate that they will always perform their work correctly. There's a virtual machine where you can also stake your funds, and if you perform any computation or state transition not in accordance with the Ethereum Virtual Machine's specification, you'll be penalized.": "Laten we nog eens kijken naar deze twee schema's samen: relay chain, beacon chain, runtime, beveiligd door proof of stake, waar iemand zijn fondsen inzet om te valideren dat ze altijd correct zullen werken. Er is een virtuele machine waar je ook je fondsen kunt inzetten, en als je enige berekening of statusovergang uitvoert die niet in overeenstemming is met de specificatie van de Ethereum Virtual Machine, zul je worden gestraft.",
  "In Polkadot, there's an additional external layer, which seems to be one of the main advantages, such pleasant perks of the engineering implementation that, in my opinion, should be present here. It should appear between L2 networks and the beacon chain, which exists in Ethereum. By the way, some say that the term \"beacon chain\" is dying out again and is misunderstood, but I really like to use it in analogy with the \"relay chain,\" a term from Ethereum's roadmap.": "In Polkadot is er een extra externe laag, wat een van de belangrijkste voordelen lijkt te zijn, zoals aangename voordelen van de technische implementatie die naar mijn mening hier aanwezig zouden moeten zijn. Het zou moeten verschijnen tussen L2-netwerken en de beacon chain, die in Ethereum bestaat. Overigens zeggen sommigen dat de term \"beacon chain\" weer aan het uitsterven is en verkeerd begrepen wordt, maar ik gebruik hem graag in analogie met de \"relay chain,\" een term uit de routekaart van Ethereum.",
  "And perhaps one more interesting story in this part of the lecture: so far, we can hardly imagine proper cross-chain messages between L2 networks in Ethereum. Maybe I missed something in the papers, but when you don't have an external ring and issues like collators, paravalidators, and data availability services are not resolved, thinking about how two L2 layers can communicate is challenging. Yet, in Polkadot, it exists. Even horizontally, through the relay chain, meaning directly, one can send a transaction securely from one parachain to another, without trusting any bridges between these two parachains. This is another crucial functionality that will likely need to be implemented at the level of connecting L2 networks. Smart contracts in Ethereum communicate well. We have created many chains of linked smart contracts, where one triggers another. With this, there is no problem. But when we say that almost all applications are moving to the L2 layer in a heterogeneous network, I hear that if you live in a specific area, you won't be able to get out. That's not the case at the level of parachains and implementation in Polkadot. Both architectures are worth watching, as, in my opinion, the engineering implementation follows the mainstream path of becoming a global computer. They differ slightly, but there are many similarities. There's an enormous amount of engineering work everywhere. As we see, human civilization, in the form of a multitude of researchers, engineers, and growing developers with significant resources for further development, is moving roughly in the same direction from the smallest early stage to probably some future establishment of the world's computer, all on the same tracks.": "En misschien nog een interessant verhaal in dit deel van de lezing: tot nu toe kunnen we ons nauwelijks voorstellen dat er juiste cross-chain berichten zijn tussen L2-netwerken in Ethereum. Misschien heb ik iets gemist in de papers, maar als je geen externe ring hebt en problemen zoals collators, paravalidators en gegevensbeschikbaarheidsdiensten niet zijn opgelost, is het uitdagend om na te denken over hoe twee L2-lagen kunnen communiceren. Toch bestaat dit in Polkadot. Zelfs horizontaal, via de relay chain, wat betekent dat men direct een transactie veilig van de ene parachain naar de andere kan sturen, zonder enige bruggen tussen deze twee parachains te vertrouwen. Dit is een andere cruciale functionaliteit die waarschijnlijk op het niveau van het verbinden van L2-netwerken moet worden geïmplementeerd. Slimme contracten in Ethereum communiceren goed. We hebben veel ketens van gekoppelde slimme contracten gecreëerd, waarbij de ene de andere activeert. Hiermee is er geen probleem. Maar als we zeggen dat bijna alle toepassingen naar de L2-laag in een heterogeen netwerk verhuizen, hoor ik dat als je in een specifiek gebied woont, je niet kunt ontsnappen. Dat is niet het geval op het niveau van parachains en implementatie in Polkadot. Beide architecturen zijn het waard om in de gaten te houden, aangezien naar mijn mening de technische implementatie het mainstream pad volgt om een wereldwijde computer te worden. Ze verschillen enigszins, maar er zijn veel overeenkomsten. Er is een enorme hoeveelheid technisch werk overal. Zoals we zien, beweegt de menselijke beschaving, in de vorm van een veelheid van onderzoekers, ingenieurs en groeiende ontwikkelaars met aanzienlijke middelen voor verdere ontwikkeling, ruwweg in dezelfde richting vanaf het kleinste beginstadium tot waarschijnlijk een toekomstige oprichting van 's werelds computer, allemaal op dezelfde sporen.",
  "Part 1: The Idea of a World Computer": "Deel 1: Het Idee van een Wereldcomputer",
  "This is the first part of a four-part lecture titled \"World Computer in Your Home.\" In the first part, titled \"The Idea of a World Computer,\" I want to analyze and share my own reflections that have, in a broader historical context, gathered around the hashtag \"world computer.\"": "Dit is het eerste deel van een vierdelige lezing getiteld \"Wereldcomputer in Jouw Huis.\" In het eerste deel, getiteld \"Het Idee van een Wereldcomputer,\" wil ik mijn eigen reflecties analyseren en delen die, in een breder historisch perspectief, zijn verzameld rond de hashtag \"wereldcomputer.\"",
  "To begin with, let's try to gather a generalized understanding of what a world computer is, without delving into terminology or specific technical details. If you take your mobile phone in hand and look at the icons, you can notice that practically every application on the phone has two major segments or areas of operation.": "Laten we om te beginnen proberen een algemeen begrip te krijgen van wat een wereldcomputer is, zonder in te gaan op terminologie of specifieke technische details. Als je je mobiele telefoon in de hand neemt en naar de pictogrammen kijkt, kun je opmerken dat praktisch elke toepassing op de telefoon twee belangrijke segmenten of werkgebieden heeft.",
  "The first is the local part, meaning, for example, your calculator or notes application. This is a completely local application that requires almost no external communication. Although even applications like the notes app on an iPhone are a bit more than that, let's focus on the more austere Open Source side of applications for Android phones, so to speak.": "Het eerste is het lokale deel, wat betekent dat bijvoorbeeld je rekenmachine of notitie-applicatie. Dit is een volledig lokale toepassing die bijna geen externe communicatie vereist. Hoewel zelfs toepassingen zoals de notitie-app op een iPhone iets meer zijn dan dat, laten we ons richten op de meer sobere Open Source kant van toepassingen voor Android-telefoons, zogezegd.",
  "The second part requires cloud infrastructure, and here, when the question of cloud infrastructure arises, a multitude of quite complex stories begins: who owns this cloud infrastructure, what capabilities do developers have to add features to an application, and in general, how does the user own this application? What capabilities and responsibilities does the user have when dealing with an application that exists not only on their phone but also in some infrastructure beyond their pocket or palm? The world computer is precisely one example of how the developer community responds to these obvious questions. Obvious questions about creating higher-quality applications for your mobile phone, laptop, server, and any other smart device that needs to connect to the network and obtain knowledge from there.": "Het tweede deel vereist cloud-infrastructuur, en hier, wanneer de vraag naar cloud-infrastructuur opkomt, beginnen een veelheid van behoorlijk complexe verhalen: wie bezit deze cloud-infrastructuur, welke mogelijkheden hebben ontwikkelaars om functies aan een toepassing toe te voegen, en in het algemeen, hoe bezit de gebruiker deze toepassing? Welke mogelijkheden en verantwoordelijkheden heeft de gebruiker bij het omgaan met een toepassing die niet alleen op hun telefoon bestaat, maar ook in een infrastructuur buiten hun zak of handpalm? De wereldcomputer is precies een voorbeeld van hoe de ontwikkelaarsgemeenschap reageert op deze voor de hand liggende vragen. Voor de hand liggende vragen over het creëren van hoogwaardige toepassingen voor je mobiele telefoon, laptop, server en elk ander slim apparaat dat verbinding moet maken met het netwerk en daar kennis moet opdoen.",
  "The world computer is, accordingly, the same cloud, the same infrastructure that exists on the internet, with which developers can interact and publish their applications. As a user, you can install, download, and run them on your PC. However, with one interesting, crucial feature: no one actually owns the infrastructure or cloud of the world computer. There is no specific company, jurisdiction, or individual on Earth who can determine and say whether you can publish your application there or not, whether you have the right to access this world computer infrastructure to receive the provided service. Therefore, the world computer is a cloud in which any developer can place their application, and any user with access solely to the internet network and not to a specific IP address behind a firewall can use the application by paying for computations from their pocket.": "De wereldcomputer is dus dezelfde cloud, dezelfde infrastructuur die op internet bestaat, waarmee ontwikkelaars kunnen interageren en hun applicaties kunnen publiceren. Als gebruiker kunt u ze installeren, downloaden en uitvoeren op uw pc. Echter, met één interessante, cruciale functie: niemand bezit eigenlijk de infrastructuur of cloud van de wereldcomputer. Er is geen specifiek bedrijf, rechtsgebied of individu op aarde die kan bepalen en zeggen of u uw applicatie daar kunt publiceren of niet, of u het recht hebt om toegang te krijgen tot deze wereldcomputerinfrastructuur om de geleverde service te ontvangen. Daarom is de wereldcomputer een cloud waarin elke ontwikkelaar zijn applicatie kan plaatsen, en elke gebruiker met alleen toegang tot het internetnetwerk en niet tot een specifiek IP-adres achter een firewall kan de applicatie gebruiken door te betalen voor berekeningen vanuit hun zak.",
  "Here's the story in a generalized format. There is no mention of \"blockchain,\" no mention of \"smart contracts,\" but these concepts are underneath. Let's still acknowledge: a world computer is a cloud infrastructure that is sovereign, owned by no one, allowing each developer to avoid censorship from platform owners offering app downloads. It also prevents users from being in a situation where they don't understand how an app works on their phone. In my opinion, these are important and cool features deserving respect and attention from those who want to create more futuristic, cooler applications. This is precisely what my team and I have been doing for eight years, choosing perhaps the most challenging area - creating services for robotics on the world computer, which seems to be right outside your door, quietly scraping and saying, \"I want to come into your home.\"": "Hier is het verhaal in een gegeneraliseerd formaat. Er wordt niet gesproken over \"blockchain,\" geen vermelding van \"slimme contracten,\" maar deze concepten zitten eronder. Laten we toch erkennen: een wereldcomputer is een cloudinfrastructuur die soeverein is, eigendom van niemand, waardoor elke ontwikkelaar censuur van platformeigenaars die app-downloads aanbieden kan vermijden. Het voorkomt ook dat gebruikers in een situatie terechtkomen waarin ze niet begrijpen hoe een app werkt op hun telefoon. Naar mijn mening zijn dit belangrijke en coole functies die respect en aandacht verdienen van degenen die meer futuristische, coolere applicaties willen maken. Dit is precies wat mijn team en ik al acht jaar doen, misschien wel het meest uitdagende gebied kiezen - het creëren van diensten voor robotica op de wereldcomputer, die lijkt te staan net buiten uw deur, rustig schrapend en zeggend: \"Ik wil uw huis binnenkomen.\"",
  "Now, let's move on to a timeline and look through my personal experience at how the concept of the world computer evolved. First, let's go back to 2012. This year is notable because Bitcoin already exists as a global internet service, accessible to everyone, not owned by anyone specific. By 2012, besides Bitcoin, its so-called forks start appearing. One of the most well-known is Litecoin.": "Nu gaan we verder met een tijdslijn en kijken naar mijn persoonlijke ervaring met hoe het concept van de wereldcomputer is geëvolueerd. Laten we eerst teruggaan naar 2012. Dit jaar is opmerkelijk omdat Bitcoin al bestaat als een wereldwijde internetdienst, toegankelijk voor iedereen, niet eigendom van iemand specifiek. Tegen 2012, naast Bitcoin, beginnen zijn zogenaamde forks te verschijnen. Een van de bekendste is Litecoin.",
  "Litecoin is notable because its developer did the most important work for the entire community. He collected the most crucial configurable variables or constants from different parts of Bitcoin's code after the protocol was launched. This allowed specifying block generation time, block reward, and, statistically, Litecoin is more frequently forked than Bitcoin. When we say \"fork of Bitcoin,\" I can confidently say that, in most cases, it will be a fork of Litecoin.": "Litecoin is opmerkelijk omdat de ontwikkelaar het belangrijkste werk voor de hele gemeenschap heeft gedaan. Hij verzamelde de meest cruciale configureerbare variabelen of constanten uit verschillende delen van de code van Bitcoin nadat het protocol was gelanceerd. Dit maakte het mogelijk om de blokgeneratietijd, blokbeloning te specificeren, en statistisch gezien wordt Litecoin vaker geforkt dan Bitcoin. Wanneer we zeggen \"fork van Bitcoin,\" kan ik vol vertrouwen zeggen dat het in de meeste gevallen een fork van Litecoin zal zijn.",
  "Namecoin is also a fork of Bitcoin, and if memory serves me right, it was initially a direct fork from Bitcoin, and then Litecoin appeared a few months later in 2011. However, Namecoin turned out to be a bit different, paving the way for many developers mentally on where ideas underlying Bitcoin's internet service could evolve. Namecoin went beyond being just a coin; it could store identity as a database and allow an internet service to place your domain name. This was the first example where an internet service spawned from Bitcoin could have a different nature, not just like Litecoin with fast transactions but the ability to pay for storing certain information with its internal currency, an internal token. For example, the name in the .bit domain zone.": "Namecoin is ook een fork van Bitcoin, en als mijn geheugen me niet in de steek laat, was het aanvankelijk een directe fork van Bitcoin, en toen verscheen Litecoin een paar maanden later in 2011. Namecoin bleek echter een beetje anders te zijn, waardoor veel ontwikkelaars mentaal konden nadenken over waar ideeën die ten grondslag liggen aan de internetdienst van Bitcoin zich zouden kunnen ontwikkelen. Namecoin ging verder dan alleen een munt; het kon identiteit opslaan als een database en een internetdienst toestaan om uw domeinnaam te plaatsen. Dit was het eerste voorbeeld waar een internetdienst die voortkwam uit Bitcoin een andere aard kon hebben, niet alleen zoals Litecoin met snelle transacties maar ook met de mogelijkheid om te betalen voor het opslaan van bepaalde informatie met zijn interne valuta, een interne token. Bijvoorbeeld, de naam in de .bit domeinzone.",
  "Developers worldwide were experimenting with Bitcoin, mostly creating forks, making them faster, cheaper electronic cash. Alongside this, the first services appeared, seeing opportunities not only in financial applications but also in cross-industrial applications in other areas like Namecoin. Namecoin provided the first globally accessible and unowned internet service through which you could launch your website without being under the jurisdiction of a specific organization but within a distributed globally accessible network. This moment is crucial for us to move on to the early precursors of the world computer's ideas.": "Ontwikkelaars over de hele wereld experimenteerden met Bitcoin, voornamelijk door forks te maken, waardoor ze sneller, goedkoper elektronisch geld konden maken. Naast dit verschenen de eerste diensten, die kansen zagen niet alleen in financiële toepassingen maar ook in cross-industriële toepassingen in andere gebieden zoals Namecoin. Namecoin bood de eerste wereldwijd toegankelijke en onbeheerde internetdienst waarmee je je website kon lanceren zonder onder de jurisdictie van een specifieke organisatie te vallen maar binnen een gedistribueerd wereldwijd toegankelijk netwerk. Dit moment is cruciaal voor ons om verder te gaan naar de vroege voorlopers van de ideeën van de wereldcomputer.",
  "The first practical ideas of the world computer emerged in 2014, two years after the appearance of the first wave of Bitcoin forks and the creation of meaningful services dedicated not only to electronic cash but also exploring broader themes. We encounter ideas that precede the launch of Ethereum.": "De eerste praktische ideeën van de wereldcomputer ontstonden in 2014, twee jaar na het verschijnen van de eerste golf van Bitcoin forks en de creatie van betekenisvolle diensten die niet alleen gewijd waren aan elektronisch geld maar ook bredere thema's verkenden. We stuiten op ideeën die voorafgaan aan de lancering van Ethereum.",
  "In 2014, at several meetups worldwide, in Miami and, I believe, in Europe, Vitalik Buterin articulated sensible ideas. He suggests that we can develop not just a set of internet services that essentially function as a Swiss army knife, right? We can develop a virtual machine. Those with an education in Computer Science probably remember what an infinite tape is in Turing machines, and if we go back to the theory of computational machines, we probably recall the theoretical origins of creating our personal computers, essentially the server infrastructure we have today. It's interesting that, fifty years after the development of von Neumann architecture and the complete Turing machine theory, and with the dawn of internet technologies only by 2014, and only after experiments with Bitcoin, the first idea emerges on our planet of creating a fully virtual computational machine based on the same theory that has been tested in the computer science industry for the past 50 years. The mechanics are the same as when creating any personal computer or server in a data center, but based more on achievements in internet technologies and the achievements of the world that will later be called Web3.": "In 2014, op verschillende meetups wereldwijd, in Miami en, naar mijn mening, in Europa, articuleerde Vitalik Buterin zinnige ideeën. Hij suggereert dat we niet alleen een set internetdiensten kunnen ontwikkelen die in feite functioneren als een Zwitsers zakmes, toch? We kunnen een virtuele machine ontwikkelen. Degenen met een opleiding in Computerwetenschappen herinneren zich waarschijnlijk wat een oneindige tape is in Turingmachines, en als we teruggaan naar de theorie van computationele machines, herinneren we ons waarschijnlijk de theoretische oorsprongen van het creëren van onze persoonlijke computers, in wezen de serverinfrastructuur die we vandaag de dag hebben. Het is interessant dat, vijftig jaar na de ontwikkeling van de von Neumann-architectuur en de volledige Turingmachinetheorie, en met het aanbreken van internettechnologieën pas tegen 2014, en pas na experimenten met Bitcoin, het eerste idee op onze planeet opduikt om een volledig virtuele computationele machine te creëren op basis van dezelfde theorie die de afgelopen 50 jaar is getest in de computerwetenschapsindustrie. De mechanica zijn hetzelfde als bij het maken van elke persoonlijke computer of server in een datacenter, maar gebaseerd op meer prestaties in internettechnologieën en de prestaties van de wereld die later Web3 zal worden genoemd.",
  "Ethereum itself is not a Swiss army knife, not a set of specific internet services. It is, in the direct sense, a cloud, a computational machine. What lies at its core, I will tell you in the next lecture. Here, the most important thing for us is to focus on where the idea of Ethereum began. It started with the realization that, in two years, dozens of different internet services were invented that were interesting because they were globally accessible, available without censorship for developers to deploy. Users could use them only with an internal currency. However, what was not liked in all these concepts was that almost every interesting service required its own massive distributed infrastructure. Unlike familiar internet services, you couldn't just launch your globally accessible infrastructure if you were a very small person or a small team because such a network would be vulnerable, and the service itself would become unsafe. To overcome the problems that were side effects or negative externalities of creating your own globally accessible sovereign internet service, the concept of Ethereum emerged. Ethereum, as a full-fledged cloud capable of handling any formalized computation, allows you to write your program code, a complete program essentially, and run it in the same blockchain alongside hundreds of other applications. This possibility, sounding from the small stages of 2014, naturally captivated the minds of many and seemed absolutely logical for someone with a basic education in Computer Science. If you could understand what Turing completeness was by 2014, if you could envision the historical theory of creating a personal computer, you would definitely not overlook the Ethereum whitepaper and would say that this is exactly what the entire developer community needs.": "Ethereum zelf is geen Zwitsers zakmes, geen set specifieke internetdiensten. Het is, in de directe zin, een wolk, een rekenmachine. Wat er aan de kern ligt, zal ik je vertellen in de volgende lezing. Hier is het belangrijkste voor ons om ons te richten op waar het idee van Ethereum begon. Het begon met het besef dat, in twee jaar tijd, tientallen verschillende internetdiensten werden uitgevonden die interessant waren omdat ze wereldwijd toegankelijk waren, beschikbaar zonder censuur voor ontwikkelaars om te implementeren. Gebruikers konden ze alleen gebruiken met een interne valuta. Wat echter niet leuk was aan al deze concepten was dat bijna elke interessante dienst zijn eigen massaal gedistribueerde infrastructuur vereiste. In tegenstelling tot bekende internetdiensten kon je niet zomaar je wereldwijd toegankelijke infrastructuur lanceren als je een heel klein persoon of een klein team was, omdat zo'n netwerk kwetsbaar zou zijn en de dienst zelf onveilig zou worden. Om de problemen te overwinnen die bijwerkingen of negatieve externe effecten waren van het creëren van je eigen wereldwijd toegankelijke soevereine internetdienst, ontstond het concept van Ethereum. Ethereum, als een volwaardige wolk die in staat is om elke geformaliseerde berekening aan te kunnen, stelt je in staat om je programmacode te schrijven, een compleet programma in wezen, en het uit te voeren in dezelfde blockchain naast honderden andere toepassingen. Deze mogelijkheid, die klonk vanaf de kleine stadia van 2014, boeide natuurlijk de geesten van velen en leek absoluut logisch voor iemand met een basisopleiding in Computerwetenschappen. Als je tegen 2014 kon begrijpen wat Turing-volledigheid was, als je de historische theorie van het creëren van een persoonlijke computer kon voorstellen, zou je zeker niet het Ethereum-whitepaper over het hoofd zien en zou je zeggen dat dit precies is wat de hele ontwikkelaarsgemeenschap nodig heeft.",
  "I believe the year 2014 and Ethereum mark the first, though not explicitly named, instances of the concept of a global computer. It started with the idea that we don't need a Swiss knife; instead, we need infrastructure or a universal cloud that addresses global-level security challenges. Developers, at a low cost, should be able to deploy their applications there without concerning themselves with issues like securing the network or creating a network of providers for this computer or your specific internet service.": "Ik geloof dat het jaar 2014 en Ethereum de eerste, zij het niet expliciet genoemde, gevallen markeren van het concept van een wereldwijde computer. Het begon met het idee dat we geen Zwitsers zakmes nodig hebben; in plaats daarvan hebben we infrastructuur of een universele wolk nodig die wereldwijde beveiligingsuitdagingen aanpakt. Ontwikkelaars moeten daar tegen lage kosten hun toepassingen kunnen implementeren zonder zich zorgen te hoeven maken over zaken als het beveiligen van het netwerk of het creëren van een netwerk van providers voor deze computer of uw specifieke internetdienst.",
  "In 2015, Ethereum was effectively launched. From that moment onwards, even until 2020, I haven't encountered significant counterarguments against the idea of creating not just specific internet services but embracing and developing the concept of a virtual computer, virtual server, cloud, or a global computer, as I prefer to call it.": "In 2015 werd Ethereum effectief gelanceerd. Vanaf dat moment tot zelfs 2020 ben ik geen significante tegenargumenten tegengekomen tegen het idee om niet alleen specifieke internetdiensten te creëren, maar het concept van een virtuele computer, virtuele server, wolk of een wereldwijde computer te omarmen en te ontwikkelen, zoals ik het liever noem.",
  "Various variations emerge, perhaps some remember the then-popular EOS suggesting a slightly different consumption paradigm. Despite my personal aversion to that project, with its 21st validator and all, it seemed sufficient for many. But it introduced the idea that owning tokens grants you a portion of bandwidth, which, in the realm of Robonomics architecture, remains interesting to me to this day.": "Verschillende variaties komen naar voren, misschien herinneren sommigen zich de toen populaire EOS die een iets ander consumptieparadigma suggereerde. Ondanks mijn persoonlijke afkeer van dat project, met zijn 21e validator en al, leek het voldoende voor velen. Maar het introduceerde het idee dat het bezitten van tokens je een deel van de bandbreedte geeft, wat, in het rijk van de Robonomics-architectuur, tot op de dag van vandaag interessant voor me blijft.",
  "Simultaneously, other ideas on how to modernize the Ethereum network arise. Projects like Definity, Solana, and others come into play. Around the same time, Gavin Wood introduces Polkadot, who assisted Vitalik in creating Ethereum. From a multitude of technological projects between 2015 and 2020, we move from a race to create individual internet service variants to witnessing, on a communication protocol level, the emergence of something like Ethereum killers. Many projects started under this slogan, taking the idea of a unified cloud for multiple internet services and modifying some aspects. For instance, EOS proposed an alternative utilization scheme, where only token-backed ownership allowed access to bandwidth. There were projects where the programming language for writing code was more interesting. For example, during a hackathon for BMW, when we won with an implementation on Ethereum, the automaker immediately stated that we wouldn't go any further unless we had formally verified contracts, which was impossible to achieve on Ethereum at that time.": "Tegelijkertijd ontstaan andere ideeën over hoe het Ethereum-netwerk gemoderniseerd kan worden. Projecten zoals Definity, Solana en anderen komen in beeld. Rond dezelfde tijd introduceert Gavin Wood Polkadot, die Vitalik heeft geholpen bij het creëren van Ethereum. Van een veelheid aan technologische projecten tussen 2015 en 2020 gaan we van een race om individuele internetdienstvarianten te creëren naar het waarnemen, op communicatieprotocolniveau, van iets als Ethereum-killers. Veel projecten begonnen onder deze slogan, waarbij het idee van een verenigde cloud voor meerdere internetdiensten werd overgenomen en sommige aspecten werden aangepast. Bijvoorbeeld, EOS stelde een alternatief gebruiksschema voor, waarbij alleen door tokens gesteunde eigendom toegang tot bandbreedte mogelijk maakte. Er waren projecten waarbij de programmeertaal voor het schrijven van code interessanter was. Bijvoorbeeld, tijdens een hackathon voor BMW, toen we wonnen met een implementatie op Ethereum, verklaarde de autofabrikant onmiddellijk dat we niet verder zouden gaan tenzij we formeel geverifieerde contracten hadden, wat destijds onmogelijk was op Ethereum.",
  "At this moment, as you read about the ideas of Eternity and other networks, you may think, \"I should try working with them too.\" Service developers understood this, as did, as I mentioned, projects like Definity, which recently launched the World Computer and is gaining traction. Simultaneously, the idea of Polkadot emerges as a heterogeneous multi-chain framework. Ethereum, around the mid-2010s, also received a roadmap for scalability and development. By 2024, almost all concepts converge on the idea of having not just one database or blockchain but a multitude. Various transaction processing methods, two-layer consensus algorithms, optimistic majority approaches, and a plethora of technical implementation variations emerge, all aiming at the same global computer concept.": "Op dit moment, terwijl je leest over de ideeën van Eternity en andere netwerken, zou je kunnen denken: \"Ik zou ook moeten proberen met hen te werken.\" Dienstontwikkelaars begrepen dit, net als, zoals ik al zei, projecten zoals Definity, die onlangs de World Computer lanceerden en aan populariteit winnen. Tegelijkertijd ontstaat het idee van Polkadot als een heterogeen multi-chain framework. Ethereum ontving rond het midden van de jaren 2010 ook een routekaart voor schaalbaarheid en ontwikkeling. Tegen 2024 convergeren bijna alle concepten naar het idee van niet slechts één database of blockchain, maar een veelheid. Diverse transactieverwerkingsmethoden, tweelaagse consensusalgoritmen, optimistische meerderheidsbenaderingen en een overvloed aan technische implementatievariaties komen naar voren, allemaal gericht op hetzelfde wereldwijde computerconcept.",
  "Let's now go through a timeline snapshot:": "Laten we nu een tijdslijnsnapshot doornemen:",
  "**2009-2012**: Emergence of the first globally accessible internet service for electronic cash - Bitcoin.": "**2009-2012**: Opkomst van de eerste wereldwijd toegankelijke internetdienst voor elektronisch geld - Bitcoin.",
  "**Early 2012**: The first fork war occurs, with projects emerging to replicate similar services. Some multi-billion projects create their forks. Simultaneously, projects like Namecoin propose interesting ideas.": "**Begin 2012**: De eerste fork-oorlog vindt plaats, waarbij projecten opkomen om vergelijkbare diensten te repliceren. Enkele miljardenprojecten creëren hun forks. Tegelijkertijd stellen projecten zoals Namecoin interessante ideeën voor.",
  "**2014**: The concept of a world computer emerges, requiring a deep understanding of computer science theory and immersion in Bitcoin's development.": "**2014**: Het concept van een wereldcomputer ontstaat, waarvoor een diepgaand begrip van de computertechnologietheorie en onderdompeling in de ontwikkeling van Bitcoin vereist is.",
  "**2015-2020**: The concept moves from theory to practice. Modifications and variations of Ethereum arise, introducing different ideas with varying degrees of quality. The term \"World Computer\" became established.": "**2015-2020**: Het concept verplaatst zich van theorie naar praktijk. Aanpassingen en variaties van Ethereum ontstaan, waarbij verschillende ideeën met verschillende kwaliteitsniveaus worden geïntroduceerd. De term \"World Computer\" werd gevestigd.",
  "**2024**: We reach the World Computer, a term now well-established, marking the transition from a simple calculator on your phone to a globally accessible institution. The idea of the World Computer encompasses future money, programming money, storage for identification records, and important documents.": "**2024**: We bereiken de World Computer, een term die nu goed is ingeburgerd, wat de overgang markeert van een eenvoudige rekenmachine op je telefoon naar een wereldwijd toegankelijke instelling. Het idee van de World Computer omvat toekomstig geld, programmeergeld, opslag voor identificatierecords en belangrijke documenten.",
  "In conclusion, from a simple calculator to a globally accessible institution, the idea of the World Computer has evolved. It's seen as a place for the future of money and the storage of vital records. The concept of a World Computer has progressed from theoretical discussions to practical engineering implementations. In the next lecture, the discussion will delve into what a World Computer actually represents. It is fundamentally a state transition function, a concept to be explored further in the upcoming lecture, emphasizing its importance and the need to safeguard it.": "Tot slot, van een eenvoudige rekenmachine naar een wereldwijd toegankelijke instelling, heeft het idee van de World Computer zich ontwikkeld. Het wordt gezien als een plek voor de toekomst van geld en de opslag van vitale gegevens. Het concept van een World Computer is geëvolueerd van theoretische discussies naar praktische technische implementaties. In de volgende lezing zal de discussie ingaan op wat een World Computer eigenlijk vertegenwoordigt. Het is fundamenteel een toestandsovergangsfunctie, een concept dat verder zal worden verkend in de komende lezing, waarbij de nadruk wordt gelegd op het belang ervan en de noodzaak om het te beschermen.",
  "Part 2: The Heart of the World Computer": "Deel 2: Het Hart van de Wereldcomputer",
  "What lies at the core of projects like Ethereum or Polkadot, or any other web3 project claiming the title of the world computer, and why does the comparison with the heart in the human body fit so well into the abstract architecture of the world computer?": "Wat ligt aan de kern van projecten zoals Ethereum of Polkadot, of een ander web3-project dat de titel van de wereldcomputer claimt, en waarom past de vergelijking met het hart in het menselijk lichaam zo goed in de abstracte architectuur van de wereldcomputer?",
  "Let's try to understand these questions in this part of the lecture, and to begin with, we'll have to break the chains of Bitcoin maximalists a bit. Most likely, you've already read one or several popular science articles dedicated to Bitcoin in your life, and the main thing that is practically noted everywhere is the three main advantages of Bitcoin as electronic cash:": "Laten we proberen deze vragen te begrijpen in dit deel van de lezing, en om te beginnen, zullen we de ketenen van Bitcoin maximalisten een beetje moeten doorbreken. Waarschijnlijk heb je al een of meerdere populaire wetenschappelijke artikelen over Bitcoin gelezen in je leven, en het belangrijkste dat praktisch overal wordt opgemerkt, zijn de drie belangrijkste voordelen van Bitcoin als elektronisch geld:",
  "Censorship resistance": "Censuurweerstand",
  "Immutability of data stored in the Bitcoin blockchain": "Onveranderlijkheid van gegevens opgeslagen in de Bitcoin blockchain",
  "Transparency of transactions": "Transparantie van transacties",
  "Let's quickly go through each of these properties, and most importantly, at the end, we'll need to step back a bit from them, as the world computer inherits them as some kind of successor to Bitcoin.": "Laten we snel door elk van deze eigenschappen gaan, en het belangrijkste is dat we aan het einde een beetje moeten terugstappen, aangezien de wereldcomputer ze erft als een soort opvolger van Bitcoin.",
  "**Firstly**, immutability of data. Of course, this property, from the perspective of electronic cash, has significant advantages and importance. After you send a transaction or receive bitcoins, after one or two blocks, you gradually begin to feel the immutability of data in the blockchain. In the first 15 minutes, you can observe, using a blockchain explorer, how the transaction should settle. You already see it in the network, but it is not finalized, meaning these bitcoins are not yet in your account. However, after several blocks, there is confidence that these funds will not disappear from your account. As time passes, the probability of values being somehow overwritten from your account becomes almost negligible, practically reducing to zero. This is our property of data immutability. How cool it is when you can share information with the recipient, send them a link to the blockchain explorer, and you don't need to obtain any paper or document from the bank stating that you sent a payment on a certain date and time - this is the second advantage of Bitcoin that is very helpful in practice and is probably the most pleasant perk when comparing a bank transfer and a Bitcoin transfer.": "**Ten eerste**, onveranderlijkheid van gegevens. Natuurlijk heeft deze eigenschap, vanuit het perspectief van elektronisch geld, aanzienlijke voordelen en belang. Nadat je een transactie hebt verzonden of bitcoins hebt ontvangen, begin je na één of twee blokken geleidelijk de onveranderlijkheid van gegevens in de blockchain te voelen. In de eerste 15 minuten kun je, met behulp van een blockchain-verkenner, zien hoe de transactie zou moeten worden afgehandeld. Je ziet het al in het netwerk, maar het is nog niet definitief, wat betekent dat deze bitcoins nog niet op je rekening staan. Na enkele blokken is er echter vertrouwen dat deze fondsen niet van je rekening zullen verdwijnen. Naarmate de tijd verstrijkt, wordt de waarschijnlijkheid dat waarden op de een of andere manier van je rekening worden overschreven bijna verwaarloosbaar, praktisch teruggebracht tot nul. Dit is onze eigenschap van gegevensonveranderlijkheid. Hoe gaaf is het als je informatie kunt delen met de ontvanger, ze een link naar de blockchain-verkenner kunt sturen, en je geen papier of document van de bank hoeft te verkrijgen waarin staat dat je een betaling hebt gedaan op een bepaalde datum en tijd - dit is het tweede voordeel van Bitcoin dat zeer nuttig is in de praktijk en waarschijnlijk de meest aangename extraatje is bij het vergelijken van een bankoverschrijving en een Bitcoin-overdracht.",
  "**Secondly**, transparency of transactions. There is practically no fear when using Bitcoin that you will find yourself in a region of the world or connected to an internet provider through which you cannot perform operations with the Bitcoin network. There are practically no options other than locking you in a dark room without internet access so that you cannot use the Bitcoin network.": "**Ten tweede**, transparantie van transacties. Er is praktisch geen angst bij het gebruik van Bitcoin dat je jezelf in een regio van de wereld bevindt of verbonden bent met een internetprovider waarmee je geen operaties kunt uitvoeren met het Bitcoin-netwerk. Er zijn praktisch geen andere opties dan je op te sluiten in een donkere kamer zonder internettoegang zodat je het Bitcoin-netwerk niet kunt gebruiken.",
  "These three properties are, of course, very important. Now, in order to understand the question \"What is at the heart of the world computer,\" we will need to step back from them, abstract ourselves, and make a small leap of faith, a jump, approximately, 100 years back to the 1930s.": "Deze drie eigenschappen zijn natuurlijk erg belangrijk. Nu, om de vraag \"Wat is het hart van de wereldcomputer\" te begrijpen, zullen we een stap terug moeten doen, onszelf abstraheren en een kleine sprong van geloof maken, een sprong, ongeveer, 100 jaar terug naar de jaren 1930.",
  "In 1936, Alan Turing made a proposal to the scientific community to solve the formalization problem and, in fact, a more qualitative description of such a concept as an algorithm. Interestingly, from Alan Turing's proposal, the architecture and development of all computer science in the future emerged, but he in no way pursued the idea of creating a personal computer, and he knew nothing about data centers or clouds. His task was to provide a way to define an algorithm in the context of the tasks faced by mathematicians. It's a fascinating picture over the span of a century that the achievement of computer science turns out to be a by-product of a rather mundane problem among mathematicians.": "In 1936 deed Alan Turing een voorstel aan de wetenschappelijke gemeenschap om het formaliseringsprobleem op te lossen en, in feite, een meer kwalitatieve beschrijving van zo'n concept als een algoritme. Interessant genoeg kwam uit het voorstel van Alan Turing de architectuur en ontwikkeling van alle informatica in de toekomst voort, maar hij heeft op geen enkele manier de idee nagestreefd om een persoonlijke computer te creëren, en hij wist niets over datacenters of clouds. Zijn taak was om een manier te bieden om een algoritme te definiëren in de context van de taken waarmee wiskundigen werden geconfronteerd. Het is een fascinerend beeld over de loop van een eeuw dat de prestatie van de informatica blijkt een bijproduct te zijn van een nogal alledaags probleem onder wiskundigen.",
  "Let's delve into what Alan Turing proposed, without delving too deeply into algorithm theory and the purpose for which he suggested it. Alan Turing proposed the Turing machine, which represents an infinite tape (we can call it memory cells to make it easier), traversed by a reading and writing head. This head, positioned over a certain cell, can read data, apply some simple operations to them, and write new values.": "Laten we ingaan op wat Alan Turing voorstelde, zonder al te diep in te gaan op de algoritmetheorie en het doel waarvoor hij het voorstelde. Alan Turing stelde de Turing-machine voor, die een oneindige tape vertegenwoordigt (we kunnen het geheugencellen noemen om het gemakkelijker te maken), doorkruist door een lees- en schrijfkop. Deze kop, gepositioneerd boven een bepaalde cel, kan gegevens lezen, er enkele eenvoudige bewerkingen op toepassen en nieuwe waarden schrijven.",
  "Today, when you hear phrases like this, it might seem to you: \"Well, yes, it's a hard drive, a computer, or something like that.\" That's absolutely correct. This description gave rise to the first computer architecture. However, the main task of the Turing machine was to provide a means of representing a system or entity capable of performing any formalized computations. One can imagine a box or room, even filled with lamps, into which you insert your punch card, card, or transmit a Bluetooth signal, and the machine starts working, performing simple operations that ultimately solve your problem. Thus, the Turing machine is a universal computational mechanism that primarily solves the universal and essential task of providing a mechanism through which any simple computation or, more accurately, any formalized computation can be performed—computations that can be decomposed into the language of mathematics": "Vandaag, wanneer je zinnen als deze hoort, lijkt het je misschien: \"Nou, ja, het is een harde schijf, een computer, of zoiets.\" Dat is helemaal correct. Deze beschrijving gaf aanleiding tot de eerste computerarchitectuur. De belangrijkste taak van de Turing-machine was echter om een middel te bieden om een systeem of entiteit voor te stellen die in staat is om elke geformaliseerde berekening uit te voeren. Men kan zich een doos of kamer voorstellen, zelfs gevuld met lampen, waarin je je ponskaart, kaart, of een Bluetooth-signaal invoert, en de machine begint te werken, eenvoudige bewerkingen uitvoerend die uiteindelijk uw probleem oplossen. Zo is de Turing-machine een universeel rekenmechanisme dat in de eerste plaats het universele en essentiële doel oplost om een mechanisme te bieden waarmee elke eenvoudige berekening of, nauwkeuriger gezegd, elke geformaliseerde berekening kan worden uitgevoerd—berekeningen die kunnen worden ontleed in de taal van de wiskunde",
  "In essence, the task of the last 100 years, after finding some solution in the field of mathematics, was precisely to give it a physical form, to find the set of transistors that could be placed on a board, learn how to solder them all, reduce the processes of the computing processor, and so on. No wonder that the theory from 1936 finds application in 2014 for the ideas of the world computer. These 100 years were occupied, in general, in another area—the field of physically implementing this computer.": "In essentie was de taak van de laatste 100 jaar, na het vinden van een oplossing op het gebied van wiskunde, precies om het een fysieke vorm te geven, om de set transistors te vinden die op een bord konden worden geplaatst, te leren hoe ze allemaal te solderen, de processen van de rekenprocessor te verminderen, enzovoort. Het is dan ook geen wonder dat de theorie uit 1936 in 2014 toepassing vindt voor de ideeën van de wereldcomputer. Deze 100 jaar werden over het algemeen besteed in een ander gebied—het gebied van het fysiek implementeren van deze computer.",
  "When the planet became saturated, and we had personal computers, computational machines even inside smart devices, and when data centers started growing on the planet, the question shifted from the hardware solution to how the computational machine might look not at the physical or mathematically abstract level but at some non-physical, perhaps metaphysical, level relative to the entire planet. However, the foundation remains the same: the state transition function and nothing else.": "Toen de planeet verzadigd raakte en we persoonlijke computers hadden, rekenmachines zelfs in slimme apparaten, en toen datacenters begonnen te groeien op de planeet, verschoof de vraag van de hardware-oplossing naar hoe de rekenmachine eruit zou kunnen zien niet op fysiek of wiskundig abstract niveau maar op een niet-fysiek, misschien metafysisch niveau ten opzichte van de hele planeet. De basis blijft echter hetzelfde: de toestandsovergangsfunctie en niets anders.",
  "As an addition to what has been said, so that we don't only dwell on the theory of 1936 and don't just break the shackles of Bitcoin maximalists, open the Ethereum white paper. There you will find the crucial phrase \"Turing complete machine\"—this is the main definition of Ethereum. A Turing complete machine means that Ethereum can handle any simple operations described in a formal language, operations that are possible. This is not some set of operations that Ethereum can provide as a calculator or a sophisticated calculator for scientists. Instead, it is an abstraction inside which it is possible to load any possible variations, manipulations with variables, constants, additions, calculations with any states, and so on. You won't find anything different from what Turing proposed in the 1930s in the Ethereum concept. You will find an engineering implementation of how to do it. If we move on and open the Polkadot wiki, it's a bit more challenging to find. For this, you should use the search, enter \"State transition,\" and in the search results, find several mentions that Polkadot guarantees nothing else but the state transition. Neither the storage of data in the Polkadot blockchain nor any additional services—only the purest change of state caused by incoming transactions and processed by Polkadot validators. Now, let's try to delve more into this.": "Als toevoeging op wat er is gezegd, zodat we niet alleen blijven hangen in de theorie van 1936 en niet alleen de ketenen van Bitcoin maximalisten verbreken, open dan het Ethereum whitepaper. Daar vind je de cruciale zin \"Turing complete machine\"—dit is de belangrijkste definitie van Ethereum. Een Turing complete machine betekent dat Ethereum elke eenvoudige operatie kan uitvoeren die is beschreven in een formele taal, operaties die mogelijk zijn. Dit is niet een set operaties die Ethereum kan bieden als een rekenmachine of een geavanceerde rekenmachine voor wetenschappers. In plaats daarvan is het een abstractie waarbinnen het mogelijk is om elke mogelijke variatie, manipulatie met variabelen, constanten, toevoegingen, berekeningen met alle toestanden, enzovoort te laden. Je zult niets anders vinden dan wat Turing in de jaren 1930 voorstelde in het Ethereum-concept. Je zult een technische implementatie vinden van hoe je het moet doen. Als we verder gaan en de Polkadot wiki openen, is het wat moeilijker te vinden. Hiervoor moet je de zoekfunctie gebruiken, \"Toestandsovergang\" invoeren en in de zoekresultaten meerdere vermeldingen vinden dat Polkadot niets anders garandeert dan de toestandsovergang. Noch de opslag van gegevens in de Polkadot blockchain, noch enige aanvullende diensten—alleen de zuiverste verandering van toestand veroorzaakt door inkomende transacties en verwerkt door Polkadot validators. Laten we nu proberen hier dieper op in te gaan.",
  "Now, let's add a bit to this linear diagram to move from the theory of the 1930s to today's realities, where we describe the abstract picture of the world computer. To do this, let's consider an example with Alice and Bob. Alice, being in the office, wants to start Bob's home vacuum robot for cleaning. If we look at today's concepts of how the link between Alice's mobile application and the robot vacuum at home is implemented, you will see roughly the following picture: Alice's mobile application generates a transaction in some cloud where calculations take place, and the output of these calculations is the output values that effectively turn into a command to start the vacuum robot. It would be useful for us, from the field of robotics and Robonomics as concepts in the world of web3, to understand that in the cloud, there is a digital twin of this robot, and its state is changed. We can, in general, not go that far and stop at the fact that Alice sends a transaction to the cloud, and the cloud, having performed all the necessary calculations and manipulations, generates a command to start Bob's vacuum robot.": "Nu voegen we een beetje toe aan dit lineaire diagram om van de theorie van de jaren 1930 naar de realiteiten van vandaag te gaan, waar we het abstracte beeld van de wereldcomputer beschrijven. Laten we hiervoor een voorbeeld bekijken met Alice en Bob. Alice, die op kantoor is, wil de stofzuigrobot van Bob thuis starten voor het schoonmaken. Als we kijken naar de concepten van vandaag over hoe de link tussen de mobiele applicatie van Alice en de stofzuigrobot thuis van Bob wordt geïmplementeerd, ziet u ongeveer het volgende beeld: de mobiele applicatie van Alice genereert een transactie in een of andere cloud waar berekeningen plaatsvinden, en de output van deze berekeningen zijn de uitvoerwaarden die effectief veranderen in een opdracht om de stofzuigrobot te starten. Het zou nuttig voor ons zijn, vanuit het veld van robotica en Robonomics als concepten in de wereld van web3, om te begrijpen dat er in de cloud een digitale tweeling van deze robot is, en dat de staat ervan verandert. We kunnen over het algemeen niet zo ver gaan en stoppen bij het feit dat Alice een transactie naar de cloud stuurt, en de cloud, na alle noodzakelijke berekeningen en manipulaties te hebben uitgevoerd, een opdracht genereert om de stofzuigrobot van Bob te starten.",
  "In this scheme today, there are several main questions: if you were interacting with a physical computer in front of you or were in a room with the vacuum robot, you would approach, press a physical button, and set it in motion. What changes when instead of arrows, there is not a manual drive but a communication layer, the internet? A multitude of questions arises about how we can safely connect Alice and this cloud, how we can be sure that Alice has access to this cloud. The question of the communication network arises—how we can protect Alice from someone else addressing her vacuum robot, requesting, for example, to make a video of her entire apartment instead of cleaning, and a similar aspect arises: why would the vacuum robot listen to this cloud with such honor and integrity? Why would the robot fully trust this cloud?": "In dit schema van vandaag zijn er verschillende belangrijke vragen: als u interactie had met een fysieke computer voor u of in een kamer was met de stofzuigrobot, zou u naderen, op een fysieke knop drukken en deze in beweging zetten. Wat verandert er wanneer in plaats van pijlen, er geen handmatige aandrijving is maar een communicatielaag, het internet? Een veelheid van vragen rijst over hoe we veilig Alice en deze cloud kunnen verbinden, hoe we er zeker van kunnen zijn dat Alice toegang heeft tot deze cloud. De vraag van het communicatienetwerk rijst op - hoe kunnen we Alice beschermen tegen iemand anders die haar stofzuigrobot aanspreekt, bijvoorbeeld om een video van haar hele appartement te maken in plaats van schoon te maken, en een soortgelijk aspect rijst op: waarom zou de stofzuigrobot naar deze cloud luisteren met zoveel eer en integriteit? Waarom zou de robot volledig vertrouwen op deze cloud?",
  "Today's approach with the architecture of cloud solutions that connect your mobile phone, or rather, the application on your mobile phone, and some technology on the other side, smart devices, is based on the significant achievements in building physical computers. Computers in data centers today are something extraordinary—the level of technical processes is simply amazing. However, from the perspective of communication technologies, when you already have some experience working with internet applications, it seems that somewhere there, at the level of a technical school or college, or maybe not right next to how developers, architects of Intel processors are solving their tasks now. Almost all questions about connecting Alice to Bob boil down solely to outputting a specific access certificate on a specific IP address from both sides, linking them together, and the cloud will own and do anything. The most important thing in this scheme is to do anything, meaning to perform state transitions or operations that occur without any guarantees that for Alice, for Bob, these will be executed according to the same logic. No one can say anything about how the cloud is arranged. It is a black box where computations are not formalized, and neither Alice nor Bob knows how the computation is performed.": "De benadering van vandaag met de architectuur van cloudoplossingen die uw mobiele telefoon verbinden, of liever gezegd, de applicatie op uw mobiele telefoon, en enkele technologie aan de andere kant, slimme apparaten, is gebaseerd op de significante prestaties bij het bouwen van fysieke computers. Computers in datacenters van vandaag zijn iets buitengewoons - het niveau van technische processen is gewoon verbazingwekkend. Echter, vanuit het perspectief van communicatietechnologieën, wanneer u al enige ervaring heeft met het werken met internetapplicaties, lijkt het ergens daar, op het niveau van een technische school of hogeschool, of misschien niet direct naast hoe ontwikkelaars, architecten van Intel-processors nu hun taken oplossen. Bijna alle vragen over het verbinden van Alice met Bob komen neer op het uitvoeren van een specifiek toegangscertificaat op een specifiek IP-adres van beide kanten, ze aan elkaar koppelen, en de cloud zal bezitten en alles doen. Het belangrijkste in dit schema is om alles te doen, wat betekent het uitvoeren van toestandsovergangen of bewerkingen die plaatsvinden zonder enige garantie dat voor Alice, voor Bob, deze volgens dezelfde logica zullen worden uitgevoerd. Niemand kan iets zeggen over hoe de cloud is opgezet. Het is een black box waar berekeningen niet zijn geformaliseerd, en noch Alice noch Bob weet hoe de berekening wordt uitgevoerd.",
  "The place where you must fully trust—relying on the reputation of the company that owns these data centers, and you must completely trust the network access providers who issue a certificate and verify the security of your connection. In fact, if we talk about the boom of internet applications, this is a huge problem. The problem is that there are actually some citadels located in specific jurisdictions that operate on a relatively simple technology stack to connect you as easily as possible to the cloud, which represents a black box. Dissatisfaction with this approach actually arouses interest in the world computer because it will arrange things a bit differently. And how? Let's try to supplement the scheme we drew with blue color right now.": "De plek waar je volledig moet vertrouwen - vertrouwen op de reputatie van het bedrijf dat deze datacenters bezit, en je moet volledig vertrouwen op de netwerktoegangsproviders die een certificaat uitgeven en de beveiliging van je verbinding verifiëren. In feite, als we praten over de boom van internetapplicaties, is dit een groot probleem. Het probleem is dat er eigenlijk enkele citadellen zijn gevestigd in specifieke rechtsgebieden die werken op een relatief eenvoudige technologiestack om u zo gemakkelijk mogelijk te verbinden met de cloud, die een black box vertegenwoordigt. Onvrede met deze benadering wekt eigenlijk interesse in de wereldcomputer omdat het de dingen een beetje anders zal regelen. En hoe? Laten we proberen het schema dat we zojuist hebben getekend aan te vullen met blauw.",
  "So, to supplement our linear graph, our linear diagram from both sides, let's take a look at the discoveries that have significance in computer science and that are directly or indirectly related to achievements from the world of web3.": "Dus, om ons lineaire diagram aan beide kanten aan te vullen, laten we eens kijken naar de ontdekkingen die van belang zijn in de informatica en die direct of indirect verband houden met prestaties uit de wereld van web3.",
  "Let's start with Leslie Lamport in 1976. Those who attended my presentations, lectures from 2015-2020, probably remember how often I liked to mention that before the invention of Bitcoin, problems related to creating a decentralized network were well described by Leslie Lamport in 1976 in the Byzantine Generals problem. The solution to the Byzantine Generals problem is at the core of Tendermint PBFT algorithms and all synchronous algorithms used from Telegram Open Network to Tendermint, to Cosmos, and other blockchain projects that, accordingly, followed the path of Byzantine Generals.": "Laten we beginnen met Leslie Lamport in 1976. Degenen die mijn presentaties, lezingen van 2015-2020 hebben bijgewoond, herinneren zich waarschijnlijk hoe vaak ik graag verwees naar het feit dat vóór de uitvinding van Bitcoin, problemen met het creëren van een gedecentraliseerd netwerk goed werden beschreven door Leslie Lamport in 1976 in het Byzantijnse generaalsprobleem. De oplossing voor het Byzantijnse generaalsprobleem ligt aan de basis van de Tendermint PBFT-algoritmen en alle synchrone algoritmen die worden gebruikt van Telegram Open Network tot Tendermint, tot Cosmos, en andere blockchainprojecten die dienovereenkomstig het pad van de Byzantijnse generaals volgden.",
  "The second interesting achievement in internet technologies is torrent trackers. We don't have any specific, already erased, cloud or a black box that stores files. Still, users worldwide, by exchanging torrent files, can download exactly the file they were looking for, and this works without data substitution. No one uploads any viruses to you by replacing the file. There might sometimes be a virus embedded in the file, but the idea of receiving a link to download and actually downloading something other than what you were offered to download using torrent technology is impossible. Similar processes exist in the IPFS network, a hash-oriented storage - a way of connecting various participants with trust in the information you convey without using a black box, precisely.": "De tweede interessante prestatie in internettechnologieën zijn torrenttrackers. We hebben geen specifieke, al gewiste, cloud of een zwarte doos die bestanden opslaat. Toch kunnen gebruikers wereldwijd, door torrentbestanden uit te wisselen, precies het bestand downloaden waar ze naar op zoek waren, en dit werkt zonder gegevensvervanging. Niemand uploadt virussen naar u door het bestand te vervangen. Er kan soms een virus in het bestand zijn ingesloten, maar het idee om een link te ontvangen om te downloaden en daadwerkelijk iets anders te downloaden dan wat u werd aangeboden om te downloaden met behulp van torrenttechnologie is onmogelijk. Soortgelijke processen bestaan in het IPFS-netwerk, een op hash georiënteerde opslag - een manier om verschillende deelnemers met vertrouwen te verbinden in de informatie die u overbrengt zonder een zwarte doos, precies.",
  "And of course, Bitcoin. Bitcoin, as a more collective example, I'm sure Satoshi Nakamoto was well aware of Leslie Lamport's solution to the Byzantine Generals problem and, of course, observed how the idea of torrent trackers was developing. If we don't emphasize the properties that the Bitcoin blockchain obtained, such as immutability, transparency of transactions, and, to some extent, censorship resistance, then Bitcoin is an internet service that performs state transition, some changes in state based on transactions without a central node. It is an example of a collective construction of a global network in which there is a constantly functioning state transition function that we can trust, and to ensure trust, neither jurisdictions nor specific IP addresses nor the most primitive technologies used and still used today in building cloud services are used. The collective image of Bitcoin allowed overlaying the general concept from the 1930s of a Turing-complete machine on the existence of a universal abstract function for everything.": "En natuurlijk, Bitcoin. Bitcoin, als een meer collectief voorbeeld, ben ik er zeker van dat Satoshi Nakamoto goed op de hoogte was van Leslie Lamport's oplossing voor het Byzantijnse generaalsprobleem en, natuurlijk, observeerde hoe het idee van torrenttrackers zich ontwikkelde. Als we niet de eigenschappen benadrukken die de Bitcoin blockchain heeft verkregen, zoals onveranderlijkheid, transparantie van transacties en, tot op zekere hoogte, censuurbestendigheid, dan is Bitcoin een internetdienst die staatsovergang uitvoert, enkele veranderingen in de staat op basis van transacties zonder een centrale knooppunt. Het is een voorbeeld van een collectieve constructie van een mondiaal netwerk waarin een constant functionerende staatsovergangsfunctie bestaat waarop we kunnen vertrouwen, en om vertrouwen te garanderen, worden noch rechtsgebieden noch specifieke IP-adressen noch de meest primitieve technologieën die worden gebruikt en nog steeds worden gebruikt bij het bouwen van cloudservices gebruikt. Het collectieve beeld van Bitcoin maakte het mogelijk om het algemene concept uit de jaren 1930 van een Turing-volledige machine te overlappen op het bestaan van een universele abstracte functie voor alles.",
  "So, what do we need to add to this scheme to envision a global computer? From the bottom, we provide consensus validators or, in general, validators. It can be said that the \"Data availability layer\" is probably a phrase many have heard around Ethereum this year, and it has become an advantage of Bitcoin as well. However, in the organization scheme of the global computer, this is one piece of the puzzle and, as I mentioned, it complements the main function that lies at the heart of the global computer—the function of universal state transition. Going back to the very beginning, the analogy of the heart in the human body is interesting here. It's not a thinking thing, indeed. Yes, it doesn't generate, you could say, the brain is much more important. Still, life is impossible without the heart. It simply pumps blood. Similarly, at the core of the global computer, all transactions are pumped through the state transition function, resulting in outputs. But to organize this in a distributed internet network without the need to trust some citadel, we need to supplement the picture with two components.": "Dus, wat moeten we toevoegen aan dit schema om een wereldwijde computer voor te stellen? Van onderaf bieden we consensusvalidators of, in het algemeen, validators. Men zou kunnen zeggen dat de \"Data beschikbaarheidslaag\" waarschijnlijk een zin is die velen dit jaar rond Ethereum hebben gehoord, en het is ook een voordeel van Bitcoin geworden. Echter, in het organisatieschema van de wereldwijde computer, is dit slechts één stukje van de puzzel en, zoals ik al zei, vult het de belangrijkste functie aan die aan de basis ligt van de wereldwijde computer - de functie van universele staatsovergang. Terugkerend naar het allereerste begin, is de analogie van het hart in het menselijk lichaam hier interessant. Het is geen denkend ding, inderdaad. Ja, het genereert niet, je zou kunnen zeggen, de hersenen zijn veel belangrijker. Toch is het leven onmogelijk zonder het hart. Het pompt gewoon bloed. Op dezelfde manier worden in de kern van de wereldwijde computer alle transacties door de staatsovergangsfunctie gepompt, resulterend in uitvoer. Maar om dit te organiseren in een gedistribueerd internetnetwerk zonder de noodzaak om een citadel te vertrouwen, moeten we het beeld aanvullen met twee componenten.",
  "The first component is a set of computers or nodes that are ready to execute the state transition. When you send transactions, they don't just go here; they go to the validators. Validators perform computations, recalling what I've already mentioned in this ongoing conversation. They take your transaction, retrieve information from the blockchain about how to process that transaction, apply that processing, and then coordinate with other validators the fact that they correctly executed the state transition. The core of the global computer, in terms of protection against situations where Bob, the vacuum cleaner robot, receives a correct command from Alice in the office, is not based on trust but on cross-verification by a multitude of network participants based on available information from the blockchain. Not only from the blockchain, by the way. It's complex, and we won't delve into it right now, but essentially, a multitude of validators take turns watching and have incentives, some internal incentives within the protocol, to prevent the universal and capable-of-calculating-anything machine from executing this operation incorrectly. A validator effectively processes transactions that come into the global computer, and other validators help prevent situations where one of the validators performed an incorrect calculation. The better the consensus algorithms of the validators, the better protection we have for the state transition function or, in other words, the heart of our global computer.": "Het eerste onderdeel is een set computers of knooppunten die klaar zijn om de statusovergang uit te voeren. Wanneer je transacties verstuurt, gaan ze niet zomaar hier naartoe; ze gaan naar de validators. Validators voeren berekeningen uit, waarbij ze zich herinneren wat ik al heb genoemd in dit lopende gesprek. Ze nemen jouw transactie, halen informatie op uit de blockchain over hoe ze die transactie moeten verwerken, passen die verwerking toe, en coördineren vervolgens met andere validators het feit dat ze de statusovergang correct hebben uitgevoerd. De kern van de wereldwijde computer, wat betreft bescherming tegen situaties waarin Bob, de stofzuigerrobot, een correct commando ontvangt van Alice op kantoor, is niet gebaseerd op vertrouwen maar op kruisverificatie door een veelheid van netwerkdeelnemers op basis van beschikbare informatie uit de blockchain. Niet alleen uit de blockchain, trouwens. Het is complex, en we zullen er nu niet verder op ingaan, maar in essentie nemen een veelheid van validators om de beurt de controle en hebben ze prikkels, enkele interne prikkels binnen het protocol, om te voorkomen dat de universele en alles-kunnende machine deze operatie verkeerd uitvoert. Een validator verwerkt effectief transacties die binnenkomen in de wereldwijde computer, en andere validators helpen situaties te voorkomen waarin een van de validators een verkeerde berekening heeft uitgevoerd. Hoe beter de consensusalgoritmen van de validators, hoe beter de bescherming die we hebben voor de statusovergangsfunctie of, met andere woorden, het hart van onze wereldwijde computer.",
  "The second part of this scheme is the data availability service—what we've always called the database in Bitcoin or Ethereum. In fact, we'll have to abandon that concept because there's a fundamental change in the architecture of all projects, and for those specifically targeting the global computer, this change is most crucial. For a simple present-day example: there are various implementations of Layer 2 networks on top of Ethereum—such as Arbitrum, Optimism, and others. If you start looking into their main differences and how they operate, you'll find that, in some cases, an L2 network in Ethereum sends a larger amount of data, solely from the first-layer blockchain, i.e., from the Ethereum blockchain. All the necessary puzzle pieces to confirm that the computation on the L2 layer was correct can be found in the first-layer Ethereum blockchain. On the other hand, other approaches suggest that beyond the first layer of Ethereum, something else is stored that needs to be found to prove the correctness of transactions. So, right now, before our eyes, there is again a question of improvement, but specifically of such an architecture where transactions go on the left, in the middle, we have the heart in the form of the state transition function, validators, and their consensus allows for the correct execution of this state transition. But there is also a question of data availability, which is necessary to ensure both cross-verification and, essentially, the existence of the service itself. Some approaches and patterns for creating L2 on top of Ethereum today ask the question: \"What if a certain L2 layer loses the data it doesn't store within the main Ethereum blockchain?\"": "Het tweede deel van dit schema is de dienst voor gegevensbeschikbaarheid – wat we in Bitcoin of Ethereum altijd de database hebben genoemd. In feite zullen we dat concept moeten laten varen omdat er een fundamentele verandering in de architectuur van alle projecten plaatsvindt, en voor degenen die zich specifiek op de mondiale computer richten, is deze verandering van cruciaal belang. Om een eenvoudig hedendaags voorbeeld te geven: er zijn verschillende implementaties van Layer 2-netwerken bovenop Ethereum, zoals Arbitrum, Optimism en andere. Als je hun belangrijkste verschillen gaat onderzoeken en hoe ze werken, zul je merken dat een L2-netwerk in Ethereum in sommige gevallen een grotere hoeveelheid gegevens verzendt, uitsluitend vanuit de eerstelaags blockchain, dat wil zeggen vanaf de Ethereum-blockchain. Alle benodigde puzzelstukjes om te bevestigen dat de berekening op de L2-laag correct was, zijn te vinden in de eerste laag Ethereum-blockchain. Aan de andere kant suggereren andere benaderingen dat er buiten de eerste laag van Ethereum nog iets anders is opgeslagen dat moet worden gevonden om de juistheid van transacties te bewijzen. Dus op dit moment is er voor onze ogen opnieuw sprake van verbetering, maar specifiek van een dergelijke architectuur waarbij transacties naar links gaan, in het midden, hebben we het hart in de vorm van de staatstransitiefunctie, validators en hun consensus maakt de correcte uitvoering van deze staatstransitie mogelijk. Maar er is ook een kwestie van de beschikbaarheid van gegevens, die nodig is om zowel kruisverificatie als, in wezen, het bestaan van de dienst zelf te garanderen. Sommige benaderingen en patronen voor het creëren van L2 bovenop Ethereum stellen vandaag de dag de vraag: \"Wat als een bepaalde L2-laag de gegevens verliest die deze niet opslaat in de belangrijkste Ethereum-blockchain?\"",
  "Let's complement this picture with how Polkadot is structured. Polkadot has two consensus mechanisms: the \"babe\" consensus, responsible for the parachain-level consensus and is fast, and the \"grandpa\" consensus, which is slower and verifies everything afterward. So, if you delve into the wiki article titled \"The Path of a Block in the Polkadot Network,\" you will encounter interesting abbreviations. After achieving the \"babe\" consensus at the parachain level, the \"grandpa\" consensus introduces the concept of \"proof of validity and data availability.\" Going deeper, you'll find the term \"chunk\" of redundant pieces of information, inspired by CD RW technologies from the 90s and 2000s. This addresses the question of how to preserve information when absolute trust in a specific entity in the network is not feasible. The concept of \"chunk\" of redundant information is one of these patterns.": "Laten we dit beeld aanvullen met hoe Polkadot is gestructureerd. Polkadot heeft twee consensusmechanismen: de 'babe'-consensus, die verantwoordelijk is voor de consensus op parachain-niveau en snel is, en de 'opa'-consensus, die langzamer is en alles daarna verifieert. Dus als je je verdiept in het wiki-artikel getiteld 'Het pad van een blok in het Polkadot-netwerk', zul je interessante afkortingen tegenkomen. Nadat de 'babe'-consensus op parachain-niveau is bereikt, introduceert de 'opa'-consensus het concept van 'bewijs van geldigheid en beschikbaarheid van gegevens'. Als we dieper gaan, zul je de term 'chunk' tegenkomen. van overbodige stukjes informatie, geïnspireerd door CD-RW-technologieën uit de jaren 90 en 2000. Dit richt zich op de vraag hoe informatie behouden kan blijven wanneer absoluut vertrouwen in een specifieke entiteit in het netwerk niet haalbaar is. Het concept van 'stukjes' overtollige informatie is een van deze patronen.",
  "Summing up, at the core lies an abstract function that enables any computation and was described by Alan Turing in the 1930s. The personal computer, essentially a side effect of a mathematical problem, emerged from Turing's work. The technologies first applied in Bitcoin, such as consensus that allows the network to exist without a specific data center or entity responsible for data correctness, form a functioning mechanism. It goes beyond providing a specific service for electronic cash transfers; it allows us to audit and control any computation in the network. Additionally, we face the challenge of ensuring data availability, as it's not the primary concern of the world computer. The world computer's task lies at its core, executing computation, managing state transitions, and performing calculations, while the data in this scheme serves as a puzzle piece that is more necessary to support the lower part. Thus, this overall scheme can be seen as an abstract and generalized illustration of the world computer's structure, where the state transition function is at its core.": "Samenvattend ligt in de kern een abstracte functie die elke berekening mogelijk maakt en die in de jaren dertig door Alan Turing werd beschreven. De personal computer, in wezen een bijeffect van een wiskundig probleem, kwam voort uit het werk van Turing. De technologieën die voor het eerst in Bitcoin werden toegepast, zoals consensus die ervoor zorgt dat het netwerk kan bestaan zonder een specifiek datacenter of entiteit die verantwoordelijk is voor de juistheid van de gegevens, vormen een functionerend mechanisme. Het gaat verder dan het aanbieden van een specifieke dienst voor elektronische geldoverboekingen; het stelt ons in staat om elke berekening in het netwerk te auditen en te controleren. Bovendien staan we voor de uitdaging om de beschikbaarheid van gegevens te garanderen, aangezien dit niet de voornaamste zorg van de wereldcomputer is. De taak van de wereldcomputer ligt in de kern: het uitvoeren van berekeningen, het beheren van toestandsovergangen en het uitvoeren van berekeningen, terwijl de gegevens in dit schema dienen als een puzzelstukje dat meer noodzakelijk is om het lagere deel te ondersteunen. Dit algemene schema kan dus worden gezien als een abstracte en algemene illustratie van de structuur van de wereldcomputer, waarin de statustransitiefunctie centraal staat.",
  "Part 4: The Path of a New Block of Information in the World Computer": "Deel 4: Het Pad van een Nieuw Blok van Informatie in de Wereldcomputer",
  "The fourth and final part of our lecture is \"The World Computer in Your Home.\" After this, I will begin recording screencasts for the practical part of the sessions.": "Het vierde en laatste deel van onze lezing is \"De Wereldcomputer in Jouw Huis.\" Hierna zal ik beginnen met het opnemen van screencasts voor het praktische gedeelte van de sessies.",
  "Now we will try to summarize almost all the theory we have covered so far in terms of one process. The process that describes the path of an information block in the world computer. Let's start again by returning to the theme of web3 and the concept of blockchain. The phrase \"block\" or \"information block\" can be considered identical when stepping away from the last 10 years and taking a more general theory, as explored in the previous parts of the lectures. The concept of a \"block of information\" aligns with web3, but not necessarily with blockchain. Even without any crypto projects, we need to understand that when forming the theory of the world computer without referencing the formation of information blocks, it's currently challenging to envision other models. So, we will consider the path of an information block throughout the entire world computer, not because it is blockchain, but because, for now, there are no other ways to conceptualize the existence of the world computer other than by processing information in specific portions.": "Nu zullen we proberen bijna alle theorie die we tot nu toe hebben behandeld samen te vatten in termen van één proces. Het proces dat het pad van een informatieblok in de wereldcomputer beschrijft. Laten we opnieuw beginnen door terug te keren naar het thema van web3 en het concept van blockchain. De term \"blok\" of \"informatieblok\" kan als identiek worden beschouwd wanneer we ons terugtrekken van de laatste 10 jaar en een meer algemene theorie nemen, zoals onderzocht in de vorige delen van de lezingen. Het concept van een \"blok van informatie\" komt overeen met web3, maar niet noodzakelijkerwijs met blockchain. Zelfs zonder enige cryptoprojecten moeten we begrijpen dat wanneer we de theorie van de wereldcomputer vormgeven zonder te verwijzen naar de vorming van informatieblokken, het momenteel uitdagend is om andere modellen voor te stellen. Dus, we zullen het pad van een informatieblok in de hele wereldcomputer overwegen, niet omdat het blockchain is, maar omdat er op dit moment geen andere manieren zijn om het bestaan van de wereldcomputer te conceptualiseren dan door informatie te verwerken in specifieke porties.",
  "Block of information = block in web3, but without blockchain and without any crypto project influence. We must currently consider the formation of information blocks when discussing the theory of the world computer. Now, let's move on to the first point. I tried to find close analogies from everyday life to help illustrate the path of an information block in the world computer. The analogy I've chosen is the movement of a bus on a route. Our first meeting point is the bus station.": "Informatieblok = blok in web3, maar zonder blockchain en zonder enige invloed van cryptoprojecten. We moeten momenteel de vorming van informatieblokken overwegen bij het bespreken van de theorie van de wereldcomputer. Laten we nu doorgaan naar het eerste punt. Ik heb geprobeerd om nauwe analogieën uit het dagelijks leven te vinden om het pad van een informatieblok in de wereldcomputer te illustreren. De analogie die ik heb gekozen is de beweging van een bus op een route. Ons eerste ontmoetingspunt is het busstation.",
  "I marked transactions in pink as small dots. Let's imagine a typical bus stop where people gather, waiting for a bus that operates on a schedule. If we don't consider the hustle and bustle of large cities, where buses are always late, everyone in the world generally knows that the train from village A to village B always arrives around 7:15 am. Transactions that users want to send to the world computer gather at a certain bus stop and wait for the bus to arrive.": "Ik heb transacties in het roze gemarkeerd als kleine stippen. Laten we ons een typische bushalte voorstellen waar mensen samenkomen en wachten op een bus die volgens een schema rijdt. Als we de drukte van grote steden niet meerekenen, waar bussen altijd te laat zijn, weet iedereen in de wereld over het algemeen dat de trein van dorp A naar dorp B altijd rond 7:15 uur aankomt. Transacties die gebruikers naar de wereldcomputer willen sturen verzamelen zich bij een bepaalde bushalte en wachten tot de bus arriveert.",
  "This is how our block is formed. Imagine: the bus arrives, and each person starts boarding one by one, taking their seats. The bus then follows its route. In our case, the block of information overcomes the first frontier. Our transactions, in some form, have settled into the bus and overcome the initial barrier. I will be using terminology primarily from Polkadot, and the third part should have better explained the concept of the world computer in the comparison between Ethereum and Polkadot. My personal opinion, and probably the majority of engineers today would agree, is that the representation of a heterogeneous multicentric world computer is better implemented in Polkadot. However, we will still go through the terms inherited from Ethereum, but towards the end of this part of the lecture.": "Dit is hoe ons blok wordt gevormd. Stel je voor: de bus arriveert en elke persoon begint één voor één aan boord te gaan, neemt plaats. De bus volgt dan zijn route. In ons geval overwint het blok van informatie de eerste grens. Onze transacties, in enige vorm, zijn in de bus gesetteld en hebben de initiële barrière overwonnen. Ik zal voornamelijk terminologie van Polkadot gebruiken, en het derde deel zou het concept van de wereldcomputer beter moeten hebben uitgelegd in de vergelijking tussen Ethereum en Polkadot. Mijn persoonlijke mening, en waarschijnlijk zou de meerderheid van de ingenieurs vandaag het ermee eens zijn, is dat de representatie van een heterogene multicentrische wereldcomputer beter geïmplementeerd is in Polkadot. We zullen echter nog steeds de termen doornemen die zijn geërfd van Ethereum, maar tegen het einde van dit deel van de lezing.",
  "What is the line that separates the bus stop from the bus's further movement? This line represents the collators of the network – participants in the network nodes who collect transactions. You can think of a collator not as a bus driver but as a controller who stays at the bus stop. In other words, this controller checks whether you have a ticket when you enter the bus. It doesn't recheck in the database how valid the ticket is but looks at the basic parameters of the ticket and checks if everything seems fine. In reality, collators perform almost all the calculations required, verifying the ticket number and other data, but they are not required to guarantee that the check is done correctly. Therefore, collators are controllers who remain at the bus stop, primarily ensuring passenger boarding, seating, and sending the bus further along the route.": "Wat is de lijn die de bushalte scheidt van de verdere beweging van de bus? Deze lijn vertegenwoordigt de collators van het netwerk - deelnemers aan de netwerknodes die transacties verzamelen. Je kunt een collator niet zien als een buschauffeur maar als een controller die bij de bushalte blijft. Met andere woorden, deze controller controleert of je een kaartje hebt wanneer je de bus instapt. Het controleert niet opnieuw in de database hoe geldig het kaartje is, maar kijkt naar de basisparameters van het kaartje en controleert of alles in orde lijkt. In werkelijkheid voeren collators bijna alle vereiste berekeningen uit, verifiëren het kaartnummer en andere gegevens, maar ze zijn niet verplicht om te garanderen dat de controle correct is uitgevoerd. Daarom zijn collators controllers die bij de bushalte blijven, voornamelijk zorgen voor het instappen van passagiers, het plaatsen en het verder sturen van de bus langs de route.",
  "Beyond the drawn border, we enter the first validation area where paravalidators are located. These are validators of the entire ecosystem, the entire network, specifically assigned for a certain time to check each transaction and thus perform actual computations in the world computer. Our not-yet-fully-formed block of information is marked with a dashed line. It is still a candidate block of information since it has not undergone any actual verification. The collator, who collected the block of information and checked the transactions at the entrance, does not participate in any way in securing the cybersecurity of the computations conducted. Its task is only to seat all transactions and form the first block. At this stage, the transformation from a candidate to a real block of information begins.": "Voorbij de getrokken grens betreden we het eerste validatiegebied waar paravalidators zich bevinden. Dit zijn validators van het hele ecosysteem, het hele netwerk, specifiek toegewezen voor een bepaalde tijd om elke transactie te controleren en zo daadwerkelijke berekeningen uit te voeren in de wereldcomputer. Ons nog niet volledig gevormde blok van informatie is gemarkeerd met een stippellijn. Het is nog steeds een kandidaat-blok van informatie omdat het nog geen enkele daadwerkelijke verificatie heeft ondergaan. De collator, die het blok van informatie heeft verzameld en de transacties bij de ingang heeft gecontroleerd, neemt op geen enkele manier deel aan het beveiligen van de cyberbeveiliging van de uitgevoerde berekeningen. Zijn taak is alleen om alle transacties te plaatsen en het eerste blok te vormen. In deze fase begint de transformatie van een kandidaat naar een echt blok van informatie.",
  "I have divided it into three parts, but forgot one more. Let's consider four parts of this candidate block. The top part, known to users of various web3 applications as the header or block header, is the quintessence, the most popular piece of information circulating and reflected from the block explorer to the console clients of all nodes mining, staking, and so on. The header is a key element of the block, but it is practically formed at the last stage at this point.": "Ik heb het in drie delen verdeeld, maar vergat er nog een. Laten we vier delen van dit kandidaatblok overwegen. Het bovenste deel, bekend bij gebruikers van verschillende web3-toepassingen als de header of blokkop, is de essentie, het meest populaire stuk informatie dat circuleert en wordt weerspiegeld vanuit de blokverkenner naar de consoleclients van alle knooppunten die mijnen, staken, enz. De header is een sleutelelement van het blok, maar wordt praktisch gevormd in de laatste fase op dit punt.",
  "Firstly, we have our actual requests for state transitions or computations. There is a list of changes that need to be made: convert A to A', B to B', C to C', applying a set of algorithms to them. For this, we will now build another boundary immediately and go beyond it to perform this part of the work, and then only proceed beyond it. Already at the block preparation stage, we have to cross the second boundary within the world computer to go for the algorithms that need to be applied to prepare the block. As I mentioned before, theoretically, the controller at the bus stop here does the same, but I wouldn't pay much attention to that. The block preparation stage, especially when we talk about examples simultaneously from Polkadot and Ethereum as a world computer, they differ slightly and show us the insignificance of checks at this stage because it is precisely on the second step, after passing the first boundary and receiving the block of information from collators, that the attention-worthy calculations of this world computer begin.": "Ten eerste hebben we onze daadwerkelijke verzoeken voor statusovergangen of berekeningen. Er is een lijst van veranderingen die moeten worden aangebracht: A omzetten naar A', B naar B', C naar C', waarbij een reeks algoritmen op hen wordt toegepast. Hiervoor zullen we nu onmiddellijk een andere grens bouwen en er voorbij gaan om dit deel van het werk uit te voeren, en dan pas verder gaan. Al bij de blokvoorbereidingsfase moeten we de tweede grens binnen de wereldcomputer oversteken om naar de algoritmen te gaan die moeten worden toegepast om het blok voor te bereiden. Zoals ik al eerder zei, doet de controller bij de bushalte hier theoretisch hetzelfde, maar daar zou ik niet veel aandacht aan besteden. De blokvoorbereidingsfase, vooral wanneer we tegelijkertijd voorbeelden bespreken van Polkadot en Ethereum als wereldcomputer, verschillen ze iets en tonen ons de onbeduidendheid van controles in deze fase omdat het precies op de tweede stap is, na het passeren van de eerste grens en het ontvangen van het blok van informatie van collators, dat de aandachtswaardige berekeningen van deze wereldcomputer beginnen.",
  "To perform these calculations, the validator, at this stage, can only do so by turning to the relay chain, the central database, and taking from there the algorithms from the runtime. In the case of Ethereum, it was the same virtual machines in the previous architectural concept, which could be applied, so there was no need to go anywhere. Almost every node had a complete copy of the algorithms that could be applied. But in terms of a heterogeneous network, where each segment or each individual chain may have its own set of algorithms, a validator, before actually executing all the transitions, calculations obtained in the form of a block candidate from the collator, must consult. It must consult the relay chain, consult the main blockchain in the network and take from there the necessary algorithms, apply them, and perform state transitions.": "Om deze berekeningen uit te voeren, kan de validator op dit moment alleen naar de relay chain, de centrale database, gaan en daar de algoritmes uit de runtime halen. In het geval van Ethereum waren het dezelfde virtuele machines in het vorige architecturale concept, die konden worden toegepast, dus er was geen noodzaak om ergens heen te gaan. Bijna elke node had een volledige kopie van de algoritmes die konden worden toegepast. Maar in termen van een heterogeen netwerk, waar elk segment of elke individuele chain zijn eigen set algoritmes kan hebben, moet een validator, voordat hij daadwerkelijk alle overgangen uitvoert, berekeningen verkregen in de vorm van een blokkandidaat van de collator, raadplegen. Hij moet de relay chain raadplegen, de main blockchain in het netwerk raadplegen en daar de benodigde algoritmes vandaan halen, ze toepassen en overgangen uitvoeren.",
  "During the execution of calculations, a Merkle tree is simultaneously formed, and we won't dwell on it because Merkle trees are not that complicated from the perspective of computer science. Still, I notice that to understand how to apply them in engineering and in the architecture of a project, how they are applied, not just by reading on Wikipedia, you need to break your head a bit, imagine examples. In this example, we won't delve too much into it, but I think for those who are already familiar with some basic definitions, have read about Merkle trees, it will become a bit clearer about how and at what moments another Merkle tree is assembled. The Merkle tree is formed when we actually perform calculations and output values appear. These output values are packed into a binary tree format, then the addition is performed between them in computer science language, and the top node reaches the header. Let's denote it with a big letter \"H.\" It's a small and pleasant aspect of considering such schemes.": "Tijdens de uitvoering van berekeningen wordt tegelijkertijd een Merkle tree gevormd, en we zullen er niet te lang bij stilstaan omdat Merkle trees niet zo ingewikkeld zijn vanuit het perspectief van de informatica. Toch merk ik op dat om te begrijpen hoe ze toegepast worden in de techniek en in de architectuur van een project, hoe ze worden toegepast, niet alleen door te lezen op Wikipedia, je een beetje je hoofd moet breken, voorbeelden moet bedenken. In dit voorbeeld zullen we er niet te diep op ingaan, maar ik denk dat voor degenen die al bekend zijn met enkele basisdefinities, die hebben gelezen over Merkle trees, het iets duidelijker zal worden over hoe en op welke momenten een andere Merkle tree wordt samengesteld. De Merkle tree wordt gevormd wanneer we daadwerkelijk berekeningen uitvoeren en er outputwaarden verschijnen. Deze outputwaarden worden verpakt in een binaire boomstructuur, vervolgens wordt de toevoeging tussen hen uitgevoerd in de taal van de informatica, en de bovenste knoop bereikt de header. Laten we het aanduiden met een grote letter \"H.\" Het is een klein en aangenaam aspect om dergelijke schema's te overwegen.",
  "In this scheme, we can note how the block header is actually related to the computations performed inside. Let's look again - our block candidate came from the collator. There is a set of transactions that need to be executed, perform calculations. The validator went through another internal boundary, one more, behind the algorithms, applied them, and recorded all the results at the lowest level of the Merkle tree. The other nodes are essentially systemic. They do not come from any data; they don't come from anywhere. At the second level, the node does not come from any information. It is obtained by summing values in these two leaves, and when we go up with you, we get only the root of this tree, which is enough to protect all output values. We won't get the same header if we change any of these calculations. And this is one of the magical and simple features, like hash-oriented storage, of how we can protect a whole block of information by talking only about one header. Therefore, headers are so important and play a cornerstone role even in architectures when we transition from one chain or one virtual machine to many combined in the network. It is enough for us to ensure the security of storing headers to be sure that all transactions that were executed at the block preparation stage were executed correctly, and they cannot be replaced.": "In dit schema kunnen we opmerken hoe de blokkop eigenlijk gerelateerd is aan de berekeningen die binnenin worden uitgevoerd. Laten we nog eens kijken - onze blokkandidaat kwam van de collator. Er is een reeks transacties die moeten worden uitgevoerd, berekeningen uitvoeren. De validator ging door een andere interne grens, nog een, achter de algoritmes, paste ze toe en registreerde alle resultaten op het laagste niveau van de Merkle tree. De andere knooppunten zijn in wezen systemisch. Ze komen niet voort uit enige data; ze komen niet van ergens. Op het tweede niveau komt het knooppunt niet voort uit enige informatie. Het wordt verkregen door waarden in deze twee bladeren op te tellen, en wanneer we omhoog gaan, krijgen we alleen de wortel van deze boom, die voldoende is om alle outputwaarden te beschermen. We krijgen niet dezelfde header als we een van deze berekeningen wijzigen. En dit is een van de magische en eenvoudige kenmerken, zoals op hash-georiënteerde opslag, van hoe we een hele blok informatie kunnen beschermen door alleen te praten over één header. Daarom zijn headers zo belangrijk en spelen ze zelfs een hoeksteenrol in architecturen wanneer we overgaan van één chain of één virtuele machine naar velen gecombineerd in het netwerk. Het is voldoende voor ons om de beveiliging van het opslaan van headers te waarborgen om er zeker van te zijn dat alle transacties die zijn uitgevoerd in de blokvoorbereidingsfase correct zijn uitgevoerd en niet kunnen worden vervangen.",
  "And one field is still left unfilled. In the process of preparing the block of information, it is the author's field, that is, the validator who actually performed all the changes, prepared the Merkle tree, and recorded the header. Since we are considering an example with the bus moving along the route from the stop, let's call the validator a \"controller\" who goes right inside the bus, passes each seat, approaches each person, checks for real what is written on their tickets, makes some mark, validates it, and, accordingly, puts their signature. The controller, for example, number 134, meaning, naturally, each validator has some unique identifier, their address, and we also somehow uniquely renamed it here.": "En er is nog steeds één veld oningevuld. In het proces van het voorbereiden van het blok informatie, is het het veld van de auteur, dat wil zeggen de validator die daadwerkelijk alle wijzigingen heeft uitgevoerd, de Merkle tree heeft voorbereid en de header heeft opgenomen. Aangezien we een voorbeeld bekijken met de bus die langs de route van de halte beweegt, laten we de validator een \"controller\" noemen die rechtstreeks de bus in gaat, elke stoel passeert, elke persoon benadert, controleert wat er echt op hun tickets staat, een markering maakt, valideert het en plaatst dienovereenkomstig hun handtekening. De controller, bijvoorbeeld nummer 134, wat natuurlijk betekent dat elke validator een unieke identificatie heeft, hun adres, en we het hier ook op de een of andere manier uniek hebben hernoemd.",
  "And it seems that at this point, we could have shaded and made our block boundaries bolder, but no, and this is one of the interesting changes that have occurred in the last 5 years in terms of decentralized ecosystems, namely the shift from proof of work. When validators of the network, at that time miners, never had to coordinate anything with each other. You produced a block and sent it to the network and moved on. In fact, it was not a consensus of agreed consent. It was a consensus of obvious agreement with the fact that had occurred. What is interesting changes when the architecture becomes more complex, and we have come closer from a simple calculator like Bitcoin with a ledger towards an actual virtual computer, is that at each stage, the connectivity of participants who ensure security and block production has increased. Because, in fact, no one who risks their stake, the one who ensures this security and wants to earn by processing your transactions, has something to lose, unlike proof of work. In proof of work, you bought the equipment, yes, you put money into it, you spend electricity, but there is actually no protection against the fact that you can attack the network with your power, the same 51% attack, where someone with a lot of miners can try to rewrite the chain.": "En het lijkt erop dat we op dit punt onze blokgrenzen hadden kunnen markeren en dikker hadden kunnen maken, maar nee, en dit is een van de interessante veranderingen die zich in de afgelopen 5 jaar hebben voorgedaan op het gebied van gedecentraliseerde ecosystemen, namelijk de verschuiving van proof of work. Toen de validators van het netwerk, destijds mijnwerkers, nooit iets met elkaar hoefden af te stemmen. Je produceerde een blok en stuurde het naar het netwerk en ging verder. In feite was het geen consensus van overeengekomen instemming. Het was een consensus van duidelijke overeenstemming met het feit dat zich had voorgedaan. Wat interessante veranderingen zijn wanneer de architectuur complexer wordt, en we zijn dichterbij gekomen van een eenvoudige rekenmachine zoals Bitcoin met een grootboek naar een daadwerkelijke virtuele computer, is dat op elk niveau de connectiviteit van de deelnemers die zorgen voor beveiliging en blokproductie is toegenomen. Omdat, in feite, niemand die zijn inzet riskeert, degene die deze beveiliging waarborgt en wil verdienen door uw transacties te verwerken, iets te verliezen heeft, in tegenstelling tot proof of work. Bij proof of work heb je de apparatuur gekocht, ja, je hebt er geld in gestoken, je hebt elektriciteit verbruikt, maar er is eigenlijk geen bescherming tegen het feit dat je het netwerk kunt aanvallen met je kracht, dezelfde 51% aanval, waar iemand met veel mijnwerkers kan proberen de keten te herschrijven.",
  "Now we are talking about proof of stake, where a deposit is already made, and if you do something wrong, a part will be withdrawn from it, as a penalty. All nodes, absolutely, in all architectures that I currently observe, mechanisms for messaging between validators began to appear quickly at the block preparation stage. In Polkadot, it is no different. Any validator of a separate parachain that collects a block knows the addresses or already has established contact with another 15-63 validators who are with you on this epoch, on some temporary period, as validators, and each of them randomly becomes a block producer at some point. But being appointed as a producer does not negate a very important component of this process. You do not stop interacting with the other participants. There is always a pool of validators assigned to a specific epoch, to a certain time slot, for validating a particular parachain or segment of the world computer. Regardless of whether you are a validator-controller specifically assigned to produce the next block in the world computer of this segment, you still stay in touch with the other validators, and you have constant contact with them.": "Nu praten we over bewijs van belang, waarbij al een storting is gedaan, en als je iets verkeerd doet, wordt er een deel van afgetrokken als straf. Alle knooppunten, absoluut, in alle architecturen die ik momenteel observeer, begonnen mechanismen voor berichtenuitwisseling tussen validators snel te verschijnen in de fase van blokvoorbereiding. In Polkadot is het niet anders. Elke validator van een afzonderlijke parachain die een blok verzamelt, kent de adressen of heeft al contact gelegd met nog eens 15-63 validators die met jou op dit tijdperk zijn, gedurende een bepaalde tijdelijke periode, als validators, en elk van hen wordt op een gegeven moment willekeurig een blokproducent. Maar benoemd worden als producent doet geen afbreuk aan een zeer belangrijk onderdeel van dit proces. Je stopt niet met communiceren met de andere deelnemers. Er is altijd een pool van validators toegewezen aan een specifiek tijdperk, aan een bepaald tijdsinterval, voor het valideren van een bepaalde parachain of segment van de wereldcomputer. Ongeacht of je een validator-controller bent die specifiek is toegewezen om het volgende blok te produceren in de wereldcomputer van dit segment, blijf je toch in contact met de andere validators, en heb je voortdurend contact met hen.",
  "Why is this constant contact necessary? It turns out to be quite simple. We do not want, when we move into the inner part, to be afraid or worry that we performed any of the operations incorrectly. As surprising as it may seem, it is beneficial for any validator, before moving on, to first turn to their colleagues assigned to validation and ask them to double-check the calculations. This check is informal, so even if we do not use any logging into an immutable database of requests for verification and the results of this verification, the appointed controller, after talking to the pool of validators, still collects additional responses from all validators assigned to this parachain or network segment. Together with additional confirmations, the controller moves on to the next stage. But even here, it's not quite as simple. At this stage, another process has to be performed. It is important to note that at this stage, our block of information is still a candidate block, and settlement of information is already taking place in the storage. Neither at the very end, nor after we have created and sealed the block and attached it with an archiver in the final part, namely here, in this middle part where all the calculations are actually performed, does the information get saved in the storage. Therefore, our controller, in addition to talking to their colleagues, also ensures the storage of data in some storage, which is also quite metaphysical because the moment you communicate with other validators, this storage gets filled. How is this checked? We will need to move on to the next stage.": "Waarom is dit constante contact noodzakelijk? Het blijkt vrij eenvoudig te zijn. We willen niet, wanneer we naar het binnenste deel gaan, bang zijn of ons zorgen maken dat we een van de operaties verkeerd hebben uitgevoerd. Zo verrassend als het ook mag lijken, is het gunstig voor elke validator, voordat ze verder gaan, eerst naar hun collega's die zijn toegewezen aan validatie te gaan en hen vragen om de berekeningen te controleren. Deze controle is informeel, dus zelfs als we geen logging gebruiken in een onveranderlijke database van verzoeken om verificatie en de resultaten van deze verificatie, verzamelt de aangewezen controller, na met de groep validators te hebben gesproken, nog steeds aanvullende reacties van alle validators die zijn toegewezen aan deze parachain of netwerksegment. Samen met aanvullende bevestigingen gaat de controller verder naar de volgende fase. Maar zelfs hier is het niet helemaal zo eenvoudig. Op dit punt moet nog een ander proces worden uitgevoerd. Het is belangrijk op te merken dat op dit punt ons informatieblok nog steeds een kandidaat-blok is, en de afwikkeling van informatie al plaatsvindt in de opslag. Noch aan het einde, noch nadat we het blok hebben gemaakt en verzegeld en het met een archiver in het laatste deel hebben bevestigd, namelijk hier, in dit middelste deel waar alle berekeningen daadwerkelijk worden uitgevoerd, wordt de informatie opgeslagen in de opslag. Daarom zorgt onze controller, naast het praten met hun collega's, er ook voor dat de gegevens worden opgeslagen in een opslag, wat ook behoorlijk metafysisch is omdat op het moment dat je communiceert met andere validators, deze opslag wordt gevuld. Hoe wordt dit gecontroleerd? We zullen verder moeten gaan naar de volgende fase.",
  "In summary, to complete the middle part, let's look again. We still have only a candidate block at the very beginning. Yes, all transactions are roughly calculated somewhere at the bus stop, everyone has taken their seats according to their tickets. We have passed the first boundary, which is essentially direct established contact between validators and block collators. In Ethereum and Polkadot, these are slightly different schemes now. But everything that happens on the left side at the very beginning does not provide cybersecurity for data and calculations. It's just preparation. Once we have passed and entered the environment of the validators' attention, work with the block of information in the world computer begins. A randomly selected validator, in our case, with a bus route - a controller, actually goes through each of the seats, checks the ticket, checks and performs all the calculations that were made, gathers all the information into a tree. The resulting root node of this tree becomes the header of the proposed block. The validator who actually performs all the calculations with this block of information communicates with the other participants who perform a similar function for the same route in an undefined time slot. And while communicating with them and asking them to verify all the calculations, we are actually filling a certain storage of data in the network. It is not a specific physical storage; there is no specific IP address, no specific hard drive onto which they all load through some VPN or login and password scheme, of course not. In the process of communicating with other validators, data remains on their local machines, and this data will further participate in the transformation of this candidate into a new block of information. In essence, the sealed block that will be settled in the relay chain is collected. We have assembled a block. All the metadata around the calculations is already filled, which means we can try to move on to the next frontier.": "Samenvattend, om het middelste deel te voltooien, laten we nog eens kijken. We hebben nog steeds alleen een kandidaatblok aan het begin. Ja, alle transacties worden ergens bij de bushalte ruwweg berekend, iedereen heeft zijn plaats ingenomen volgens hun tickets. We hebben de eerste grens gepasseerd, wat in feite direct vastgesteld contact is tussen validators en blokcollators. In Ethereum en Polkadot zijn dit nu enigszins verschillende schema's. Maar alles wat aan het begin aan de linkerkant gebeurt, biedt geen cyberbeveiliging voor gegevens en berekeningen. Het is slechts voorbereiding. Zodra we de aandacht van de validators hebben getrokken en de omgeving zijn binnengegaan, begint het werk met het blok informatie in de wereldcomputer. Een willekeurig geselecteerde validator, in ons geval, met een busroute - een controller, gaat eigenlijk door elk van de stoelen, controleert het ticket, controleert en voert alle berekeningen uit die zijn gemaakt, verzamelt alle informatie in een boom. De resulterende wortelknoop van deze boom wordt de header van het voorgestelde blok. De validator die daadwerkelijk alle berekeningen met dit blok informatie uitvoert, communiceert met de andere deelnemers die een soortgelijke functie uitvoeren voor dezelfde route in een ongedefinieerd tijdsbestek. En terwijl we met hen communiceren en hen vragen om alle berekeningen te verifiëren, vullen we eigenlijk een bepaalde opslag van gegevens in het netwerk. Het is geen specifieke fysieke opslag; er is geen specifiek IP-adres, geen specifieke harde schijf waarop ze allemaal laden via een VPN of inlog- en wachtwoordschema, natuurlijk niet. In het proces van communicatie met andere validators blijven de gegevens op hun lokale machines, en deze gegevens zullen verder deelnemen aan de transformatie van deze kandidaat in een nieuw blok informatie. In wezen wordt het verzegelde blok dat zal worden afgewikkeld in de relay chain verzameld. We hebben een blok samengesteld. Alle metadata rond de berekeningen is al ingevuld, wat betekent dat we kunnen proberen om verder te gaan naar de volgende grens.",
  "At this moment, let's delve into the passage of the next boundary. The most crucial aspect at the final stage becomes the block header. We are less concerned with the execution of computations; we can simplify our perspective here, as computations may vary based on the architecture, whether it's Ethereum or Polkadot. The key point is that, on the intermediate stage, from what I observe in the theory and practice of implementing the world computer concept, most computations happen at an intermediate level. The last level remains only to execute essential checks. Almost all these checks in a multi-chain architecture are related to the concatenation or merging of block headers into one block.": "Op dit moment gaan we dieper in op de passage van de volgende grens. Het meest cruciale aspect in de laatste fase wordt de blokkop. We maken ons minder zorgen over de uitvoering van berekeningen; we kunnen hier ons perspectief vereenvoudigen, aangezien berekeningen kunnen variëren op basis van de architectuur, of het nu Ethereum of Polkadot is. Het belangrijkste punt is dat, in de tussenfase, vanuit wat ik observeer in de theorie en praktijk van het implementeren van het concept van de wereldcomputer, de meeste berekeningen op een tussenliggend niveau plaatsvinden. Het laatste niveau blijft alleen over om essentiële controles uit te voeren. Bijna al deze controles in een multi-chain architectuur hebben betrekking op de concatenatie of samenvoeging van blokkoppen tot één blok.",
  "In the final part of our journey, the most important element in the world computer's information block becomes the cornerstone – the header. The second component is more about meta-information. If the header is the actual result of all computations, the additional meta-information being transmitted consists of receipts and signatures of the validators who participated in the intermediate stage of this process. At the final stage, we can visualize the whole picture solely as the assembly of the same tree, not as a list of transactions. In the relay chain's final part, the crucial aspect is the assembly of headers from many similar processes, but linked to different segments of the world computer, different parachains.": "In het laatste deel van onze reis wordt het belangrijkste element in het informatieblok van de wereldcomputer de hoeksteen - de kop. Het tweede component gaat meer over meta-informatie. Als de kop het daadwerkelijke resultaat is van alle berekeningen, bestaat de aanvullende meta-informatie die wordt verzonden uit ontvangstbewijzen en handtekeningen van de validators die hebben deelgenomen aan de tussenfase van dit proces. In de laatste fase kunnen we het geheel alleen visualiseren als de samenstelling van dezelfde boom, niet als een lijst van transacties. In het laatste deel van de relay chain is het cruciale aspect de samenstelling van koppen uit veel vergelijkbare processen, maar gekoppeld aan verschillende segmenten van de wereldcomputer, verschillende parachains.",
  "Each parachain, each set of validators – we've discussed one example, but in reality, such block preparations for parachains happen 30-40 times. The number of parachain slots or the number of L2 networks in Ethereum will result in a similar number of processes with a similar architecture. However, in the final stage, we will see an approximately identical picture everywhere – how the block header will be formed from a multitude of headers from other blocks. In this process, we need to introduce one more entity and jump back across the boundary to the second stage.": "Elke parachain, elke set van validators - we hebben één voorbeeld besproken, maar in werkelijkheid gebeuren dergelijke blokvoorbereidingen voor parachains 30-40 keer. Het aantal parachain-slots of het aantal L2-netwerken in Ethereum zal resulteren in een vergelijkbaar aantal processen met een vergelijkbare architectuur. Echter, in de laatste fase zullen we overal een ongeveer identiek beeld zien - hoe de blokkop zal worden gevormd uit een veelheid van koppen van andere blokken. In dit proces moeten we nog een entiteit introduceren en terug springen over de grens naar de tweede fase.",
  "Finalizers. In fact, they are also validators, but relay chain validators. In the Polkadot architecture, we have a thousand validators divided into two groups. The first, a very small group, is responsible only for forming the block header and a new block consisting of the headers of the State of the States blocks. The second group – parachain validators – is further divided into many subgroups, but this group is called parachain validators. In L2 networks above Ethereum, this story will eventually gain more understanding, more denominators. For now, let's focus on the Polkadot architecture. Finalizers, besides checking an additional set of meta-information and rechecking a validator with a specific ID, randomly chosen to generate this block of all blocks, also help recheck meta-information, check, and assemble all headers into one. It's a bit complex, yes, if we look at it from the perspective of tree assembly.": "Finalizers. In feite zijn ze ook validators, maar relay chain validators. In de Polkadot-architectuur hebben we duizend validators verdeeld in twee groepen. De eerste, een zeer kleine groep, is alleen verantwoordelijk voor het vormen van de blokkop en een nieuw blok bestaande uit de koppen van de State of the States-blokken. De tweede groep - parachain validators - is verder onderverdeeld in veel subgroepen, maar deze groep wordt parachain validators genoemd. In L2-netwerken boven Ethereum zal dit verhaal uiteindelijk meer begrip, meer noemers krijgen. Laten we ons nu richten op de Polkadot-architectuur. Finalizers, naast het controleren van een aanvullende set meta-informatie en het opnieuw controleren van een validator met een specifiek ID, willekeurig gekozen om dit blok van alle blokken te genereren, helpen ook bij het opnieuw controleren van meta-informatie, controleren en samenstellen van alle koppen tot één. Het is een beetje complex, ja, als we het bekijken vanuit het perspectief van de boomassemblage.",
  "In addition to this, in the Polkadot architecture and in Ethereum with the latest changes, a data availability check takes place. For this, finalizers visit parachain validators and try to request actual information about each block stored in the network. If they receive data from at least 1/3 of the validators, using technology that allows redundant storage of information, and subsequently, if someone loses it, one or two or three validators can still restore it, there is a critical threshold at 1/3. If 1/3 of the nodes respond and say that we have data about the block being produced, finalizers tell the block that it is already a fully formed information block, that all computations have been done correctly, that we have already taken the header of this block and combined it with someone else's headers from other segments of the network. We have already formed the main header of the entire network. After that, finalizers place many checkmarks on the final block, which combines all performed computations.": "Naast dit alles vindt in de Polkadot-architectuur en in Ethereum met de nieuwste wijzigingen een controle van gegevensbeschikbaarheid plaats. Hiervoor bezoeken finalizers parachain-validatoren en proberen ze daadwerkelijke informatie op te vragen over elk blok dat is opgeslagen in het netwerk. Als ze gegevens ontvangen van minstens 1/3 van de validators, met behulp van technologie die redundante opslag van informatie mogelijk maakt, en vervolgens, als iemand het verliest, kunnen één, twee of drie validators het nog steeds herstellen, is er een kritische drempel op 1/3. Als 1/3 van de knooppunten reageert en zegt dat we gegevens hebben over het geproduceerde blok, vertellen finalizers het blok dat het al een volledig gevormd informatieblok is, dat alle berekeningen correct zijn uitgevoerd, dat we al de kop van dit blok hebben genomen en gecombineerd met de koppen van iemand anders van andere segmenten van het netwerk. We hebben al de hoofdkop van het hele netwerk gevormd. Daarna plaatsen finalizers veel vinkjes op het definitieve blok, dat alle uitgevoerde berekeningen combineert.",
  "Currently, this is the situation from the perspective of the most engineering-implemented multi-chain heterogeneous ecosystem, which is Polkadot. It is the most engineering-implemented multi-chain heterogeneous ecosystem, not too far from Ethereum. I would like to focus on the comparison, and if someone is interested in understanding how information blocks flow in Ethereum with L2 networks, you can try to do that now. I will return to this question when some elements of Ethereum, in terms of heterogeneity and multi-chain aspects, are completed. It might take 1-2 years, and then we can build such a picture. Nevertheless, we can generally accept a scheme with three main stages:": "Op dit moment is dit de situatie vanuit het perspectief van het meest technisch geïmplementeerde multi-chain heterogene ecosysteem, dat Polkadot is. Het is het meest technisch geïmplementeerde multi-chain heterogene ecosysteem, niet al te ver van Ethereum. Ik zou me willen richten op de vergelijking, en als iemand geïnteresseerd is in het begrijpen van hoe informatieblokken stromen in Ethereum met L2-netwerken, kan je dat nu proberen. Ik zal terugkomen op deze vraag wanneer sommige elementen van Ethereum, op het gebied van heterogeniteit en multi-chain aspecten, zijn voltooid. Het kan 1-2 jaar duren, en dan kunnen we zo'n beeld opbouwen. Desalniettemin kunnen we over het algemeen een schema accepteren met drie hoofdfasen:",
  "**1. Formation of a candidate for the information block:**": "**1. Vorming van een kandidaat voor het informatieblok:**",
  "In this stage, the initial candidate for the information block is formed.": "In deze fase wordt de initiële kandidaat voor het informatieblok gevormd.",
  "**2. Execution of all computations, data storage, data availability, rechecking with other nodes, ensuring that all state transitions are performed correctly according to specific algorithms, and storing these algorithms in the main citadel:**": "**2. Uitvoering van alle berekeningen, gegevensopslag, gegevensbeschikbaarheid, hercontrole met andere knooppunten, ervoor zorgen dat alle toestandsovergangen correct worden uitgevoerd volgens specifieke algoritmen, en het opslaan van deze algoritmen in de hoofdcitadel:**",
  "This stage involves the actual execution of computations, saving data to certain layers, ensuring data availability, rechecking with other nodes to confirm that all state transitions are in accordance with algorithms stored somewhere in the main citadel.": "In deze fase wordt de daadwerkelijke uitvoering van berekeningen, het opslaan van gegevens op bepaalde lagen, het waarborgen van gegevensbeschikbaarheid, hercontrole met andere knooppunten om te bevestigen dat alle toestandsovergangen in overeenstemming zijn met algoritmen die ergens in de hoofdcitadel zijn opgeslagen.",
  "**3. Finalization, which will not recheck the computations but will verify the meta-information, how this meta-information is stored. It will then assemble the final block, which is the state of the states, and release it as a common information block for the entire segmented multi-chain network:**": "**3. Finalisatie, waarbij de berekeningen niet opnieuw worden gecontroleerd, maar de meta-informatie zal verifiëren, hoe deze meta-informatie is opgeslagen. Vervolgens zal het het uiteindelijke blok assembleren, dat de toestand van de staten is, en het vrijgeven als een gemeenschappelijk informatieblok voor het gehele gesegmenteerde multi-chain netwerk:**",
  "The final stage involves checking the meta-information, verifying how this meta-information is stored, assembling the final block (state of the states), and releasing it as a common information block for the entire segmented multi-chain network.": "De laatste fase omvat het controleren van de meta-informatie, het verifiëren van hoe deze meta-informatie is opgeslagen, het assembleren van het uiteindelijke blok (toestand van de staten) en het vrijgeven ervan als een gemeenschappelijk informatieblok voor het gehele gesegmenteerde multi-chain netwerk.",
  "At this point, we can say that our information is saved. It has passed through the heart, the heart has executed its data transfer correctly, and we can already use the output values. Some will use them to open a smart-contract-purchased apartment with a smart lock, while others might show off their NFT, just received for 10 ethers.": "Op dit punt kunnen we zeggen dat onze informatie is opgeslagen. Het is door het hart gegaan, het hart heeft zijn gegevensoverdracht correct uitgevoerd, en we kunnen al gebruik maken van de uitvoerwaarden. Sommigen zullen ze gebruiken om een slimme-contract-gekocht appartement te openen met een slim slot, terwijl anderen misschien pronken met hun NFT, zojuist ontvangen voor 10 ethers.",
  "In general, this is approximately how it works. This concludes the theoretical part. I think it took about 2 hours, and ahead of us are practical sessions that I will be recording over the next few months. They will help us understand the observed data from the console window, decentralized applications, block explorers, where we will gradually understand how all these theoretical numbers and letters actually look in implementation using Polkadot as an example. I will also start getting hands-on with implementations at the L2 level using one of the well-known frameworks for building L2. Thank you to everyone who has been watching.": "Over het algemeen is dit ongeveer hoe het werkt. Hiermee wordt het theoretische deel afgesloten. Ik denk dat het ongeveer 2 uur duurde, en voor ons liggen praktijksessies die ik de komende maanden zal opnemen. Ze zullen ons helpen om de waargenomen gegevens vanuit het consolevenster, gedecentraliseerde toepassingen, block explorers te begrijpen, waar we geleidelijk zullen begrijpen hoe al deze theoretische cijfers en letters er eigenlijk uitzien in de implementatie met behulp van Polkadot als voorbeeld. Ik zal ook beginnen met praktische implementaties op het L2-niveau met behulp van een van de bekende frameworks voor het bouwen van L2. Bedankt aan iedereen die heeft gekeken."
}